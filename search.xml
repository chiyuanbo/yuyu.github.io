<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>windows安装elasticsearch</title>
      <link href="/2018/05/03/windows%E5%AE%89%E8%A3%85elasticsearch/"/>
      <url>/2018/05/03/windows%E5%AE%89%E8%A3%85elasticsearch/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h3 id="使用版本"><a href="#使用版本" class="headerlink" title="使用版本"></a>使用版本</h3><p>公司版本</p><pre><code>cupid-elasticsearch-1.7.2.zip</code></pre><h3 id="更改配置文件"><a href="#更改配置文件" class="headerlink" title="更改配置文件"></a>更改配置文件</h3><h4 id="elasticsearch-bat"><a href="#elasticsearch-bat" class="headerlink" title="elasticsearch.bat"></a>elasticsearch.bat</h4><pre><code>#注释前两行错误配置::for /f %%a in (&quot;%~dp0\..&quot;) do set JAVA_HOME_=%%~dpajava::if exist &quot;%JAVA_HOME_%\bin\java.exe&quot; (set JAVA_HOME=%JAVA_HOME_%) else (echo %JAVA_HOME_%指向的路径不存在，使用本地的JAVA_HOME变量)set JAVA_HOME=C:\Program Files\Java\jdk1.8.0_111</code></pre><h4 id="plugin-bat"><a href="#plugin-bat" class="headerlink" title="plugin.bat"></a>plugin.bat</h4><pre><code>同elasticsearch.bat</code></pre><h4 id="service-bat"><a href="#service-bat" class="headerlink" title="service.bat"></a>service.bat</h4><pre><code>elasticsearch.bat</code></pre><h4 id="elasticsearch-yml"><a href="#elasticsearch-yml" class="headerlink" title="elasticsearch.yml"></a>elasticsearch.yml</h4><pre><code>只记录了需要更改的cluster.name: cupid-es-chinode.max_local_storage_nodes: 1index.number_of_replicas: 1gateway.recover_after_nodes: 1gateway.expected_nodes: 1</code></pre><h4 id="完整版配置文件解释-不一定全配置"><a href="#完整版配置文件解释-不一定全配置" class="headerlink" title="完整版配置文件解释[不一定全配置]"></a>完整版配置文件解释[不一定全配置]</h4><h5 id="配置文件详解1-0版"><a href="#配置文件详解1-0版" class="headerlink" title="配置文件详解1.0版"></a>配置文件详解1.0版</h5><pre><code>配置文件位于es根目录的config目录下面，有elasticsearch.yml和logging.yml两个配置，主配置文件是elasticsearch.yml，日志配置文件是logging.yml，elasticsearch调用log4j记录日志，所以日志的配置文件可以按照默认的设置，我来介绍下elasticsearch.yml里面的选项。cluster.name: elasticsearch配置的集群名称，默认是elasticsearch，es服务会通过广播方式自动连接在同一网段下的es服务，通过多播方式进行通信，同一网段下可以有多个集群，通过集群名称这个属性来区分不同的集群。node.name: &quot;Franz Kafka&quot;当前配置所在机器的节点名，你不设置就默认随机指定一个name列表中名字，该name列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。node.master: true指定该节点是否有资格被选举成为node（注意这里只是设置成有资格， 不代表该node一定就是master），默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。node.data: true指定该节点是否存储索引数据，默认为true。index.number_of_shards: 5设置默认索引分片个数，默认为5片。index.number_of_replicas: 1设置默认索引副本个数，默认为1个副本。如果采用默认设置，而你集群只配置了一台机器，那么集群的健康度为yellow，也就是所有的数据都是可用的，但是某些复制没有被分配（健康度可用 curl &apos;localhost:9200/_cat/health?v&apos; 查看， 分为绿色、黄色或红色。绿色代表一切正常，集群功能齐全，黄色意味着所有的数据都是可用的，但是某些复制没有被分配，红色则代表因为某些原因，某些数据不可用）。path.conf: /path/to/conf设置配置文件的存储路径，默认是es根目录下的config文件夹。path.data: /path/to/data设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：path.data: /path/to/data1,/path/to/data2path.work: /path/to/work设置临时文件的存储路径，默认是es根目录下的work文件夹。path.logs: /path/to/logs设置日志文件的存储路径，默认是es根目录下的logs文件夹path.plugins: /path/to/plugins设置插件的存放路径，默认是es根目录下的plugins文件夹, 插件在es里面普遍使用，用来增强原系统核心功能。bootstrap.mlockall: true设置为true来锁住内存不进行swapping。因为当jvm开始swapping时es的效率 会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。 同时也要允许elasticsearch的进程可以锁住内存，linux下启动es之前可以通过`ulimit -l unlimited`命令设置。network.bind_host: 192.168.0.1设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0，绑定这台机器的任何一个ip。network.publish_host: 192.168.0.1设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。network.host: 192.168.0.1这个参数是用来同时设置bind_host和publish_host上面两个参数。transport.tcp.port: 9300设置节点之间交互的tcp端口，默认是9300。transport.tcp.compress: true设置是否压缩tcp传输时的数据，默认为false，不压缩。http.port: 9200设置对外服务的http端口，默认为9200。http.max_content_length: 100mb设置内容的最大容量，默认100mbhttp.enabled: false是否使用http协议对外提供服务，默认为true，开启。gateway.type: localgateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器等。gateway.recover_after_nodes: 1设置集群中N个节点启动时进行数据恢复，默认为1。gateway.recover_after_time: 5m设置初始化数据恢复进程的超时时间，默认是5分钟。gateway.expected_nodes: 2设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。cluster.routing.allocation.node_initial_primaries_recoveries: 4初始化数据恢复时，并发恢复线程的个数，默认为4。cluster.routing.allocation.node_concurrent_recoveries: 2添加删除节点或负载均衡时并发恢复线程的个数，默认为4。indices.recovery.max_size_per_sec: 0设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。indices.recovery.concurrent_streams: 5设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。discovery.zen.minimum_master_nodes: 1设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）discovery.zen.ping.timeout: 3s设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。discovery.zen.ping.multicast.enabled: false设置是否打开多播发现节点，默认是true。discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;, &quot;host3[portX-portY]&quot;]设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。</code></pre><h5 id="配置文件详解2-0版"><a href="#配置文件详解2-0版" class="headerlink" title="配置文件详解2.0版"></a>配置文件详解2.0版</h5><pre><code>配置文件位于%ES_HOME%/config/elasticsearch.yml文件中，用Editplus打开它，你便可以进行配置。        所有的配置都可以使用环境变量，例如：node.rack: ${RACK_ENV_VAR}        表示环境变量中有一个RACK_ENV_VAR变量。        下面列举一下elasticsearch的可配置项：        1. 集群名称，默认为elasticsearch：cluster.name: elasticsearch        2. 节点名称，es启动时会自动创建节点名称，但你也可进行配置：node.name: &quot;Franz Kafka&quot;        3. 是否作为主节点，每个节点都可以被配置成为主节点，默认值为true：node.master: true        4. 是否存储数据，即存储索引片段，默认值为true：node.data: true        master和data同时配置会产生一些奇异的效果：        1) 当master为false，而data为true时，会对该节点产生严重负荷；        2) 当master为true，而data为false时，该节点作为一个协调者；        3) 当master为false，data也为false时，该节点就变成了一个负载均衡器。        你可以通过连接http://localhost:9200/_cluster/health或者http://localhost:9200/_cluster/nodes，或者使用插件http://github.com/lukas-vlcek/bigdesk或http://mobz.github.com/elasticsearch-head来查看集群状态。        5. 每个节点都可以定义一些与之关联的通用属性，用于后期集群进行碎片分配时的过滤：node.rack: rack314        6. 默认情况下，多个节点可以在同一个安装路径启动，如果你想让你的es只启动一个节点，可以进行如下设置：node.max_local_storage_nodes: 1        7. 设置一个索引的碎片数量，默认值为5：index.number_of_shards: 5        8. 设置一个索引可被复制的数量，默认值为1：index.number_of_replicas: 1        当你想要禁用公布式时，你可以进行如下设置：index.number_of_shards: 1index.number_of_replicas: 0        这两个属性的设置直接影响集群中索引和搜索操作的执行。假设你有足够的机器来持有碎片和复制品，那么可以按如下规则设置这两个值：        1) 拥有更多的碎片可以提升索引执行能力，并允许通过机器分发一个大型的索引；        2) 拥有更多的复制器能够提升搜索执行能力以及集群能力。        对于一个索引来说，number_of_shards只能设置一次，而number_of_replicas可以使用索引更新设置API在任何时候被增加或者减少。        ElasticSearch关注加载均衡、迁移、从节点聚集结果等等。可以尝试多种设计来完成这些功能。        可以连接http://localhost:9200/A/_status来检测索引的状态。        9. 配置文件所在的位置，即elasticsearch.yml和logging.yml所在的位置：path.conf: /path/to/conf        10. 分配给当前节点的索引数据所在的位置：path.data: /path/to/data        可以可选择的包含一个以上的位置，使得数据在文件级别跨越位置，这样在创建时就有更多的自由路径，如：path.data: /path/to/data1,/path/to/data2        11. 临时文件位置：path.work: /path/to/work        12. 日志文件所在位置：path.logs: /path/to/logs        13. 插件安装位置：path.plugins: /path/to/plugins        14. 插件托管位置，若列表中的某一个插件未安装，则节点无法启动：plugin.mandatory: mapper-attachments,lang-groovy        15. JVM开始交换时，ElasticSearch表现并不好：你需要保障JVM不进行交换，可以将bootstrap.mlockall设置为true禁止交换：bootstrap.mlockall: true        请确保ES_MIN_MEM和ES_MAX_MEM的值是一样的，并且能够为ElasticSearch分配足够的内在，并为系统操作保留足够的内存。        16. 默认情况下，ElasticSearch使用0.0.0.0地址，并为http传输开启9200-9300端口，为节点到节点的通信开启9300-9400端口，也可以自行设置IP地址：network.bind_host: 192.168.0.1        17. publish_host设置其他节点连接此节点的地址，如果不设置的话，则自动获取，publish_host的地址必须为真实地址：network.publish_host: 192.168.0.1        18. bind_host和publish_host可以一起设置：network.host: 192.168.0.1        19. 可以定制该节点与其他节点交互的端口：transport.tcp.port: 9300        20. 节点间交互时，可以设置是否压缩，转为为不压缩：transport.tcp.compress: true        21. 可以为Http传输监听定制端口：http.port: 9200        22. 设置内容的最大长度：http.max_content_length: 100mb        23. 禁止HTTPhttp.enabled: false        24. 网关允许在所有集群重启后持有集群状态，集群状态的变更都会被保存下来，当第一次启用集群时，可以从网关中读取到状态，默认网关类型（也是推荐的）是local：gateway.type: local        25. 允许在N个节点启动后恢复过程：gateway.recover_after_nodes: 1        26. 设置初始化恢复过程的超时时间：gateway.recover_after_time: 5m        27. 设置该集群中可存在的节点上限：gateway.expected_nodes: 2        28. 设置一个节点的并发数量，有两种情况，一种是在初始复苏过程中：cluster.routing.allocation.node_initial_primaries_recoveries: 4        另一种是在添加、删除节点及调整时：cluster.routing.allocation.node_concurrent_recoveries: 2        29. 设置复苏时的吞吐量，默认情况下是无限的：indices.recovery.max_size_per_sec: 0        30. 设置从对等节点恢复片段时打开的流的数量上限：indices.recovery.concurrent_streams: 5        31. 设置一个集群中主节点的数量，当多于三个节点时，该值可在2-4之间：discovery.zen.minimum_master_nodes: 1        32. 设置ping其他节点时的超时时间，网络比较慢时可将该值设大：discovery.zen.ping.timeout: 3shttp://elasticsearch.org/guide/reference/modules/discovery/zen.html上有更多关于discovery的设置。        33. 禁止当前节点发现多个集群节点，默认值为true：discovery.zen.ping.multicast.enabled: false        34. 设置新节点被启动时能够发现的主节点列表（主要用于不同网段机器连接）：discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;, &quot;host3[portX-portY]&quot;]       35.设置是否可以通过正则或者_all删除或者关闭索引action.destructive_requires_name 默认false 允许 可设置true不允许     </code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>常用</title>
      <link href="/2018/05/03/%E5%B8%B8%E7%94%A8/"/>
      <url>/2018/05/03/%E5%B8%B8%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><p>==注意！Hadoop需要配置环境变量==</p><p>.class.getResourceAsStream()读取的文件路径只局限与工程的源文件夹中，包括在工程src根目录下，以及类包里面任何位置，但是如果配置文件路径是在除了源文件夹之外的其他文件夹中时，该方法是用不了的。</p><p>连接phoenix</p><pre><code>sqlline.py localhost!help查看帮助指令!all                Execute the specified SQL against all the current connections!autocommit         Set autocommit mode on or off!batch              Start or execute a batch of statements!brief              Set verbose mode off!call               Execute a callable statement!close              Close the current connection to the database!closeall           Close all current open connections!columns            List all the columns for the specified table!commit             Commit the current transaction (if autocommit is off)!connect            Open a new connection to the database.!dbinfo             Give metadata information about the database!describe           Describe a table!dropall            Drop all tables in the current database!exportedkeys       List all the exported keys for the specified table!go                 Select the current connection!help               Print a summary of command usage!history            Display the command history!importedkeys       List all the imported keys for the specified table!indexes            List all the indexes for the specified table!isolation          Set the transaction isolation for this connection!list               List the current connections!manual             Display the SQLLine manual!metadata           Obtain metadata information!nativesql          Show the native SQL for the specified statement!outputformat       Set the output format for displaying results                    (table,vertical,csv,tsv,xmlattrs,xmlelements)!primarykeys        List all the primary keys for the specified table!procedures         List all the procedures!properties         Connect to the database specified in the properties file(s)!quit               Exits the program!reconnect          Reconnect to the database!record             Record all output to the specified file!rehash             Fetch table and column names for command completion!rollback           Roll back the current transaction (if autocommit is off)!run                Run a script from the specified file!save               Save the current variabes and aliases!scan               Scan for installed JDBC drivers!script             Start saving a script to a file!set                Set a sqlline variable!tables查看所有表select * from FJUDM4.HBASE_MD_OMS_T_PROTECTAZFXYB ;//查询的时候库名+表名</code></pre><p>linux使用jdbc的方式去连接hive 可以测试jdbc是否能用</p><p>beeline -u jdbc:hive2://192.168.6.1:10009 -n yarn<br>jdbc的ResultSetMetaData.getColumnCount()是列的数量</p><p>北京实验室环境</p><p>D:\电科院\集群环境-新.html</p><p>tab的反向是shift+tab</p><p>dm的查询不加库名和中间名会查不出来<br>复制路径打开dm的说明：D:\电科院\随记\DM.docx</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d29698dfa.png" alt=""></p><p>hive文档的路径：D:\电科院\随记\hive.docx</p><p>遍历ResultSet</p><p>为什么遍历ResultSet，行列要从1开始。</p><p>因为Resultset的第一行的第一列都是空的，要用rs.next()到第一行才能进行读取。</p><pre><code>Statement stmt=null;ResultSet rs=null;ResultSetMetaDatam=null;//获取 列信息try{stmt=con.createStatement();rs=stmt.executeQuery(sql);m=rs.getMetaData();int columns=m.getColumnCount();==//显示列,表格的表头====(绝对不可以使用while(rs.next())去遍历)==for(int i=1;i&lt;=columns;i++){System.out.print(m.getColumnName(i));System.out.print(&quot;\t\t&quot;);}System.out.println();==//显示表格内容==while(rs.next()){for(int i=1;i&lt;=columns;i++){System.out.print(rs.getString(i));System.out.print(&quot;\t\t&quot;);}System.out.println();}</code></pre><p>hive查询的double格式能显示全部小数，dm显示4位<br>hive查询的表结构小写，dm大写</p><p>将double类型保留两位小数</p><pre><code>double d = (double)Math.round(Double.valueOf(str)*100)/100;这个方法有问题如果是5.00  转换为5.0Double d = Double.valueOf(str);DecimalFormat df = new DecimalFormat(&quot;#.00&quot;);String d2 =  df.format(d);这个方法不好用  比如0.25  处理后会变为.25String.format(&quot;%.2f&quot;, Double.valueOf(str))使用这个</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>VMWARE克隆虚机更改静态IP</title>
      <link href="/2018/05/03/VMWARE%E5%85%8B%E9%9A%86%E8%99%9A%E6%9C%BA%E6%9B%B4%E6%94%B9%E9%9D%99%E6%80%81IP/"/>
      <url>/2018/05/03/VMWARE%E5%85%8B%E9%9A%86%E8%99%9A%E6%9C%BA%E6%9B%B4%E6%94%B9%E9%9D%99%E6%80%81IP/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><p>==使用版本:centos6.7==</p><p>克隆过程这里就不写了</p><p>克隆过后它会默认开启另一个ip接口</p><p>我们要做的就是修改几个配置文件</p><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><pre><code>vi /etc/sysconfig/network更改这里的HOSTNAME</code></pre><h3 id="修改映射关系"><a href="#修改映射关系" class="headerlink" title="修改映射关系"></a>修改映射关系</h3><pre><code>vi /etc/hosts删掉上边存的不正确的 将自己的添加上 例如:127.0.0.1       cluster_model localhost.localdomain localhost192.168.15.11   cluster_model192.168.15.12   cluster_node1192.168.15.13   cluster_node2</code></pre><h3 id="修改ip-及-eth1-这里是eth0改为eth1-及-硬件地址"><a href="#修改ip-及-eth1-这里是eth0改为eth1-及-硬件地址" class="headerlink" title="修改ip  及 eth1( 这里是eth0改为eth1)    及 硬件地址"></a>修改ip  及 eth1( 这里是eth0改为eth1)    及 硬件地址</h3><pre><code>ifconfig查看HWADDR重命名mv /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth1修改配置vi /etc/sysconfig/network-scripts/ifcfg-eth1DEVICE=eth1加上刚才查看的HWADDRIPADDR=</code></pre><h3 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h3><pre><code>service network restart</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><pre><code>ping下其他集群ip以及宿主机ip测试下</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Linux虚拟机 配置YUM源</title>
      <link href="/2018/05/03/Linux%E8%99%9A%E6%8B%9F%E6%9C%BA%20%E9%85%8D%E7%BD%AEYUM%E6%BA%90/"/>
      <url>/2018/05/03/Linux%E8%99%9A%E6%8B%9F%E6%9C%BA%20%E9%85%8D%E7%BD%AEYUM%E6%BA%90/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[TOC]</p><h3 id="本地YUM源配置"><a href="#本地YUM源配置" class="headerlink" title="本地YUM源配置"></a>本地YUM源配置</h3><h4 id="使用挂载光驱作为YUM源"><a href="#使用挂载光驱作为YUM源" class="headerlink" title="使用挂载光驱作为YUM源"></a>使用挂载光驱作为YUM源</h4><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d84aa243e.png" alt=""></p><h4 id="挂载光驱"><a href="#挂载光驱" class="headerlink" title="挂载光驱"></a>挂载光驱</h4><pre><code>mkdir /mnt/cdrom        mount -t iso9660 -o ro /dev/cdrom /mnt/cdrom/ </code></pre><p>如果报错</p><pre><code>mount: no medium found on /dev/sr1</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/08/5939132157cd7.jpg" alt="2012040814220010.jpg"></p><p><img src="https://ooo.0o0.ooo/2017/06/08/5939132158d3b.jpg" alt="2012040814223645.jpg"></p><h4 id="修改本机的YUM源，将源只想光驱"><a href="#修改本机的YUM源，将源只想光驱" class="headerlink" title="修改本机的YUM源，将源只想光驱"></a>修改本机的YUM源，将源只想光驱</h4><pre><code>cd /etc/yum.repos.d/            rename .repo .repo.bak *         #为了测试方便，避免其他YUM源的干扰cp CentOS-Media.repo.bak CentOS-Local.repovi CentOS-Local.repo修改如下配置：baseurl=file:///mnt/cdrom        #挂载光驱的位置gpgcheck=1                              #gpg验证是否开启的选项，1是开启，0是不开启，一般情况可以关掉。enabled=1                                  #是否启用：0：不启用  1：启用</code></pre><h4 id="配置好后"><a href="#配置好后" class="headerlink" title="配置好后"></a>配置好后</h4><pre><code>yum clean allyum list查看列表</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>centos7安装hive1.2.1</title>
      <link href="/2018/05/03/centos7%E5%AE%89%E8%A3%85hive1.2.1/"/>
      <url>/2018/05/03/centos7%E5%AE%89%E8%A3%85hive1.2.1/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h3 id="准备软件"><a href="#准备软件" class="headerlink" title="准备软件"></a>准备软件</h3><pre><code>apache-hive-1.2.1-bin.tar.gz</code></pre><h3 id="安装步奏"><a href="#安装步奏" class="headerlink" title="安装步奏"></a>安装步奏</h3><pre><code>将文件解压在/usr/local/下并改名hive_1.2.1#配置系统环境变量/etc/profile# Hive Environment Variablesexport HIVE_HOME=/usr/local/hive_1.2.1export PATH=$PATH:$HIVE_HOME/bin:$HIVE_HOME/confsource /etc/profile 使刚刚的配置生效#配置Hivehive的配置文件放在$HIVE_HOME/conf下，里面有4个默认的配置文件模板hive-default.xml.template                           默认模板hive-env.sh.template                hive-env.sh默认配置hive-exec-log4j.properties.template    exec默认配置hive-log4j.properties.template               log默认配置可不做任何修改hive也能运行，默认的配置元数据是存放在Derby数据库里面的，大多数人都不怎么熟悉，我们得改用mysql来存储我们的元数据，以及修改数据存放位置和日志存放位置等使得我们必须配置自己的环境，下面介绍如何配置。</code></pre><p>（1）创建配置文件，直接copy默认配置文件再修改即可，用户自定义配置会覆盖默认配置</p><pre><code>cp $HIVE_HOME/conf/hive-default.xml.template $HIVE_HOME/conf/hive-site.xmlcp $HIVE_HOME/conf/hive-env.sh.template $HIVE_HOME/conf/hive-env.shcp $HIVE_HOME/conf/hive-exec-log4j.properties.template $HIVE_HOME/conf/hive-exec-log4j.propertiescp $HIVE_HOME/conf/hive-log4j.properties.template $HIVE_HOME/conf/hive-log4j.properties</code></pre><p>（2）修改 hive-env.sh </p><pre><code>vi $HIVE_HOME/conf/hive-env.sh export HADOOP_HOME=/usr/local/hadoopexport HIVE_CONF_DIR=/usr/local/hive_1.2.1/conf</code></pre><p>（3）修改 hive-log4j.properties</p><pre><code>mkdir $HIVE_HOME/logsvi $HIVE_HOME/conf/hive-log4j.propertieshive.log.dir=/usr/local/hive_1.2.1/logs</code></pre><p>（4）修改 hive-site.xml</p><pre><code>vi $HIVE_HOME/conf/hive-site.xml&lt;property&gt;&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;&lt;value&gt;/usr/local/hive_1.2.1/warehouse&lt;/value&gt;&lt;description&gt;location of default database for the warehouse&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hive.exec.scratchdir&lt;/name&gt;&lt;value&gt;/usr/local/hive_1.2.1/scratchdir&lt;/value&gt;&lt;description&gt;HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: ${hive.exec.scratchdir}/&amp;lt;username&amp;gt; is created, with ${hive.scratch.dir.permission}.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hive.querylog.location&lt;/name&gt;&lt;value&gt;/usr/local/hive_1.2.1/logs&lt;/value&gt;&lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;&lt;value&gt;jjdbc:mysql://192.168.15.131:3306/hivedb?createDatabaseIfNotExist=true&lt;/value&gt;&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;&lt;value&gt;root&lt;/value&gt;&lt;description&gt;Username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;&lt;value&gt;root&lt;/value&gt;&lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Elasticsearch集群搭建</title>
      <link href="/2018/05/03/Elasticsearch%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>/2018/05/03/Elasticsearch%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h3 id="搭建集群model"><a href="#搭建集群model" class="headerlink" title="搭建集群model"></a>搭建集群model</h3><p>准备一台虚机  </p><pre><code>centos6.7免密码登陆yum源静态IP/etc/hosts配置/etc/sysconfig/network配置jdk&amp;环境变量</code></pre><p>解压elasticsearch到/usr/local下 </p><p>配置elasticsearch.yml(注意要顶格写，冒号后面要加一个空格)</p><pre><code>a)  Cluster.name: elasticsearch_chi  (同一集群要一样)b)  Node.name： node-1  (同一集群要不一样)c)  Network.Host: 192.168.15.11d)  discovery.zen.ping.multicast.enabled: false    discovery.zen.ping.timeout: 120s    client.transport.ping.timeout: 60s    discovery.zen.ping.unicast.hosts: [&quot;192.168.15.11&quot;,&quot;192.168.15.12&quot;, &quot;192.168.15.13&quot;]</code></pre><p>开始clone两台虚机  clone过后改ip方法见我笔记    </p><h3 id="head插件"><a href="#head插件" class="headerlink" title="head插件"></a>head插件</h3><h4 id="插件安装方法1："><a href="#插件安装方法1：" class="headerlink" title="插件安装方法1："></a>插件安装方法1：</h4><pre><code>1.elasticsearch/bin/plugin -install mobz/elasticsearch-head2.运行es3.打开http://localhost:9200/_plugin/head/</code></pre><h4 id="插件安装方法2："><a href="#插件安装方法2：" class="headerlink" title="插件安装方法2："></a>插件安装方法2：</h4><pre><code>1.https://github.com/mobz/elasticsearch-head下载zip     解到压elasticsearch-1.0.0\plugins\  并重命名为head2.运行es3.打开http://localhost:9200/_plugin/head/</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>hive开发过程中遇到的一些问题</title>
      <link href="/2018/05/03/hive%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/"/>
      <url>/2018/05/03/hive%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h3 id="1、连接hive的时候发现连接不上，后来发现是hdfs有损坏文件，"><a href="#1、连接hive的时候发现连接不上，后来发现是hdfs有损坏文件，" class="headerlink" title="1、连接hive的时候发现连接不上，后来发现是hdfs有损坏文件，"></a>1、连接hive的时候发现连接不上，后来发现是hdfs有损坏文件，</h3><p>hadoop fsck的一些命令</p><pre><code>Hadoop fsck [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]&lt;path&gt;        检查的起始目录-move        将损坏的文件移动到/lost+found下面-delete        删除损坏的文件-openforwrite    打印出正在写的文件-files        打印出所有被检查的文件-blocks        打印出block报告-locations    打印出每个block的位置-racks        打印出datanode的网络拓扑结构</code></pre><p>==hadoop fsck -list-corruptfileblocks命令查看==</p><p>hadoop fsck -delete命令清理</p><h3 id="hiveserver2启动"><a href="#hiveserver2启动" class="headerlink" title="hiveserver2启动:"></a>hiveserver2启动:</h3><p>1.启动 metastort</p><pre><code>nohup  hive --service metastore &gt;/dev/null  2&gt;&amp;1 &amp;</code></pre><p>2.进入 /home/yarn/apache-hive-1.2.1-bin/bin 下启动</p><pre><code>startserver2.sh +10009beeline -u jdbc:hive2://192.168.6.1:10009 -n yarn -p yarn    #检测</code></pre><p>3.进入 /home/yarn/spark-1.5.2-bin-hadoop2.6/sbin 下启动spark的</p><pre><code>start-server2.sh +14000</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>cnetos7安装hadoop2.6.4</title>
      <link href="/2018/05/03/cnetos7%E5%AE%89%E8%A3%85hadoop2.6.4/"/>
      <url>/2018/05/03/cnetos7%E5%AE%89%E8%A3%85hadoop2.6.4/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[TOC]</p><h3 id="准备软件"><a href="#准备软件" class="headerlink" title="准备软件"></a>准备软件</h3><pre><code>jdk-7u80-linux-x64.tar.gz,hadoop-2.6.4.tar.gz</code></pre><h3 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h3><h4 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h4><p>配置jdk要先卸载centos自带的openjdk<br>先查看 rpm -qa | grep java<br>显示如下信息：</p><pre><code>[root@localhost /]# rpm -qa | grep javajava-1.8.0-openjdk-headless-1.8.0.65-3.b17.el7.x86_64javapackages-tools-3.4.1-11.el7.noarchjava-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64tzdata-java-2015g-1.el7.noarchjava-1.7.0-openjdk-1.7.0.91-2.6.2.3.el7.x86_64java-1.7.0-openjdk-headless-1.7.0.91-2.6.2.3.el7.x86_64python-javapackages-3.4.1-11.el7.noarch</code></pre><p>卸载</p><pre><code>rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.65-3.b17.el7.x86_64rpm -e --nodeps java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-1.7.0.91-2.6.2.3.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.91-2.6.2.3.el7.x86_64</code></pre><p>解压jdk并配置环境变量</p><pre><code>vim /etc/profile在最后添加JAVA_HOME=/usr/local/jdk_1.7PATH=$PATH:$JAVA_HOME/bin:CLASSPATH=.:$JAVA_HOME/libexport JAVA_HOME  PATH CLASSPATH</code></pre><h4 id="安装SSH、配置SSH无密码登陆"><a href="#安装SSH、配置SSH无密码登陆" class="headerlink" title="安装SSH、配置SSH无密码登陆"></a>安装SSH、配置SSH无密码登陆</h4><pre><code>执行如下命令进行检验：[spark@localhost ~]$ rpm -qa | grep sshopenssh-6.6.1p1-22.el7.x86_64libssh2-1.4.3-10.el7.x86_64openssh-server-6.6.1p1-22.el7.x86_64openssh-clients-6.6.1p1-22.el7.x86_64此时是已经安装了</code></pre><p> 若需要安装，则可以通过 yum 进行安装（安装过程中会让你输入 [y/N]，输入 y 即可）：</p><pre><code>sudo yum install openssh-clientssudo yum install openssh-server</code></pre><p>接着执行如下命令测试一下 SSH 是否可用：</p><pre><code>[spark@localhost ~]$ ssh localhostspark@localhost&apos;s password: Last login: Tue Feb  7 23:34:34 2017 from 192.168.15.1-bash: : No such file or directory</code></pre><p>但这样登陆是需要每次输入密码的，我们需要配置成SSH无密码登陆比较方便。</p><p>首先输入 exit 退出刚才的 ssh，就回到了我们原先的终端窗口，然后利用 ssh-keygen 生成密钥，并将密钥加入到授权中：</p><pre><code>[spark@localhost ~]$ exit# 退出刚才的 ssh localhostlogoutConnection to localhost closed.[spark@localhost ~]$ cd ~/.ssh/# 若没有该目录，请先执行一次ssh localhost[spark@localhost .ssh]$ lsknown_hosts[spark@localhost .ssh]$ ssh-keygen -t rsa# 会有提示，都按回车就可以Generating public/private rsa key pair.Enter file in which to save the key (/home/spark/.ssh/id_rsa):    Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/spark/.ssh/id_rsa.Your public key has been saved in /home/spark/.ssh/id_rsa.pub.The key fingerprint is:23:b2:30:77:8a:33:d8:93:84:c4:3a:57:4b:3e:bb:d4 spark@localhost.localdomainThe key&apos;s randomart image is:+--[ RSA 2048]----+|                 ||.                || o  o            ||o. + .           ||+ = * o S        || * * O . .       ||. B = E          ||   = .           ||    .            |+-----------------+[spark@localhost .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys# 加入授权[spark@localhost .ssh]$ chmod 600 ./authorized_keys# 修改文件权限在 Linux 系统中，~ 代表的是用户的主文件夹，即 “/home/用户名” 这个目录，如你的用户名为 hadoop，则 ~ 就代表 “/home/hadoop/”[spark@localhost .ssh]$ pwd/home/spark/.ssh</code></pre><p>此时再用 ssh localhost 命令，无需输入密码就可以直接登陆了</p><pre><code>[spark@localhost .ssh]$ ssh localhostLast login: Tue Feb  7 23:35:12 2017 from localhost-bash: : No such file or directory[spark@localhost ~]$ exitlogoutConnection to localhost closed.    </code></pre><h4 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h4><p>Hadoop 解压后即可使用。==如果没有解压权限，给压缩包的上一级文件夹变为用户的spark的==输入如下命令来检查 Hadoop 是否可用，成功则会显示 Hadoop 版本信息：<br>​<br>    更改文件夹名方便配置文件<br>    mv hadoop-2.6.4 hadoop</p><pre><code>cd /usr/local/hadoop./bin/hadoop version</code></pre><p>设置 HADOOP 环境变量</p><pre><code>vim /etc/profile# Hadoop Environment Variablesexport HADOOP_HOME=/usr/local/hadoopexport HADOOP_INSTALL=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin    </code></pre><p>执行如下命令使配置生效<br>​<br>    cource /etc/profile<br>修改配置文件 etc/hadoop<br>​<br>    core-site.xml</p> <configuration><br>        <property><br>            <name>hadoop.tmp.dir</name><br>            <value>file:/usr/local/hadoop/tmp</value><br>            <description>Abase for other temporary directories.</description><br>        </property><br>        <property><br>            <name>fs.defaultFS</name><br>            <value>hdfs://localhost:9000</value><br>        </property><br>    </configuration><br>修改配置文件 hdfs-site.xml<br>​<br>        <configuration><br>        <property><br>            <name>dfs.replication</name><br>            <value>1</value><br>        </property><br>        <property><br>            <name>dfs.namenode.name.dir</name><br>            <value>file:/usr/local/hadoop/tmp/dfs/name</value><br>        </property><br>        <property><br>            <name>dfs.datanode.data.dir</name><br>            <value>file:/usr/local/hadoop/tmp/dfs/data</value><br>        </property><br>    </configuration><p>配置完成后，执行 NameNode 的格式化:</p><pre><code>./bin/hdfs namenode -format 成功的话，会看到 “successfully formatted” 和 “Exitting with status 0” 的提示，若为 “Exitting with status 1” 则是出错。</code></pre><p>==接着开启 NaneNode 和 DataNode 守护进程：==</p><pre><code>./sbin/start-dfs.sh</code></pre><p>若出现如下 SSH 的提示 “Are you sure you want to continue connecting”，输入 yes 即可。<br>localhost: Error: JAVA_HOME is not set and could not be found.<br>​<br>      修改/etc/hadoop/hadoop-env.sh中设JAVA_HOME<br>      export JAVA_HOME=/usr/local/jdk_1.7<br>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode”和SecondaryNameNode（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。</p><p>==通过查看启动日志分析启动失败原因==</p><p>有时 Hadoop 无法正确启动，如 NameNode 进程没有顺利启动，这时可以查看启动日志来排查原因，注意几点：</p><pre><code>启动时会提示形如 “dblab: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-dblab.out”，其中 dblab 对应你的主机名，但启动的日志信息是记录在 /usr/local/hadoop/logs/hadoop-hadoop-namenode-dblab.log 中，所以应该查看这个后缀为 .log 的文件；每一次的启动日志都是追加在日志文件之后，所以得拉到最后面看，看下记录的时间就知道了。一般出错的提示在最后面，也就是写着 Fatal、Error 或者 Java Exception 的地方。可以在网上搜索一下出错信息，看能否找到一些相关的解决方法。</code></pre><p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：<br>​<br>        ./bin/hdfs dfs -mkdir -p /user/spark<br>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/hadoop/input 中。我们使用的是 spark 用户，并且已创建相应的用户目录 /user/spark ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/spark/input:<br>​<br>    ./bin/hdfs dfs -mkdir input<br>    ./bin/hdfs dfs -put ./etc/hadoop/*.xml input<br>复制完成后，可以通过如下命令查看 HDFS 中的文件列表：</p><pre><code>./bin/hdfs dfs -ls input</code></pre><p>[图片丢失]</p><p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p><pre><code>./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output &apos;dfs[a-z.]+&apos;</code></pre><p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：<br>​<br>        ./bin/hdfs dfs -cat output/*<br>结果如下，注意到刚才我们已经更改了配置文件，所以运行结果不同。</p><p>[图片丢失]</p><p>我们也可以将运行结果取回到本地：</p><pre><code>rm -r ./output    # 先删除本地的 output 文件夹（如果存在）./bin/hdfs dfs -get output ./output     # 将 HDFS 上的 output 文件夹拷贝到本机cat ./output/*</code></pre><p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:<br>​<br>        ./bin/hdfs dfs -rm -r output    # 删除 output 文件夹<br>运行程序时，输出目录不能存在</p><p>运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时自动删除输出目录，避免繁琐的命令行操作：</p><pre><code>Configuration conf = new Configuration();Job job = new Job(conf);/* 删除输出目录 */Path outputPath = new Path(args[1]);outputPath.getFileSystem(conf).delete(outputPath, true);        </code></pre><p>==若要关闭 Hadoop，则运行==</p><pre><code>./sbin/stop-dfs.sh</code></pre><h4 id="启动YARN"><a href="#启动YARN" class="headerlink" title="启动YARN"></a>启动YARN</h4><p>有的读者可能会疑惑，怎么启动 Hadoop 后，见不到书上所说的 JobTracker 和 TaskTracker，这是因为新版的 Hadoop 使用了新的 MapReduce 框架（MapReduce V2，也称为 YARN，Yet Another Resource Negotiator）。</p><p>YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性，YARN 的更多介绍在此不展开，有兴趣的可查阅相关资料。</p><p>上述通过 ./sbin/start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们可以启动 YARN ，让 YARN 来负责资源管理与任务调度。</p><p>首先修改配置文件 mapred-site.xml，这边需要先进行重命名：</p><pre><code>mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml</code></pre><p>Shell 命令</p><p>然后再进行编辑，vim ./etc/hadoop/mapred-site.xml ：</p><pre><code>&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>XML</p><p>接着修改配置文件 yarn-site.xml：</p><pre><code>vim ./etc/hadoop/yarn-site.xml &lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;     &lt;/property&gt;&lt;/configuration&gt;</code></pre><p> ==然后就可以启动 YARN 了（需要先执行过 ./sbin/start-dfs.sh）：==</p><pre><code>./sbin/start-yarn.sh      $ 启动YARN./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况</code></pre><p>[图片丢失]<br>启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：<a href="http://192.168.15.131:8088/cluster，如下图所示。" target="_blank" rel="noopener">http://192.168.15.131:8088/cluster，如下图所示。</a></p><p>[图片丢失]</p><p>但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑得稍慢些。因此在单机上是否开启 YARN 就看实际情况了。<br>== 不启动 YARN 需重命名 mapred-site.xml==</p><pre><code>如果不想启动 YARN，务必把配置文件 mapred-site.xml 重命名，改成 mapred-site.xml.template，需要用时改回来就行。否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，这也是为何该配置文件初始文件名为 mapred-site.xml.template。</code></pre><p>==同样的，关闭 YARN 的脚本如下：==</p><pre><code>./sbin/stop-yarn.sh./sbin/mr-jobhistory-daemon.sh stop historyserver</code></pre><h4 id="配置变量"><a href="#配置变量" class="headerlink" title="配置变量"></a>配置变量</h4><p>在前面我们设置 HADOOP 环境变量时，我们已经顺便设置了 PATH 变量（即 “export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin”），那么以后我们在任意目录中都可以直接通过执行start-dfs.sh 来启动 Hadoop 或者执行 hdfs dfs -ls input 查看 HDFS 文件了，执行 hdfs dfs -ls input 试试看。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>centos7安装hbase1.1.4</title>
      <link href="/2018/05/03/centos7%E5%AE%89%E8%A3%85hbase1.1.4/"/>
      <url>/2018/05/03/centos7%E5%AE%89%E8%A3%85hbase1.1.4/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[TOC]</p><h3 id="准备软件"><a href="#准备软件" class="headerlink" title="准备软件"></a>准备软件</h3><pre><code>hbase-1.1.4-bin.tar.gz</code></pre><h3 id="安装步奏"><a href="#安装步奏" class="headerlink" title="安装步奏"></a>安装步奏</h3><pre><code>#解压tar zxvf hbase-1.1.4-bin.tar.gz#修改环境变量   vi /etc/profile# Hbase Environment Variablesexport HBASE_HOME=/usr/local/hbase-1.1.4export PATH=$HBASE_HOME/bin:$PATHsource /etc/profile生效。#修改hbase-env.sh，添加：vi conf/hbase-env.shexport JAVA_HOME=/usr/local/jdk_1.7#修改配置文件vi conf/hbase-site.xml&lt;configuration&gt;    &lt;property&gt;            &lt;name&gt;hbase.rootdir&lt;/name&gt;            &lt;value&gt;hdfs://192.168.15.131:9000/hbase&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;            &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>shell</title>
      <link href="/2018/05/02/shell/"/>
      <url>/2018/05/02/shell/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h4 id="jdbc连接hive"><a href="#jdbc连接hive" class="headerlink" title="jdbc连接hive"></a>jdbc连接hive</h4><p><code>beeline -u jdbc:hive2://192.168.6.1:10009 -n yarn</code></p><h4 id="连接Phoenix"><a href="#连接Phoenix" class="headerlink" title="连接Phoenix"></a>连接Phoenix</h4><p><code>sqlline.py localhost可以进入phoenix shell   然后   !tables查看表</code></p><h4 id="ls-l排序"><a href="#ls-l排序" class="headerlink" title="ls -l排序"></a>ls -l排序</h4><pre><code>按大小排序[root@localhost ~]# ll -Sh 按时间排序[root@localhost ~]# ll -rtll －t 是降序， ll －t ｜ tac 是升序</code></pre><h4 id="查询可执行文件命令"><a href="#查询可执行文件命令" class="headerlink" title="查询可执行文件命令"></a>查询可执行文件命令</h4><pre><code>which eclipse想要在xstar上执行eclipse的话如果有变量直接eclipse就可以了</code></pre><h4 id="给SecureCRT安装上传和下载的工具"><a href="#给SecureCRT安装上传和下载的工具" class="headerlink" title="给SecureCRT安装上传和下载的工具"></a>给SecureCRT安装上传和下载的工具</h4><pre><code>yum install lrzsz现在CentOS7使用systemd作为新的init系统，而systemd系统使用“target”来代替“runlevel”，默认有两个主要的target： multi-user.target：相当于runlevel 3[命令行界面]，graphical.target：相当于runlevel 5[图形界面]设置默认的target则使用命令：ln -sf /lib/systemd/system/&lt;target name&gt;.target /etc/systemd/system/default.target我这里要将CentOS7开机默认进入命令行界面，则运行命令：ln -sf /lib/systemd/system/multi-user.target /etc/systemd/system/default.target</code></pre><h4 id="centos7开机模式"><a href="#centos7开机模式" class="headerlink" title="centos7开机模式"></a>centos7开机模式</h4><p>现在CentOS7使用systemd作为新的init系统，而systemd系统使用“target”来代替“runlevel”，默认有两个主要的target：    </p><pre><code>multi-user.target：相当于runlevel 3[命令行界面]，            graphical.target：相当于runlevel 5[图形界面]设置默认的target则使用命令：ln -sf /lib/systemd/system/&lt;target name&gt;.target     /etc/systemd/system/default.target我这里要将CentOS7开机默认进入命令行界面，则运行命令：ln -sf /lib/systemd/system/multi-user.target /etc/systemd/system/default.target</code></pre><h4 id="切换用户"><a href="#切换用户" class="headerlink" title="切换用户"></a>切换用户</h4><pre><code>su [user] 和 su - [user]的区别：su [user]切换到其他用户，但是不切换环境变量，su - [user]则是完整的切换到新的用户环境。如：[root@rac1 ~]# pwd  --当前目录/root[root@rac1 ~]# su oracle --使用su [user][oracle@rac1 root]$ pwd  --当前目录没有改变，还是之前的用户目录/root[oracle@rac1 root]$ su - oracle --使用su - [user]Password:[oracle@rac1 ~]$ pwd   --当前目录变为当前用户的家目录/home/oracle[oracle@rac1 ~]$所以建议大家在切换用户时，尽量用su - [use r]，否则可能会出现环境变量不对的问题。</code></pre><h4 id="无法用yum安装"><a href="#无法用yum安装" class="headerlink" title="无法用yum安装"></a>无法用yum安装</h4><p>==提示：file:///mnt/cdrom/repodata/repomd.xml: [Errno 14] Could not open/read file:/ ==    </p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d3cdc345d.png" alt=""><br><img src="https://ooo.0o0.ooo/2017/06/02/5930d4017be37.png" alt=""></p><h4 id="rz上传不成功-was-skipped"><a href="#rz上传不成功-was-skipped" class="headerlink" title="rz上传不成功 *was skipped"></a>rz上传不成功 *was skipped</h4><p>==权限不够==</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d442c03fa.png" alt=""></p><h4 id="使用tar命令解压-zip文件的时候，遇到如下异常"><a href="#使用tar命令解压-zip文件的时候，遇到如下异常" class="headerlink" title="使用tar命令解压.zip文件的时候，遇到如下异常"></a>使用tar命令解压.zip文件的时候，遇到如下异常</h4><pre><code>linuxidc@Ubuntu:~/Documents$ tar -xzvf wls1033_dev.zipgzip: stdin has more than one entry--rest ignoredtar: Child returned status 2tar: Error is not recoverable: exiting now</code></pre><p>==tar命令是调用了gunzip命令的，<br>对只有一个压缩内容的文件来解压的时候才用tar， 而如果压缩包里有多个文件被压缩了，<br>tar命令不能继续工作。可以采用unzip命令去解压。<br>先查看是否已安装unzip，没有安装的话下载unzip。<br>然后解压缩：==</p><pre><code>linuxidc@ubuntu:~/Documents$  unzip wls1033_dev,zip -d weblogic</code></pre><p>解压缩到当前文件夹下的weblogic文件夹下。</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d4430c194.png" alt=""></p><h4 id="设置变量的三种方法"><a href="#设置变量的三种方法" class="headerlink" title="设置变量的三种方法"></a>设置变量的三种方法</h4><p>1) 在/etc/profile文件中添加变量【对所有用户生效（永久的）】</p><p>用vi在文件/etc/profile文件中增加变量，该变量将会对Linux下所有用户有效，并且是“永久的”。</p><p>例如：编辑/etc/profile文件，添加CLASSPATH变量</p><pre><code>vi /etc/profileexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar;$JAVA_HOME/lib/dt.jar</code></pre><p>注：修改文件后要想马上生效还要运行# source /etc/profile不然只能在下次重进此用户时生效。</p><p>2) 在用户目录下的.bash_profile文件中增加变量【对单一用户生效（永久的）】</p><p>用VI在用户目录下的.bash_profile文件中增加变量，改变量仅会对当前用户有效，并且是“永久的”。</p><p>例如：编辑li用户目录（/home/li）下的.bashrc</p><pre><code>$ vi /home/li/.bashrc  </code></pre><p>添加如下内容：</p><pre><code>export CLASSPATH=.:$JAVA_HOME/lib/tools.jar;$JAVA_HOME/lib/dt.jar</code></pre><p>注：修改文件后要想马上生效还要运行$ source /home/li/.bashrc不然只能在下次重进此用户时生效。</p><p>3) 直接运行export命令定义变量【只对当前shell（BASH）有效（临时的）】</p><p>在shell的命令行下直接使用[export变量名=变量值]定义变量，该变量只在当前的shell（BASH）或其子shell（BASH）下是有效的，shell关闭了，变量也就失效了，再打开新shell时就没有这个变量，需要使用的话还需要重新定义。</p><h4 id="添加用户-赋予root权"><a href="#添加用户-赋予root权" class="headerlink" title="添加用户 赋予root权"></a>添加用户 赋予root权</h4><p>1、添加用户，首先用adduser命令添加一个普通用户，命令如下：</p><pre><code>#adduser tommy//添加一个名为tommy的用户#passwd tommy   //修改密码Changing password for user tommy.New UNIX password:     //在这里输入新密码Retype new UNIX password:  //再次输入新密码passwd: all authentication tokens updated successfully.</code></pre><p>2、赋予root权限</p><p>方法一：修改 /etc/sudoers 文件，找到下面一行，把前面的注释（#）去掉</p><pre><code>Allows people in group wheel to run all commands%wheel    ALL=(ALL)    ALL</code></pre><p>然后修改用户，使其属于root组（wheel），命令如下：</p><pre><code>#usermod -g root tommy</code></pre><p>修改完毕，现在可以用tommy帐号登录，然后用命令 su – ，即可获得root权限进行操作。</p><p>方法二：修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示：</p><pre><code>Allow root to run any commands anywhereroot    ALL=(ALL)     ALLtommy   ALL=(ALL)     ALL</code></pre><p>修改完毕，现在可以用tommy帐号登录，然后用命令 sudo – ，即可获得root权限进行操作。</p><p>方法三：修改 /etc/passwd 文件，找到如下行，把用户ID修改为 0 ，如下所示：</p><pre><code>tommy:x:0:33:tommy:/data/webroot:/bin/bash</code></pre><h4 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h4><h5 id="linux6"><a href="#linux6" class="headerlink" title="linux6"></a>linux6</h5><p>1) 重启后生效</p><pre><code>开启： chkconfig iptables on  关闭： chkconfig iptables off</code></pre><p>2) 即时生效，重启后失效service 方式</p><pre><code>开启： service iptables start  关闭： service iptables stop  </code></pre><h5 id="linux7"><a href="#linux7" class="headerlink" title="linux7"></a>linux7</h5><p>CentOS7这个版本的防火墙默认使用的是firewall，与之前的版本使用iptables不一样。按如下方便配置防火墙：<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、 查看防火墙状态</span><br><span class="line">    firewall-cmd    --state</span><br><span class="line">    关闭防火墙</span><br><span class="line">    systemctl  stop   firewalld.service</span><br><span class="line">    开启防火墙</span><br><span class="line">    systemctl  start   firewalld.service</span><br><span class="line"><span class="number">2</span>、关闭开机启动：systemctl disable firewalld.service</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>、安装iptables防火墙，执行以下命令安装iptables防火墙：yum install iptables-services  </span><br><span class="line">    开启iptables防火墙的命令是：</span><br><span class="line">    systemctl  start  iptables.service</span><br><span class="line">    重启iptables防火墙的命令是：</span><br><span class="line">    systemctl  restart  iptables.service</span><br><span class="line">    关闭iptables防火墙的命令是：</span><br><span class="line">    systemctl  stop  iptables.service</span><br><span class="line">    查看iptables防火墙状态的命令是：</span><br><span class="line">    systemctl  status  iptables.service</span><br></pre></td></tr></table></figure></p><h4 id="新增用户"><a href="#新增用户" class="headerlink" title="新增用户"></a>新增用户</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">新增用户</span><br><span class="line">[root@BDS-DATA2 kafka]<span class="comment"># useradd -g root -m yuanbo</span></span><br><span class="line">[root@BDS-DATA2 kafka]<span class="comment"># passwd yuanbo</span></span><br><span class="line">更改用户 yuanbo 的密码 。</span><br><span class="line">新的 密码：yuanbo</span><br><span class="line">无效的密码： 它基于字典单词</span><br><span class="line">无效的密码： 过于简单</span><br><span class="line">重新输入新的 密码：yuanbo</span><br><span class="line">passwd： 所有的身份验证令牌已经成功更新。</span><br><span class="line"></span><br><span class="line">修改sudo权限</span><br><span class="line">[root@BDS-CM config]<span class="comment"># vim /etc/sudoers</span></span><br><span class="line">在root    ALL=(ALL)       ALL下添加一行</span><br><span class="line">yuanbo  ALL=(ALL)       ALL</span><br></pre></td></tr></table></figure><h4 id="新增硬盘"><a href="#新增硬盘" class="headerlink" title="新增硬盘"></a>新增硬盘</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fdisk  /dev/sdb</span><br><span class="line">n</span><br><span class="line">p</span><br><span class="line">l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wq</span><br><span class="line"></span><br><span class="line">然后 再做文件系统   mkfs.ext3 /dev/sdb1</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">然后 vim  /etc/fstab </span><br><span class="line"></span><br><span class="line">看着上面的格式加一行 </span><br><span class="line">/dev/sdb1        /dataN        ext3      defaults    <span class="number">0</span>       <span class="number">0</span></span><br></pre></td></tr></table></figure><h4 id="关于分区"><a href="#关于分区" class="headerlink" title="关于分区"></a>关于分区</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[root@BDS <span class="keyword">data</span>3]<span class="comment"># fdisk /dev/sdb1</span></span><br><span class="line"></span><br><span class="line">Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabel</span><br><span class="line"></span><br><span class="line">Building a new DOS disklabel with disk identifier <span class="number">0</span>x0b32c3f6.</span><br><span class="line"></span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, <span class="keyword">until</span> you decide to write them.</span><br><span class="line"></span><br><span class="line">After that, of course, the previous content won<span class="string">'t be recoverable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">WARNING: DOS-compatible mode is deprecated. It'</span>s strongly recommended to</span><br><span class="line"><span class="keyword">switch</span> off the mode (command <span class="string">'c'</span>) and change display units to</span><br><span class="line">     sectors (command <span class="string">'u'</span>).</span><br><span class="line">     </span><br><span class="line">Command (m <span class="keyword">for</span> help): m</span><br><span class="line"></span><br><span class="line">Command action</span><br><span class="line">       <span class="comment">#切换一个可启动的标志</span></span><br><span class="line">   a   toggle a bootable flag</span><br><span class="line">       <span class="comment">#编辑bsd磁碟标签</span></span><br><span class="line">   b   edit bsd disklabel</span><br><span class="line">       <span class="comment">#切换dos兼容性标志</span></span><br><span class="line">   c   toggle the dos compatibility flag</span><br><span class="line">       <span class="comment">#删除一个分区</span></span><br><span class="line">   d   delete a partition</span><br><span class="line">       <span class="comment">#已知的分区类型列表</span></span><br><span class="line">   l   list known partition types</span><br><span class="line">       <span class="comment">#打印这个菜单</span></span><br><span class="line">   m   print this menu</span><br><span class="line">       <span class="comment">#添加一个新的分区</span></span><br><span class="line">   n   add a new partition</span><br><span class="line">       <span class="comment">#创建一个新的空DOS分区表</span></span><br><span class="line">   o   create a new empty DOS partition table</span><br><span class="line">       <span class="comment">#打印分区表</span></span><br><span class="line">   p   print the partition table</span><br><span class="line">       <span class="comment">#退出不保存更改</span></span><br><span class="line">   q   quit without saving changes</span><br><span class="line">       <span class="comment">#创建一个新的空的Sun disklabel</span></span><br><span class="line">   s   create a new empty Sun disklabel</span><br><span class="line">       <span class="comment">#更改分区的系统id</span></span><br><span class="line">   t   change a partition<span class="string">'s system id</span></span><br><span class="line"><span class="string">       #改变显示/输入单元</span></span><br><span class="line"><span class="string">   u   change display/entry units</span></span><br><span class="line"><span class="string">       #验证分区表</span></span><br><span class="line"><span class="string">   v   verify the partition table</span></span><br><span class="line"><span class="string">       #将表写入磁盘并退出</span></span><br><span class="line"><span class="string">   w   write table to disk and exit</span></span><br><span class="line"><span class="string">       #额外的功能(专家)</span></span><br><span class="line"><span class="string">   x   extra functionality (experts only)</span></span><br></pre></td></tr></table></figure><h4 id="查看某一端口的占用情况：-lsof-i-端口号"><a href="#查看某一端口的占用情况：-lsof-i-端口号" class="headerlink" title="查看某一端口的占用情况： lsof -i:端口号"></a>查看某一端口的占用情况： lsof -i:端口号</h4><h4 id="centos6-7设置开机启动命令界面"><a href="#centos6-7设置开机启动命令界面" class="headerlink" title="centos6.7设置开机启动命令界面"></a>centos6.7设置开机启动命令界面</h4><p>开机后进入图形化界面还是进入命令行取决于inittab文件中的配置。该文件位于etc目录下。<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#vim /etc/inittab</span></span><br><span class="line"></span><br><span class="line">id:<span class="number">5</span>:initdefault:(默认的 run level 等级为 <span class="number">5</span>,即图形 界面)</span><br><span class="line">将 <span class="number">5</span> 修改为 <span class="number">3</span> 即可。</span><br></pre></td></tr></table></figure></p><p>保存文件后重启系统你就可以看见是启动的文本界面了。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>linux里挂载（mount）和取消挂载（umount）命令的使用</title>
      <link href="/2018/05/02/linux%E9%87%8C%E6%8C%82%E8%BD%BD%EF%BC%88mount%EF%BC%89%E5%92%8C%E5%8F%96%E6%B6%88%E6%8C%82%E8%BD%BD%EF%BC%88umount%EF%BC%89%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2018/05/02/linux%E9%87%8C%E6%8C%82%E8%BD%BD%EF%BC%88mount%EF%BC%89%E5%92%8C%E5%8F%96%E6%B6%88%E6%8C%82%E8%BD%BD%EF%BC%88umount%EF%BC%89%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="一、简单用法"><a href="#一、简单用法" class="headerlink" title="一、简单用法"></a>一、简单用法</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mount /dev/hda2 /home</span><br></pre></td></tr></table></figure><p>第一个叁数是与包括文件系统的磁盘或分区相关的设备文件。<br>第二个叁数是要mount到的目录。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ umount /dev/hda2</span><br><span class="line">$ umount /usr</span><br></pre></td></tr></table></figure><p>参数可以是设备文件或安装点。</p><h3 id="二、mount详细介绍"><a href="#二、mount详细介绍" class="headerlink" title="二、mount详细介绍"></a>二、mount详细介绍</h3><p>如果想在运行的Linux下访问其它文件系统中的资源的话，就要用mount命令来实现。</p><p> <strong>1.    mount的基本用法是？</strong></p><p>格式：<strong>mount [-参数] [设备名称] [挂载点]</strong></p><p>其中常用的参数有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">-a 安装在/etc/fstab文件中类出的所有文件系统。</span><br><span class="line"></span><br><span class="line">-f 伪装mount，作出检查设备和目录的样子，但并不真正挂载文件系统。</span><br><span class="line"></span><br><span class="line">-n 不把安装记录在/etc/mtab文件中。</span><br><span class="line"></span><br><span class="line">-r 讲文件系统安装为只读。</span><br><span class="line"></span><br><span class="line">-v 详细显示安装信息。</span><br><span class="line"></span><br><span class="line">-w 将文件系统安装为可写，为命令默认情况。</span><br><span class="line"></span><br><span class="line">-t 指定设备的文件系统类型，常见的有：</span><br><span class="line"></span><br><span class="line">ext2  linux目前常用的文件系统</span><br><span class="line"></span><br><span class="line">msdos   MS-DOS的fat，就是fat16</span><br><span class="line"></span><br><span class="line">vfat   windows98常用的fat32</span><br><span class="line"></span><br><span class="line">nfs   网络文件系统</span><br><span class="line"></span><br><span class="line">iso9660   CD-ROM光盘标准文件系统</span><br><span class="line"></span><br><span class="line">ntfs   windows NT/2000/XP的文件系统</span><br><span class="line"></span><br><span class="line">auto 自动检测文件系统</span><br><span class="line"></span><br><span class="line">-o 指定挂载文件系统时的选项，有些也可写到在/etc/fstab中。常用的有：</span><br><span class="line"></span><br><span class="line">defaults 使用所有选项的默认值（auto、nouser、rw、suid）</span><br><span class="line"></span><br><span class="line">auto/noauto 允许/不允许以 –a选项进行安装</span><br><span class="line"></span><br><span class="line">dev/nodev 对/不对文件系统上的特殊设备进行解释</span><br><span class="line"></span><br><span class="line">exec/noexec 允许/不允许执行二进制代码</span><br><span class="line"></span><br><span class="line">suid/nosuid 确认/不确认suid和sgid位</span><br><span class="line"></span><br><span class="line">user /nouser 允许/不允许一般用户挂载</span><br><span class="line"></span><br><span class="line">codepage=XXX 代码页</span><br><span class="line"></span><br><span class="line">iocharset=XXX 字符集</span><br><span class="line"></span><br><span class="line">ro 以只读方式挂载</span><br><span class="line"></span><br><span class="line">rw 以读写方式挂载</span><br><span class="line"></span><br><span class="line">remount 重新安装已经安装了的文件系统</span><br><span class="line"></span><br><span class="line">loop 挂载回旋设备</span><br></pre></td></tr></table></figure><p>需要注意的是，挂载点必须是一个已经存在的目录，这个目录可以不为空，但挂载后这个目录下以前的内容将不可用，umount以后会恢复正常。使用多个-o参数的时候，-o只用一次，参数之间用半角逗号隔开：<br><code># mount –o remount,rw /</code></p><p>例如要挂载windows下文件系统为FAT32的D盘，一般而言在Linux下这个分区对应/dev/hda5，根据具体的分区情况会有不同，这里就以hda5来举例说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># mkdir /mnt/hda5   //创建hda5的目录作为挂载点，位置和目录名可自定义//</span><br><span class="line"></span><br><span class="line"># mount -t vfat /dev/hda5 /mnt/hda5</span><br></pre></td></tr></table></figure><p>一般而言，Linux会自动探测分区的文件系统，除非让你指定时，否则-t vfat 可以省掉。<br><code># mount /dev/hda5 /mnt/hda5</code></p><p>这样就可以进入/mnt/hda5目录去访问分区中的资源了。</p><p><strong>2.    为什么mount上分区后显示不了中文文件为问号/乱码？</strong></p><p>显 示问号表明你的系统中没有可识别使用的中文字体，请先安装中文字体。确保你的系统已经可以很好的显示中文。显示为乱码一般是mount默认使用的文件系统 编码和文件系统中文件的实际编码不一致造成的。要想正常显示中文文件，mount时需要用到 -o 参数里的codepage和iocharset选项。codepage指定文件系统的代码页，简体中文中文代码是936；iocharset指定字符集，简体中文一般用cp936或gb2312。</p><p><code># mount –o iocharset=gb2312 codepage=936 /dev/hda5 /mnt/hda5</code></p><p>一般来说 mount –o iocharset=cp936 /dev/hda5 /mnt/hda5 就可以解决问题了。</p><p>如果这样做了以后还有问题，请尝试UTF-8编码：<br>CODE:<br><code># mount –o iocharset=utf8 /dev/hda5 /mnt/hda5</code></p><p><strong>3.    为什么mount上去以后分区普通用户不可写？</strong></p><p>mount时加上 –oumask=000 即可：<br>CODE:<br><code># mount –o umask=000, iocharset=cp936 /dev/hda5 /mnt/hda5</code></p><p><strong>4.    为什么mount上去后的分区中的文件都变成短文件名了？</strong></p><p>这是文件系统挂错的原因，将FAT32挂载成FAT16时就会出现这种情况，先umount，然后用–t vfat 重新挂载即可解决问题。<br>CODE:<br><code># mount –t vat /dev/hda5 /mnt/hda5</code></p><p><strong>5.    为什么不能mount ntfs分区？</strong></p><p>这是内核不支持NTFS文件系统的原因，请重新编译内核或者安装内核的NTFS文件系统支持包，以使得内核有NTFS文件系统的支持。</p><p><strong>6.    如何挂载U盘和mp3？</strong></p><p>如果计算机没有其它SCSI设备和usb外设的情况下，插入的U盘的设备路径是 /dev/sda1，用命令：</p><p># mkdir /mnt/u</p><p># mount /dev/sda1 /mnt/u</p><p>挂载即可。</p><p><strong>7.    可以直接使用iso文件吗？</strong></p><p>可以，就是mount的这一选项使得Linux下有免费虚拟光驱的说法，具体用法是：</p><p># mkdir /mnt/iso</p><p># mount –o loop linux.iso /mnt/iso</p><p>当然，挂载以后挂载点/mnt/iso也是只读的。 </p><p><strong>8.    我怎么不可以mount iso文件？</strong></p><p>一般而言，大多数的发行版使用的内核均已将loop设备的支持编译进去了，但是也有没有的情况，所以请确保系统所使用的内核支持loop设备。</p><p>第二种情况是iso文件被放置到了NTFS或其它只读文件系统中了。挂载loop 设备必须要求挂载到一个可写的分区中，目前Linux内核对NTFS文件系统的写支持非常有限，请将iso文件复制到其它可写文件系统中后再挂载。</p><p><strong>9.  如何挂载光驱和软驱</strong></p><p>一般来说CDROM的设备文件是/dev/hdc，软驱的设备名是/dev/fd0<br>CODE:<br># mkdir /mnt/cdrom</p><p># mount /dev/hdc /mnt/cdrom //挂载光驱 //</p><p># mkdir /mnt/floppy </p><p># mount /dev/fd0 /mnt/floppy //挂载软驱 //</p><p><strong>10.   为何挂载的CD-ROM不能显示中文文件？</strong></p><p>使用 –o iocharset=cp936 选项一般能解决问题，否则使用utf-8编码。<br><code># mount –o iocharset=cp936 /dev/hdc /mnt/cdrom</code></p><p><strong>11.   如何开机自动挂载分区？</strong></p><p>每次挂载都要输入那么长的命令的确是繁琐了些，只要将分区信息写到/etc/fstab文件中即可实现系统启动的自动挂载，例如对于/dev/hda5的自动挂载添加如下的行即可：<br><code>/dev/hda5 /mnt/hda5 vfat defaults,iocharset=cp936, rw 0 0</code></p><p><strong>12.   如何挂载samba 分区？</strong><br><code># mkdir /mnt/share</code></p><p><code># mount -t smbfs -ousername=root,password=abc,codepage=936,iocharset=gb2312//192.168.1.100/share   /mnt/share</code></p><p>如果中文显示不正常请尝试UTF-8编码。当然可以写到fstab中实现自动挂载。</p><p><strong>13.   mount–bind是什么意思？</strong></p><p>mount –bind 是将一个目录中的内容挂载到另一个目录上，用法是<br>CODE:<br><code># mount --bind olddir newdir</code></p><p>这个命令使得自己搭建的FTP要共享某个目录的时候变得特别方便。如果要取消mount用命令：<br><code># mount --move olddir newdir 即可。</code></p><p>如果mount –bind 也想写入fstab中的话格式如下：<br><code>olddir newdir none bind 0 0</code></p><h3 id="三、-umount基本用法"><a href="#三、-umount基本用法" class="headerlink" title="三、 umount基本用法"></a>三、 umount基本用法</h3><p>比如 /dev/hda5 已经挂载在/mnt/hda5上,用一下三条命令均可卸载挂载的文件系统</p><p><code># umount /dev/hda5</code></p><p><code># umount /mnt/hda5</code></p><p><code># umount /dev/hda5 /mnt/hda5</code></p><ol start="16"><li>为什么umount的时候老显示 device busy？</li></ol><p>这是因为有程序正在访问这个设备，最简单的办法就是让访问该设备的程序退出以后再umount。可能有时候用户搞不清除究竟是什么程序在访问设备，如果用户不急着umount，则可以用:</p><p><code>#umount -l /mnt/hda5</code></p><p>来卸载设备。选项 –l 并不是马上umount，而是在该目录空闲后再umount。还可以先用命令ps aux 来查看占用设备的程序PID，然后用命令kill来杀死占用设备的进程，这样就umount的非常放心了。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>tomcat远程调试</title>
      <link href="/2018/05/02/tomcat%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"/>
      <url>/2018/05/02/tomcat%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/</url>
      <content type="html"><![CDATA[<p>[toc]</p><p><strong>1、Linux中配置tomcat在catalina.sh中添加如下</strong><br><code>CATALINA_OPTS=&quot;-server-Xdebug -Xnoagent -Djava.compiler=NONE-Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5888&quot;</code></p><p><strong>2、Window中修改 catalina,bat文件，添加：</strong></p><p><code>Set  “CATALINA_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n&quot;</code></p><p>如图：<br><img src="http://osapnihnq.bkt.clouddn.com/blog/180502/AC715l16md.png?imageslim" alt="mark"></p><p>远程调试参数说明：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-Xdebug                             ： 启用调试模式</span><br><span class="line"></span><br><span class="line">-Xrunjdwp&lt;sub-options&gt;  : 加载JVM的JPDA参考实现库</span><br><span class="line"></span><br><span class="line">transport=dt_socket          ：Socket连接，可选dt_shmem 通过共享内存的方式连接到调试服务器</span><br><span class="line"></span><br><span class="line">address=<span class="number">8000</span>                    ：调试服务器监听的端口</span><br><span class="line"></span><br><span class="line">server=y                            ： 是否是服务器端，n为客户端</span><br><span class="line"></span><br><span class="line">suspend=n                        ： 启动过程是否加载暂停，y为启动时暂停，方便调试启动过程</span><br></pre></td></tr></table></figure><p><strong>3**</strong>、启动<strong><strong>tomcat</strong></strong>，看看<strong><strong>tomcat</strong></strong>是否启动成功，**</p><p>如果启动成功，tomcat日志文件(catalina.out)中会有如下输出：</p><p>Listening for transport dt_socket at address: 8000</p><p><strong>4**</strong>、使用<strong><strong>eclipse</strong></strong>调试：**</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180502/Gm4e4AIljF.png?imageslim" alt="mark"></p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180502/eDJh33JbmB.png?imageslim" alt="mark"></p><p>点击debug，就可进行调试了</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180502/6LhCK98ibh.png?imageslim" alt="mark"></p><p>剩下的就和普通调试一样了。断点直接在源代码中添加就行</p><p><strong>5**</strong>、可能出现的连接问题：**</p><p>Failed to connect to remote VM. Connection refused.</p><p>Connection refused: connect。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180502/fk45KAIcif.png?imageslim" alt="mark"></p><p>出现如图所示的情况可能是已经建立了一个连接了。</p><p>解决方法：去debug透视图中<img src="http://osapnihnq.bkt.clouddn.com/blog/180502/CJmhea511A.png?imageslim" alt="mark"></p><p>找到点击<img src="http://osapnihnq.bkt.clouddn.com/blog/180502/blf9BLB9CI.png?imageslim" alt="mark">断开链接，就可以解决问题了。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>J.U.C-原子操作</title>
      <link href="/2018/05/02/J.U.C-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/05/02/J.U.C-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h4 id="完整的类库结构"><a href="#完整的类库结构" class="headerlink" title="完整的类库结构"></a>完整的类库结构</h4><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180119/HdkeleJimJ.png?imageslim" alt="mark"></p><h4 id="原子操作-part-1"><a href="#原子操作-part-1" class="headerlink" title="原子操作 part 1"></a>原子操作 part 1</h4><blockquote><p>通常情况下，在Java里面，++i或者–i不是线程安全的，这里面有三个独立的操作：获取变量当前值，为该值+1/-1，然后写回新的值。在没有额外资源可以利用的情况下，只能使用加锁才能保证读-改-写这三个操作时“原子性”的。</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">一切从java.util.concurrent.atomic.AtomicInteger开始。</span><br><span class="line"></span><br><span class="line">int addAndGet(int delta)</span><br><span class="line">          以原子方式将给定值与当前值相加。 实际上就是等于线程安全版本的i =i+delta操作。参考下图<span class="number">1</span>。</span><br><span class="line"></span><br><span class="line">boolean compareAndSet(int expect, int update)</span><br><span class="line">          如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 如果成功就返回true，否则返回false，并且不修改原值。</span><br><span class="line"></span><br><span class="line">int decrementAndGet()</span><br><span class="line">          以原子方式将当前值减 <span class="number">1</span>。 相当于线程安全版本的--i操作。</span><br><span class="line"></span><br><span class="line">int get()</span><br><span class="line">          获取当前值。</span><br><span class="line"></span><br><span class="line">int getAndAdd(int delta)</span><br><span class="line">          以原子方式将给定值与当前值相加，返回值为定值过去值。 相当于线程安全版本的t=i;i+=delta;<span class="keyword">return</span> t;操作。参考下图<span class="number">1</span>。</span><br><span class="line"></span><br><span class="line">int getAndDecrement()</span><br><span class="line">          以原子方式将当前值减 <span class="number">1</span>。 相当于线程安全版本的i--操作。</span><br><span class="line"></span><br><span class="line">int getAndIncrement()</span><br><span class="line">          以原子方式将当前值加 <span class="number">1</span>。 相当于线程安全版本的i++操作。类似getAndAdd().</span><br><span class="line"></span><br><span class="line">int getAndSet(int newValue)</span><br><span class="line">          以原子方式设置为给定值，并返回旧值。 相当于线程安全版本的t=i;i=newValue;<span class="keyword">return</span> t;操作。</span><br><span class="line"></span><br><span class="line">int incrementAndGet()</span><br><span class="line">          以原子方式将当前值加 <span class="number">1</span>。 相当于线程安全版本的++i操作。 类似addAndGet().</span><br><span class="line">          </span><br><span class="line">void lazySet(int newValue)</span><br><span class="line">          最后设置为给定值。 延时设置变量值，这个等价于set()方法，但是由于字段是volatile类型的，因此次字段的修改会比普通字段（非volatile字段）有稍微的性能延时（尽管可以忽略），所以如果不是想立即读取设置的新值，允许在“后台”修改值，那么此方法就很有用。如果还是难以理解，这里就类似于启动一个后台线程如执行修改新值的任务，原线程就不等待修改结果立即返回（这种解释其实是不正确的，但是可以这么理解）。</span><br><span class="line"></span><br><span class="line">void set(int newValue)</span><br><span class="line">          设置为给定值。 直接修改原始值，也就是i=newValue操作。</span><br><span class="line"></span><br><span class="line">boolean weakCompareAndSet(int expect, int update)</span><br><span class="line">          如果当前值 == 预期值，则以原子方式将该设置为给定的更新值。JSR规范中说：以原子方式读取和有条件地写入变量但不 创建任何 happen-before 排序，因此不提供与除 weakCompareAndSet 目标外任何变量以前或后续读取或写入操作有关的任何保证。大意就是说调用weakCompareAndSet时并不能保证不存在happen-before的发生（也就是可能存在指令重排序导致此操作失败）。但是从Java源码来看，其实此方法并没有实现JSR规范的要求，最后效果和compareAndSet是等效的，都调用了unsafe.compareAndSwapInt()完成操作。</span><br></pre></td></tr></table></figure><p><code>图①</code></p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180122/2mCl38EaAB.png?imageslim" alt="mark"></p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>J.U.C-线程池</title>
      <link href="/2018/05/02/J.U.C-%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
      <url>/2018/05/02/J.U.C-%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
      <content type="html"><![CDATA[<p>[TOC]</p><blockquote><p>下图描述的是线程池API的一部分。广义上的完整线程池可能还包括Thread/Runnable、Timer/TimerTask等部分。这里只介绍主要的和高级的API以及架构和原理。</p></blockquote><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180122/jm79K9I6ae.png?imageslim" alt="mark"></p><p>大多数并发应用程序是围绕执行任务（Task）进行管理的。所谓任务就是抽象、离散的工作单元（unit of work）。把一个应用程序的工作（work）分离到任务中，可以简化程序的管理；这种分离还在不同事物间划分了自然的分界线，可以方便程序在出现错误时进行恢复；同时这种分离还可以为并行工作提供一个自然的结构，有利于提高程序的并发性。</p><p>并发执行任务的一个很重要前提是拆分任务。把一个大的过程或者任务拆分成很多小的工作单元，每一个工作单元可能相关、也可能无关，这些单元在一定程度上可以充分利用CPU的特性并发的执行，从而提高并发性（性能、响应时间、吞吐量等）。</p><p>所谓的任务拆分就是确定每一个执行任务（工作单元）的边界。理想情况下独立的工作单元有最大的吞吐量，这些工作单元不依赖于其它工作单元的状态、结果或者其他资源等。因此将任务尽可能的拆分成一个个独立的工作单元有利于提高程序的并发性。</p><p>对于有依赖关系以及资源竞争的工作单元就涉及到任务的调度和负载均衡。工作单元的状态、结果或者其他资源等有关联的工作单元就需要有一个总体的调度者来协调资源和执行顺序。同样在有限的资源情况下，大量的任务也需要一个协调各个工作单元的调度者。这就涉及到任务执行的策略问题。</p><p>任务的执行策略包括4W3H部分：</p><ul><li>任务在什么（What）线程中执行</li><li>任务以什么（What）顺序执行（FIFO/LIFO/优先级等）</li><li>同时有多少个（How Many）任务并发执行</li><li>允许有多少个（How Many）个任务进入执行队列</li><li>系统过载时选择放弃哪一个（Which）任务，如何（How）通知应用程序这个动作</li><li>任务执行的开始、结束应该做什么（What）处理</li></ul><p>在后面会详细分写这些策略是如何实现的。我们先来简单回答些如何满足上面的条件。</p><ol><li>首先明确一定是在Java里面可以供使用者调用的启动线程类是Thread。因此Runnable或者Timer/TimerTask等都是要依赖Thread来启动的，因此在ThreadPool里面同样也是靠Thread来启动多线程的。</li><li>默认情况下Runnable接口执行完毕后是不能拿到执行结果的，因此在ThreadPool里就定义了一个Callable接口来处理执行结果。</li><li>为了异步阻塞的获取结果，Future可以帮助调用线程获取执行结果。</li><li>Executor解决了向线程池提交任务的入口问题，同时ScheduledExecutorService解决了如何进行重复调用任务的问题。</li><li>CompletionService解决了如何按照执行完毕的顺序获取结果的问题，这在某些情况下可以提高任务执行的并发，调用线程不必在长时间任务上等待过多时间。</li><li>显然线程的数量是有限的，而且也不宜过多，因此合适的任务队列是必不可少的，BlockingQueue的容量正好可以解决此问题。</li><li>固定任务容量就意味着在容量满了以后需要一定的策略来处理过多的任务（新任务），RejectedExecutionHandler正好解决此问题。</li><li>一定时间内阻塞就意味着有超时，因此TimeoutException就是为了描述这种现象。TimeUnit是为了描述超时时间方便的一个时间单元枚举类。</li><li>有上述问题就意味了配置一个合适的线程池是很复杂的，因此Executors默认的一些线程池配置可以减少这个操作。</li></ol><blockquote><p>Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。</p></blockquote><blockquote><p>下面这张图完整描述了线程池的类体系结构</p></blockquote><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180202/KE6l6bK5im.png?imageslim" alt="mark"></p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java 异常处理的 9 个最佳实践</title>
      <link href="/2018/05/02/Java%20%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E7%9A%84%209%20%E4%B8%AA%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
      <url>/2018/05/02/Java%20%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E7%9A%84%209%20%E4%B8%AA%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><p>在 Java 中，异常处理是个很麻烦的事情。初学者觉得它很难理解，甚至是经验丰富的开发者也要花费很长时间决定异常是要处理掉和抛出。</p><p>所以很多开发团队约定一些原则处理异常。如果你是一个团队的新成员，你可能会很惊讶，因为他们约定的规则可能和你以前使用的规则不一样。</p><p>不过，有很多最佳实践的规则，被大部分团队接受。这里有 9 大重要的约定，帮助你学习或者改进异常处理。</p><hr><h4 id="1、在-Finally-清理资源或者使用-Try-With-Resource-特性"><a href="#1、在-Finally-清理资源或者使用-Try-With-Resource-特性" class="headerlink" title="1、在 Finally 清理资源或者使用 Try-With-Resource 特性"></a><strong>1、在 Finally 清理资源或者使用 Try-With-Resource 特性</strong></h4><p>大部分情况下，在 try 代码块中使用资源后需要关闭资源，例如 <em>InputStream 。</em>在这些情况下，一种常见的失误就是在 try 代码块的最后关闭资源。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/d4lgFlj12g.png?imageslim" alt="mark"></p><p>问题就是，只有没有异常抛出的时候，这段代码才可以正常工作。try 代码块内代码会正常执行，并且资源可以正常关闭。但是，使用 try 代码块是有原因的，一般调用一个或多个可能抛出异常的方法，而且，你自己也可能会抛出一个异常，这意味着代码可能不会执行到 try 代码块的最后部分。结果就是，你并没有关闭资源。</p><p>所以，你应该把清理工作的代码放到 finally 里去，或者使用 try-with-resource 特性。</p><p>与前面几行 try 代码块不同，finally 代码块总是会被执行。不管 try 代码块成功执行之后还是你在 catch 代码块中处理完异常后都会执行。因此，你可以确保你清理了所有打开的资源。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/9Cggk2041E.png?imageslim" alt="mark"></p><h5 id="Java-7-的-Try-With-Resource-语法"><a href="#Java-7-的-Try-With-Resource-语法" class="headerlink" title="Java 7 的 Try-With-Resource 语法"></a><strong>Java 7 的 Try-With-Resource 语法</strong></h5><p>另一个可选的方案是 try-with-resource 语法，我在<a href="https://stackify.com/specify-handle-exceptions-java/#tryWithResource" target="_blank" rel="noopener">介绍 Java 的异常处理</a>里更详细的介绍了它。</p><p>如果你的资源实现了 <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/AutoCloseable.html" target="_blank" rel="noopener">AutoCloseable</a> 接口，你可以使用这个语法。大多数的 Java 标准资源都继承了这个接口。当你在 try 子句中打开资源，资源会在 try 代码块执行后或异常处理后自动关闭。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/m13dDJEF60.png?imageslim" alt="mark"></p><h4 id="2、优先明确异常"><a href="#2、优先明确异常" class="headerlink" title="2、优先明确异常"></a><strong>2、优先明确异常</strong></h4><p>你抛出的异常越明确越好，永远记住，你的同事或者几个月之后的你，将会调用你的方法并且处理异常。</p><p>因此需要保证提供给他们尽可能多的信息。这样你的 API 更容易被理解。你的方法的调用者能够更好的处理异常并且避免<a href="https://stackify.com/top-java-software-errors/" target="_blank" rel="noopener">额外的检查</a>。</p><p>因此，总是尝试寻找最适合你的异常事件的类，例如，抛出一个 <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/NumberFormatException.html" target="_blank" rel="noopener">NumberFormatException</a> 来替换一个 <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/IllegalArgumentException.html" target="_blank" rel="noopener">IllegalArgumentException</a> 。避免抛出一个不明确的异常。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/bFIaFglGCb.png?imageslim" alt="mark"></p><h4 id="3、记录指定的异常"><a href="#3、记录指定的异常" class="headerlink" title="3、记录指定的异常"></a><strong>3、记录指定的异常</strong></h4><p>每当你在方法签名中<a href="https://stackify.com/specify-handle-exceptions-java/#specify" target="_blank" rel="noopener">指定异常</a>，你也应该在 <a href="http://blog.joda.org/2012/11/javadoc-coding-standards.html" target="_blank" rel="noopener">Javadoc 中记录它</a>。 这与上一个最佳实践具有相同的目标：尽可能多地向调用者提供信息，以便避免或处理异常。</p><p>因此，请确保向 Javadoc 添加 @throws 声明并描述可能导致异常的情况。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/aAJIGJA16D.png?imageslim" alt="mark"></p><h4 id="4、使用描述性消息抛出异常"><a href="#4、使用描述性消息抛出异常" class="headerlink" title="4、使用描述性消息抛出异常"></a><strong>4、使用描述性消息抛出异常</strong></h4><p>这个最佳实践背后的想法与前两个类似。但这一次，你不会将信息提供给方法的调用者。每个必须了解在日志文件或监视工具中报告异常情况时发生了什么情况的人都可以读取异常消息。</p><p>因此，应该尽可能精确地描述问题，并提供最相关的信息来了解异常事件。</p><p>不要误会我的意思，你不用去写一段文字。但你也应该在1-2个短句中解释异常的原因。这有助于你的运营团队了解问题的严重性，并且还可以让你更轻松地分析任何服务突发事件。</p><p>如果抛出一个特定的异常，它的类名很可能已经描述了这种错误。所以，你不需要提供很多额外的信息。一个很好的例子是 NumberFormatException 。当你以错误的格式提供 String 时，它将被 java.lang.Long 类的构造函数抛出。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/HfBLkJB8ii.png?imageslim" alt="mark"></p><p>NumberFormatException 类的名称已经告诉你这种问题。它的消息表示只需要提供导致问题的输入字符串。如果异常类的名称不具有表达性，则需要在消息中提供所需的信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">17</span>:<span class="number">17</span>:<span class="number">26</span>,<span class="number">386</span> ERROR TestExceptionHandling:<span class="number">52</span> - java.lang.NumberFormatException: For input string: <span class="string">"xyz"</span></span><br></pre></td></tr></table></figure><h4 id="5、优先捕获最具体的异常"><a href="#5、优先捕获最具体的异常" class="headerlink" title="5、优先捕获最具体的异常"></a><strong>5、优先捕获最具体的异常</strong></h4><p>大多数 IDE 都可以帮助你实现这个最佳实践。当你尝试首先捕获较不具体的异常时，它们会报告无法访问的代码块。</p><p>但问题在于，只有匹配异常的第一个 catch 块会被执行。 因此，如果首先捕获 IllegalArgumentException ，则永远不会到达应该处理更具体的 NumberFormatException 的 catch 块，因为它是 IllegalArgumentException 的子类。</p><p>总是优先捕获最具体的异常类，并将不太具体的 catch 块添加到列表的末尾。</p><p>你可以在下面的代码片断中看到这样一个 try-catch 语句的例子。 第一个 catch 块处理所有 NumberFormatException 异常，第二个处理所有非 NumberFormatException 异常的  IllegalArgumentException 异常。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/bH44h3mG59.png?imageslim" alt="mark"></p><h4 id="6、不要捕获-Throwable-类"><a href="#6、不要捕获-Throwable-类" class="headerlink" title="6、不要捕获 Throwable 类"></a><strong>6、不要捕获 Throwable 类</strong></h4><p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Throwable.html" target="_blank" rel="noopener">Throwable</a><em> </em>是所有异常和错误的超类。你可以在 catch 子句中使用它，但是你永远不应该这样做！</p><p>如果在 catch 子句中使用 Throwable ，它不仅会捕获所有异常，也将捕获所有的错误。JVM 抛出错误，指出不应该由应用程序处理的严重问题。 典型的例子是 <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/OutOfMemoryError.html" target="_blank" rel="noopener">OutOfMemoryError</a> 或者 <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/StackOverflowError.html" target="_blank" rel="noopener">StackOverflowError</a> 。 两者都是由应用程序控制之外的情况引起的，无法处理。</p><p>所以，最好不要捕获 Throwable ，除非你确定自己处于一种特殊的情况下能够处理错误。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/28LK4B0Jbh.png?imageslim" alt="mark"></p><h4 id="7、不要忽略异常"><a href="#7、不要忽略异常" class="headerlink" title="7、不要忽略异常"></a><strong>7、不要忽略异常</strong></h4><p>你曾经有去分析过一个只执行了你用例的第一部分的 bug 报告吗？</p><p>这通常是由于一个被忽略的异常造成的。开发者可能会非常肯定，它永远不会被抛出，并添加一个 catch 块，不做处理或不记录它。而当你发现这个块时，你很可能甚至会发现其中有一个“这永远不会发生”的注释。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/i8m6cIEAc9.png?imageslim" alt="mark"></p><p>那么，你可能正在分析一个不可能发生的问题。</p><p>所以，请不要忽略任何一个异常。 你不知道代码将来如何改变。有人可能会在没有意识到会造成问题的情况下，删除阻止异常事件的验证。或者是抛出异常的代码被改变，现在抛出同一个类的多个异常，而调用的代码并不能阻止所有异常。</p><p>你至少应该写一条日志信息，告诉大家这个不可思议的事发生了，而且有人需要检查它。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/d5C2DGjCfH.png?imageslim" alt="mark"></p><h4 id="8、不要记录日志和抛出错误"><a href="#8、不要记录日志和抛出错误" class="headerlink" title="8、不要记录日志和抛出错误"></a><strong>8、不要记录日志和抛出错误</strong></h4><p>这可能是该文章中最常被忽略的最佳实践。 你可以找到很多的其中有一个异常被捕获的代码片段，甚至是一些代码库，被记录和重新抛出。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/EKH0A37J30.png?imageslim" alt="mark"></p><p>在发生异常时记录异常可能会感觉很直观，然后重新抛出异常，以便调用者可以适当地处理异常。但它会为同一个异常重复写入多个错误消息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">17</span>:<span class="number">44</span>:<span class="number">28</span>,<span class="number">945</span> ERROR TestExceptionHandling:<span class="number">65</span> - java.lang.NumberFormatException: For input string: <span class="string">"xyz"</span></span><br><span class="line">Exception in thread <span class="string">"main"</span> java.lang.NumberFormatException: For input string: <span class="string">"xyz"</span></span><br><span class="line">at java.lang.NumberFormatException.forInputString(NumberFormatException.java:<span class="number">65</span>)</span><br><span class="line">at java.lang.Long.parseLong(Long.java:<span class="number">589</span>)</span><br><span class="line">at java.lang.Long.(Long.java:<span class="number">965</span>)</span><br><span class="line">at com.stackify.example.TestExceptionHandling.logAndThrowException(TestExceptionHandling.java:<span class="number">63</span>)</span><br><span class="line">at com.stackify.example.TestExceptionHandling.main(TestExceptionHandling.java:<span class="number">58</span>)</span><br></pre></td></tr></table></figure><p>附加消息也不会添加任何信息。正如在最佳实践＃4中所解释的那样，异常消息应该描述异常事件。 堆栈跟踪告诉你在哪个类，方法和行中抛出异常。</p><p>如果你需要添加其他信息，则应该捕获异常并将其包装在自定义的信息中。 但请务必遵循最佳实践9。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/LdgLJB9G29.png?imageslim" alt="mark"></p><p>所以，只捕获你想处理的异常。 否则，在方法签名中指定它，并让调用者处理它。</p><h4 id="9、封装好的异常类而不使用"><a href="#9、封装好的异常类而不使用" class="headerlink" title="9、封装好的异常类而不使用"></a><strong>9、封装好的异常类而不使用</strong></h4><p>有时候，最好是捕获一个标准异常并将其封装成一定制的异常。一个典型的例子是应用程序或框架特定的业务异常。允许你添加些额外的信息，并且你也可以为你的异常类实现一个特殊的处理。</p><p>在你这样做时，请确保将原始异常设置为原因（注：参考下方代码 NumberFormatException e 中的原始异常 e ）。<em>Exception </em>类提供了特殊的构造函数方法，它接受一个 <em>Throwable </em>作为参数。另外，你将会丢失堆栈跟踪和原始异常的消息，这将会使分析导致异常的异常事件变得困难。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180308/B37m2l50ga.png?imageslim" alt="mark"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>如你所见，当你抛出或捕获异常的时候，有很多不同的事情需要考虑，而且大部分事情都是为了改善代码的可读性或者 API 的可用性。</p><p>异常通常都是一种异常处理技巧，同时也是一种通信媒介。因此，为了和同事更好的合作，一个团队必须要制定出一个最佳实践和规则，只有这样团队成员才能理解这些通用概念，同时在工作中使用它。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>CentOS 6.7yum安装mysql</title>
      <link href="/2018/05/02/CentOS%206.7yum%E5%AE%89%E8%A3%85mysql/"/>
      <url>/2018/05/02/CentOS%206.7yum%E5%AE%89%E8%A3%85mysql/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h4 id="一、卸载掉原有mysql"><a href="#一、卸载掉原有mysql" class="headerlink" title="一、卸载掉原有mysql"></a>一、卸载掉原有mysql</h4><p>因为mysql数据库在Linux上实在是太流行了，所以目前下载的主流Linux系统版本基本上都集成了mysql数据库在里面，我们可以通过如下命令来查看我们的操作系统上是否已经安装了mysql数据库</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@jpress /]<span class="comment"># rpm -qa | grep mysql// 这个命令就会查看该操作系统上是否已经安装了mysql数据库</span></span><br><span class="line">mysql-libs-<span class="number">5.1</span>.<span class="number">73</span>-<span class="number">5</span>.el6_6.x86_64</span><br></pre></td></tr></table></figure><p>有的话，我们就通过 rpm -e 命令 或者 rpm -e –nodeps 命令来卸载掉</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># rpm -e mysql-libs-5.1.73-5.el6_6.x86_64　　// 普通删除模式</span></span><br><span class="line">[root@xiaoluo ~]<span class="comment"># rpm -e --nodeps mysql-libs-5.1.73-5.el6_6.x86_64　　// 强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令可以对其进行强力删除</span></span><br></pre></td></tr></table></figure><p>在删除完以后我们可以通过 rpm -qa | grep mysql 命令来查看mysql是否已经卸载成功！！</p><h4 id="二、通过yum来进行mysql的安装"><a href="#二、通过yum来进行mysql的安装" class="headerlink" title="二、通过yum来进行mysql的安装"></a>二、通过yum来进行mysql的安装</h4><p>我是通过yum的方式来进行mysql的数据库安装，首先我们可以输入 yum list | grep mysql 命令来查看yum上提供的mysql数据库可下载的版本：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># yum list | grep mysql</span></span><br></pre></td></tr></table></figure><p>就可以得到yum服务器上mysql数据库的可下载版本信息：</p><p><img src="http://www.centoscn.com/uploads/allimg/141211/1-141211021235456.jpg" alt="img"></p><p>然后我们可以通过输入 <code>yum install -y mysql-server mysql mysql-devel</code> 命令将<code>mysql mysql-server mysql-devel</code>都安装好(注意:安装mysql时我们并不是安装了mysql客户端就相当于安装好了mysql数据库了，我们还需要安装mysql-server服务端才行)</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># yum install -y mysql-server mysql mysql-deve</span></span><br></pre></td></tr></table></figure><p>在等待了一番时间后，yum会帮我们选择好安装mysql数据库所需要的软件以及其它附属的一些软件<img src="http://www.centoscn.com/uploads/allimg/141211/1-14121102124M46.jpg" alt="img"></p><p>我们发现，通过yum方式安装mysql数据库省去了很多没必要的麻烦，当出现下面的结果时，就代表mysql数据库安装成功了</p><p><img src="http://www.centoscn.com/uploads/allimg/141211/1-14121102130E38.jpg" alt="img"></p><p>此时我们可以通过如下命令，查看刚安装好的mysql-server的版本</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># rpm -qi mysql-server</span></span><br></pre></td></tr></table></figure><p>我们安装的mysql-server并不是最新版本，如果你想尝试最新版本，那就去mysql官网下载rpm包安装就行了，至此我们的mysql数据库已经安装完成了。</p><h4 id="三、mysql数据库的初始化及相关配置"><a href="#三、mysql数据库的初始化及相关配置" class="headerlink" title="三、mysql数据库的初始化及相关配置"></a>三、mysql数据库的初始化及相关配置</h4><p>我们在安装完mysql数据库以后，会发现会多出一个mysqld的服务，这个就是咱们的数据库服务，我们通过输入 service mysqld start 命令就可以启动我们的mysql服务。</p><p>注意：如果我们是第一次启动mysql服务，mysql服务器首先会进行初始化的配置，如：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># service mysqld start</span></span><br><span class="line"></span><br><span class="line">初始化 MySQL 数据库： WARNING: The host <span class="string">'xiaoluo'</span> could not be looked up with resolveip.</span><br><span class="line">This probably means that your libc libraries are not <span class="number">100</span> % compatible</span><br><span class="line">with this binary MySQL version. The MySQL daemon, mysqld, should work</span><br><span class="line">normally with the exception that host name resolving will not work.</span><br><span class="line">This means that you should use IP addresses instead of hostnames</span><br><span class="line">when specifying MySQL privileges !</span><br><span class="line">Installing MySQL system tables...</span><br><span class="line">OK</span><br><span class="line">Filling help tables...</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">To start mysqld at boot time you have to copy</span><br><span class="line">support-files/mysql.server to the right place <span class="keyword">for</span> your system</span><br><span class="line"></span><br><span class="line">PLEASE REMEMBER TO SET A PASSWORD <span class="keyword">FOR</span> THE MySQL root USER !</span><br><span class="line">To <span class="keyword">do</span> so, start the server, then issue the following commands:</span><br><span class="line"></span><br><span class="line">/usr/bin/mysqladmin -u root password <span class="string">'new-password'</span></span><br><span class="line">/usr/bin/mysqladmin -u root -h xiaoluo password <span class="string">'new-password'</span></span><br><span class="line"></span><br><span class="line">Alternatively you can run:</span><br><span class="line">/usr/bin/mysql_secure_installation</span><br><span class="line"></span><br><span class="line">which will also give you the option of removing the test</span><br><span class="line">databases and anonymous user created by default.  This is</span><br><span class="line">strongly recommended <span class="keyword">for</span> production servers.</span><br><span class="line"></span><br><span class="line">See the manual <span class="keyword">for</span> more instructions.</span><br><span class="line"></span><br><span class="line">You can start the MySQL daemon with:</span><br><span class="line">cd /usr ; /usr/bin/mysqld_safe &amp;</span><br><span class="line"></span><br><span class="line">You can test the MySQL daemon with mysql-test-run.pl</span><br><span class="line">cd /usr/mysql-test ; perl mysql-test-run.pl</span><br><span class="line"></span><br><span class="line">Please report any problems with the /usr/bin/mysqlbug script!</span><br><span class="line"></span><br><span class="line">                                                           [确定]</span><br><span class="line">正在启动 mysqld：                                            [确定]</span><br></pre></td></tr></table></figure><p>这时我们会看到第一次启动mysql服务器以后会提示非常多的信息，目的就是对mysql数据库进行初始化操作，当我们再次重新启动mysql服务时，就不会提示这么多信息了，如：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># service mysqld restart</span></span><br><span class="line">停止 mysqld：                                             [确定]</span><br><span class="line">正在启动 mysqld：                                          [确定]</span><br></pre></td></tr></table></figure><p>我们在使用mysql数据库时，都得首先启动mysqld服务，我们可以 通过  chkconfig –list | grep mysqld 命令来查看mysql服务是不是开机自动启动，如：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># chkconfig --list | grep mysqld</span></span><br><span class="line">mysqld             <span class="number">0</span>:关闭    <span class="number">1</span>:关闭    <span class="number">2</span>:关闭    <span class="number">3</span>:关闭    <span class="number">4</span>:关闭    <span class="number">5</span>:关闭    <span class="number">6</span>:关闭</span><br></pre></td></tr></table></figure><p>我们发现mysqld服务并没有开机自动启动，我们当然可以通过 chkconfig mysqld on 命令来将其设置成开机启动，这样就不用每次都去手动启动了</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># chkconfig mysqld on</span></span><br><span class="line">[root@xiaoluo ~]<span class="comment"># chkconfig --list | grep mysql</span></span><br><span class="line">mysqld             <span class="number">0</span>:关闭    <span class="number">1</span>:关闭    <span class="number">2</span>:启用    <span class="number">3</span>:启用    <span class="number">4</span>:启用    <span class="number">5</span>:启用    <span class="number">6</span>:关闭</span><br></pre></td></tr></table></figure><p>mysql数据库安装完以后只会有一个root管理员账号，但是此时的root账号还并没有为其设置密码，在第一次启动mysql服务时，会进行数据库的一些初始化工作，在输出的一大串信息中，我们看到有这样一行信息 ：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/mysqladmin -u root password <span class="string">'new-password'</span>　　// 为root账号设置密码</span><br></pre></td></tr></table></figure><p>所以我们可以通过 该命令来给我们的root账号设置密码(注意：这个root账号是mysql的root账号，非Linux的root账号)</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># mysqladmin -u root password 'root'　　// 通过该命令给root账号设置密码为 root</span></span><br></pre></td></tr></table></figure><p>此时我们可以通过 mysql -u root -p 命令来登录我们的mysql数据库了</p><p><img src="http://www.centoscn.com/uploads/allimg/141211/1-141211021320332.jpg" alt="img"></p><h4 id="四、mysql数据库的主要配置文件"><a href="#四、mysql数据库的主要配置文件" class="headerlink" title="四、mysql数据库的主要配置文件"></a>四、mysql数据库的主要配置文件</h4><p>1./etc/my.cnf 这是mysql的主配置文件</p><p>我们可以查看一下这个文件的一些信息</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo etc]<span class="comment"># ls my.cnf </span></span><br><span class="line">my.cnf</span><br><span class="line"></span><br><span class="line">[root@xiaoluo etc]<span class="comment"># cat my.cnf </span></span><br><span class="line">[mysqld]</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/lib/mysql/mysql.sock</span><br><span class="line">user=mysql</span><br><span class="line"><span class="comment"># Disabling symbolic-links is recommended to prevent assorted security risks</span></span><br><span class="line">symbolic-links=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">[mysqld_safe]</span><br><span class="line">log-error=/var/log/mysqld.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br></pre></td></tr></table></figure><p>2./var/lib/mysql   mysql数据库的数据库文件存放位置</p><p>我们的mysql数据库的数据库文件通常是存放在了/ver/lib/mysql这个目录下</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xiaoluo ~]<span class="comment"># cd /var/lib/mysql/</span></span><br><span class="line">[root@xiaoluo mysql]<span class="comment"># ls -l</span></span><br><span class="line">总用量 <span class="number">20488</span></span><br><span class="line">-rw-rw----. <span class="number">1</span> mysql mysql <span class="number">10485760</span> <span class="number">4</span>月   <span class="number">6</span> <span class="number">22</span>:<span class="number">01</span> ibdata1</span><br><span class="line">-rw-rw----. <span class="number">1</span> mysql mysql  <span class="number">5242880</span> <span class="number">4</span>月   <span class="number">6</span> <span class="number">22</span>:<span class="number">01</span> ib_logfile0</span><br><span class="line">-rw-rw----. <span class="number">1</span> mysql mysql  <span class="number">5242880</span> <span class="number">4</span>月   <span class="number">6</span> <span class="number">21</span>:<span class="number">59</span> ib_logfile1</span><br><span class="line">drwx------. <span class="number">2</span> mysql mysql     <span class="number">4096</span> <span class="number">4</span>月   <span class="number">6</span> <span class="number">21</span>:<span class="number">59</span> mysql　　// 这两个是mysql数据库安装时默认的两个数据库文件</span><br><span class="line">srwxrwxrwx. <span class="number">1</span> mysql mysql        <span class="number">0</span> <span class="number">4</span>月   <span class="number">6</span> <span class="number">22</span>:<span class="number">01</span> mysql.sock</span><br><span class="line">drwx------. <span class="number">2</span> mysql mysql     <span class="number">4096</span> <span class="number">4</span>月   <span class="number">6</span> <span class="number">21</span>:<span class="number">59</span> test　　// 这两个是mysql数据库安装时默认的两个数据库文件</span><br></pre></td></tr></table></figure><p>我们可以自己创建一个数据库，来验证一下该数据库文件的存放位置</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mysql操作命令</title>
      <link href="/2018/05/02/mysql%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/"/>
      <url>/2018/05/02/mysql%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h4 id="查询位置"><a href="#查询位置" class="headerlink" title="查询位置"></a>查询位置</h4><p><img src="http://osapnihnq.bkt.clouddn.com/mysql%E6%9F%A5%E6%89%BE.png" alt="mysql查找"></p><h4 id="进入mysql"><a href="#进入mysql" class="headerlink" title="进入mysql"></a>进入mysql</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/<span class="keyword">data</span>1/cupid/database/bin/mysql -utsoc -pfake.PWD.fool.<span class="number">4</span>.U -P3308 -hlocalhost --socket /<span class="keyword">data</span>1/cupid/databse/<span class="keyword">data</span>/mysql.sock</span><br></pre></td></tr></table></figure><h4 id="导出表"><a href="#导出表" class="headerlink" title="导出表"></a>导出表</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/run/<span class="keyword">data</span>/cupid/database/bin/mysqldump -utsoc -pfake.PWD.fool.<span class="number">4</span>.U -P3308 -hlocalhost --socket /run/<span class="keyword">data</span>/cupid/database/<span class="keyword">data</span>/mysql.sock tsoc zd_windows2017111 &gt; /<span class="keyword">data</span>/zd_windows2017111.sql</span><br></pre></td></tr></table></figure><h4 id="导入表"><a href="#导入表" class="headerlink" title="导入表"></a>导入表</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/run/<span class="keyword">data</span>/cupid/database/bin/mysql -utsoc -pfake.PWD.fool.<span class="number">4</span>.U -P3308 -hlocalhost --socket /run/<span class="keyword">data</span>/cupid/database/<span class="keyword">data</span>/mysql.sock tsoc &lt; /<span class="keyword">data</span>/test123.sql</span><br></pre></td></tr></table></figure><h4 id="杀死任务"><a href="#杀死任务" class="headerlink" title="杀死任务"></a>杀死任务</h4><p><code>show processlist;</code></p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180402/E41kL3agBC.png?imageslim" alt="mark"></p><p><strong>找到在执行的sql  id为57</strong></p><p><strong><code>kill 57;</code></strong></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Kafka总结</title>
      <link href="/2018/05/02/Kafka%E6%80%BB%E7%BB%93/"/>
      <url>/2018/05/02/Kafka%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="1-Kafka的特性"><a href="#1-Kafka的特性" class="headerlink" title="1.Kafka的特性"></a>1.Kafka的特性</h3><ul><li><strong>高吞吐量、低延迟</strong>：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒</li><li><strong>可扩展性</strong>：kafka集群支持热扩展</li><li><strong>持久性、可靠性</strong>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li><li><strong>容错性</strong>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li><li><strong>高并发</strong>：支持数千个客户端同时读写</li></ul><h3 id="2-Kafka重要设计思想"><a href="#2-Kafka重要设计思想" class="headerlink" title="2.Kafka重要设计思想"></a>2.Kafka重要设计思想</h3><p>​    Kafka的主要设计思想</p><ul><li><strong>Consumergroup</strong>：各个consumer可以组成一个组，每个消息只能被组中的一个consumer消费，<strong>如果一个消息可以被多个consumer消费的话，那么这些consumer必须在不同的组。</strong></li><li><strong>消息状态</strong>：在Kafka中，消息的状态被保存在consumer中，broker不会关心哪个消息被消费了被谁消费了，只记录一个offset值（指向partition中下一个要被消费的消息位置），这就意味着如果consumer处理不好的话，broker上的一个消息可能会被消费多次。</li><li><strong>消息持久化</strong>：Kafka中会把消息持久化到本地文件系统中，并且保持极高的效率。</li><li><strong>消息有效期</strong>：Kafka会长久保留其中的消息，以便consumer可以多次消费，当然其中很多细节是可配置的。</li><li><strong>批量发送</strong>：Kafka支持以消息集合为单位进行批量发送，以提高push效率。</li><li><strong>push-and-pull</strong> : Kafka中的Producer和consumer采用的是push-and-pull模式，即Producer只管向broker push消息，consumer只管从broker pull消息，两者对消息的生产和消费是异步的。</li><li><strong>Kafka集群中broker之间的关系</strong>：<strong>不是主从关系，各个broker在集群中地位一样，我们可以随意的增加或删除任何一个broker节点。</strong></li><li><strong>负载均衡方面</strong>： Kafka提供了一个 metadata API来管理broker之间的负载（对Kafka0.8.x而言，对于0.7.x主要靠zookeeper来实现负载均衡）。</li><li><strong>同步异步</strong>：Producer采用异步push方式，极大提高Kafka系统的吞吐率（可以通过参数控制是采用同步还是异步方式）。</li><li><strong>分区机制partition</strong>：Kafka的broker端支持消息分区，Producer可以决定把消息发到哪个分区，在一个分区中消息的顺序就是Producer发送消息的顺序，一个主题中可以有多个分区，具体分区的数量是可配置的。分区的意义很重大，后面的内容会逐渐体现。</li><li><strong>离线数据装载</strong>：Kafka由于对可拓展的数据持久化的支持，它也非常适合向Hadoop或者数据仓库中进行数据装载。</li><li><strong>插件支持</strong>：现在不少活跃的社区已经开发出不少插件来拓展Kafka的功能，如用来配合Storm、Hadoop、flume相关的插件。</li></ul><h3 id="3-Kafka架构组件"><a href="#3-Kafka架构组件" class="headerlink" title="3.Kafka架构组件"></a>3.Kafka架构组件</h3><p>Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic，把向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份具体的kafka消息。</p><ul><li>topic：消息存放的目录即主题</li><li>Producer：生产消息到topic的一方</li><li>Consumer：订阅topic消费消息的一方    </li><li>Broker：Kafka的服务实例就是一个broker</li></ul><p><img src="http://kafka.apache.org/images/producer_consumer.png" alt="img"></p><h3 id="4-Kafka-Topic-amp-Partition"><a href="#4-Kafka-Topic-amp-Partition" class="headerlink" title="4.Kafka Topic&amp;Partition"></a>4.Kafka Topic&amp;Partition</h3><p>在Kafka中，消息是按Topic组织的.</p><ol><li><strong>Partition</strong>:topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。</li><li><strong>Segment</strong>：partition物理上由多个segment组成</li><li><strong>offse</strong>t：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li></ol><p>消息发送时都被发送到一个topic，其本质就是一个目录，而topic由是由一些Partition Logs(分区日志)组成,其组织结构如下图所示：</p><p><img src="http://kafka.apache.org/images/log_anatomy.png" alt="img"></p><ul><li>​    每个Partition中的消息都是有序的，生产的消息被不断追加到Partition log上，其中的每一个消息都被赋予了一个唯一的offset值。 </li></ul><ul><li>​    Kafka集群会保存所有的消息，不管消息有没有被消费；我们可以设定消息的过期时间，只有过期的数据才会被自动清除以释放磁盘空间。比如我们设置消息过期时间为2天，那么这2天内的所有消息都会被保存到集群中，数据只有超过了两天才会被清除。 </li></ul><ul><li>​    Kafka需要维持的元数据只有一个–消费消息在Partition中的offset值，Consumer每消费一个消息，offset就会加1。其实消息的状态完全是由Consumer控制的，Consumer可以跟踪和重设这个offset值，这样的话Consumer就可以读取任意位置的消息。</li></ul><ul><li>​    把消息日志以Partition的形式存放有多重考虑，第一，方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；第二就是可以提高并发，因为可以以Partition为单位读写了。</li></ul><h3 id="5-Kafka-核心组件"><a href="#5-Kafka-核心组件" class="headerlink" title="5.Kafka 核心组件"></a>5.Kafka 核心组件</h3><h4 id="5-1-Replications、Partitions-和Leaders"><a href="#5-1-Replications、Partitions-和Leaders" class="headerlink" title="5.1 Replications、Partitions 和Leaders"></a>5.1 Replications、Partitions 和Leaders</h4><ul><li>​    kafka中的数据是持久化的并且能够容错的。Kafka允许用户为每个topic设置副本数量，副本数量决定了有几个broker来存放写入的数据。如果副本数量设置为3，那么一份数据就会被存放在3台不同的机器上，那么就允许有2个机器失败。一般推荐副本数量至少为2，这样就可以保证增减、重启机器时不会影响到数据消费。如果对数据持久化有更高的要求，可以把副本数量设置为3或者更多。</li></ul><ul><li>​    Kafka中的topic是以partition的形式存放的，每一个topic都可以设置它的partition数量，Partition的数量决定了组成topic的log的数量。Producer在生产数据时，会按照一定规则（这个规则是可以自定义的）把消息发布到topic的各个partition中。上面将的副本都是以partition为单位的，不过只有一个partition的副本会被选举成leader作为读写用。</li></ul><ul><li>​    关于如何设置partition值需要考虑的因素。一个partition只能被一个消费者消费（一个消费者可以同时消费多个partition），因此，如果设置的partition的数量小于consumer的数量，就会有消费者消费不到数据。所以，推荐partition的数量一定要大于同时运行的consumer的数量。另外一方面，建议partition的数量大于集群broker的数量，这样leader partition就可以均匀的分布在各个broker中，最终使得集群负载均衡。在Cloudera,每个topic都有上百个partition。需要注意的是，kafka需要为每个partition分配一些内存来缓存消息数据，如果partition数量越大，就要为kafka分配更大的heap space。</li></ul><h4 id="5-2-Producers"><a href="#5-2-Producers" class="headerlink" title="5.2 Producers"></a>5.2 Producers</h4><ul><li>​    Producers直接发送消息到broker上的leader partition，不需要经过任何中介一系列的路由转发。为了实现这个特性，kafka集群中的每个broker都可以响应producer的请求，并返回topic的一些元信息，这些元信息包括哪些机器是存活的，topic的leader partition都在哪，现阶段哪些leader partition是可以直接被访问的。 <ul><li>​Producer客户端自己控制着消息被推送到哪些partition。实现的方式可以是随机分配、实现一类随机负载均衡算法，或者指定一些分区算法。Kafka提供了接口供用户实现自定义的分区，用户可以为每个消息指定一个partitionKey，通过这个key来实现一些hash分区算法。比如，把userid作为partitionkey的话，相同userid的消息将会被推送到同一个分区。</li><li>​以Batch的方式推送数据可以极大的提高处理效率，kafka Producer 可以将消息在内存中累计到一定数量后作为一个batch发送请求。Batch的数量大小可以通过Producer的参数控制，参数值可以设置为累计的消息的数量（如500条）、累计的时间间隔（如100ms）或者累计的数据大小(64KB)。通过增加batch的大小，可以减少网络请求和磁盘IO的次数，当然具体参数设置需要在效率和时效性方面做一个权衡。</li><li>​Producers可以异步的并行的向kafka发送消息，但是通常producer在发送完消息之后会得到一个future响应，返回的是offset值或者发送过程中遇到的错误。这其中有个非常重要的参数“acks”,这个参数决定了producer要求leader partition 收到确认的副本个数，如果acks设置数量为0，表示producer不会等待broker的响应，所以，producer无法知道消息是否发送成功，这样有可能会导致数据丢失，但同时，acks值为0会得到最大的系统吞吐量。</li><li>​若acks设置为1，表示producer会在leader partition收到消息时得到broker的一个确认，这样会有更好的可靠性，因为客户端会等待直到broker确认收到消息。若设置为-1，producer会在所有备份的partition收到消息时得到broker的确认，这个设置可以得到最高的可靠性保证。</li><li>​Kafka 消息有一个定长的header和变长的字节数组组成。因为kafka消息支持字节数组，也就使得kafka可以支持任何用户自定义的序列号格式或者其它已有的格式如Apache</li></ul></li><li>Avro、protobuf等。Kafka没有限定单个消息的大小，但我们推荐消息大小不要超过1MB,通常一般消息大小都在1~10kB之前。</li></ul><h4 id="5-3-Consumers"><a href="#5-3-Consumers" class="headerlink" title="5.3 Consumers"></a>5.3 Consumers</h4><ul><li>​    Kafka提供了两套consumer api，分为high-level api和sample-api。Sample-api 是一个底层的API，它维持了一个和单一broker的连接，并且这个API是完全无状态的，每次请求都需要指定offset值，因此，这套API也是最灵活的。<ul><li>​在kafka中，当前读到消息的offset值是由consumer来维护的，因此，consumer可以自己决定如何读取kafka中的数据。比如，consumer可以通过重设offset值来重新消费已消费过的数据。不管有没有被消费，kafka会保存数据一段时间，这个时间周期是可配置的，只有到了过期时间，kafka才会删除这些数据。</li></ul></li><li>​        High-level API封装了对集群中一系列broker的访问，可以透明的消费一个topic。它自己维持了已消费消息的状态，即每次消费的都是下一个消息。 <ul><li>​High-level API还支持以组的形式消费topic，如果consumers有同一个组名，那么kafka就相当于一个队列消息服务，而各个consumer均衡的消费相应partition中的数据。若consumers有不同的组名，那么此时kafka就相当与一个广播服务，会把topic中的所有消息广播到每个consumer。</li></ul></li></ul><p><img src="http://kafka.apache.org/images/consumer-groups.png" alt="img"></p><h3 id="6-Kafka核心特性"><a href="#6-Kafka核心特性" class="headerlink" title="6.Kafka核心特性"></a>6.Kafka核心特性</h3><h4 id="6-1-压缩"><a href="#6-1-压缩" class="headerlink" title="6.1 压缩"></a>6.1 压缩</h4><p>​    我们上面已经知道了Kafka支持以集合（batch）为单位发送消息，在此基础上，Kafka还支持对消息集合进行压缩，Producer端可以通过GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在Consumer端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是CPU（压缩和解压会耗掉部分CPU资源）。<br>​    那么如何区分消息是压缩的还是未压缩的呢，Kafka在消息头部添加了一个描述压缩属性字节，这个字节的后两位表示消息的压缩采用的编码，如果后两位为0，则表示消息未被压缩。</p><h4 id="6-2消息可靠性"><a href="#6-2消息可靠性" class="headerlink" title="6.2消息可靠性"></a>6.2消息可靠性</h4><p>​    在消息系统中，保证消息在生产和消费过程中的可靠性是十分重要的，在实际消息传递过程中，可能会出现如下三中情况：</p><ul><li>一个消息发送失败</li><li>一个消息被发送多次</li><li>最理想的情况：exactly-once ,一个消息发送成功且仅发送了一次                   </li></ul><ul><li>​    有许多系统声称它们实现了exactly-once，但是它们其实忽略了生产者或消费者在生产和消费过程中有可能失败的情况。比如虽然一个Producer成功发送一个消息，但是消息在发送途中丢失，或者成功发送到broker，也被consumer成功取走，但是这个consumer在处理取过来的消息时失败了。<ul><li>​从Producer端看：Kafka是这么处理的，当一个消息被发送后，Producer会等待broker成功接收到消息的反馈（可通过参数控制等待时间），如果消息在途中丢失或是其中一个broker挂掉，Producer会重新发送（我们知道Kafka有备份机制，可以通过参数控制是否等待所有备份节点都收到消息）。</li><li>​从Consumer端看：前面讲到过partition，broker端记录了partition中的一个offset值，这个值指Consumer下一个即将消费message。当Consumer收到了消息，但却在处理过程中挂掉，此时Consumer可以通过这个offset值重新找到上一个消息再进行处理。Consumer还有权限控制这个offset值，对持久化到broker端的消息做任意处理。</li></ul></li></ul><h4 id="6-3-备份机制"><a href="#6-3-备份机制" class="headerlink" title="6.3 备份机制"></a>6.3 备份机制</h4><p>​    备份机制是Kafka0.8版本的新特性，备份机制的出现大大提高了Kafka集群的可靠性、稳定性。有了备份机制后，Kafka允许集群中的节点挂掉后而不影响整个集群工作。一个备份数量为n的集群允许n-1个节点失败。在所有备份节点中，有一个节点作为lead节点，这个节点保存了其它备份节点列表，并维持各个备份间的状体同步。下面这幅图解释了Kafka的备份机制:</p><p><img src="http://img.blog.csdn.net/20150828162159461" alt="这里写图片描述"></p><h4 id="6-4-Kafka高效性相关设计"><a href="#6-4-Kafka高效性相关设计" class="headerlink" title="6.4 Kafka高效性相关设计"></a>6.4 Kafka高效性相关设计</h4><h5 id="6-4-1-消息的持久化"><a href="#6-4-1-消息的持久化" class="headerlink" title="6.4.1 消息的持久化"></a>6.4.1 消息的持久化</h5><ul><li>​    Kafka高度依赖文件系统来存储和缓存消息，一般的人认为磁盘是缓慢的，这导致人们对持久化结构具有竞争性持怀疑态度。其实，磁盘远比你想象的要快或者慢，这决定于我们如何使用磁盘。 <ul><li>​一个和磁盘性能有关的关键事实是：磁盘驱动器的吞吐量跟寻到延迟是相背离的，也就是所，线性写的速度远远大于随机写。比如：在一个6 7200rpm SATA RAID-5 的磁盘阵列上线性写的速度大概是600M/秒，但是随机写的速度只有100K/秒，两者相差将近6000倍。线性读写在大多数应用场景下是可以预测的，因此，操作系统利用read-ahead和write-behind技术来从大的数据块中预取数据，或者将多个逻辑上的写操作组合成一个大写物理写操作中。更多的讨论可以在ACMQueueArtical中找到，他们发现，对磁盘的线性读在有些情况下可以比内存的随机访问要快一些。 </li><li>​为了补偿这个性能上的分歧，现代操作系统都会把空闲的内存用作磁盘缓存，尽管在内存回收的时候会有一点性能上的代价。所有的磁盘读写操作会在这个统一的缓存上进行。 </li></ul></li></ul><p>此外，如果我们是在JVM的基础上构建的，熟悉Java内存应用管理的人应该清楚以下两件事情：</p><ol><li>一个对象的内存消耗是非常高的，经常是所存数据的两倍或者更多。</li><li>随着堆内数据的增多，Java的垃圾回收会变得非常昂贵。</li></ol><ul><li>​    基于这些事实，利用文件系统并且依靠页缓存比维护一个内存缓存或者其他结构要好——我们至少要使得可用的缓存加倍，通过自动访问可用内存，并且通过存储更紧凑的字节结构而不是一个对象，这将有可能再次加倍。这么做的结果就是在一台32GB的机器上，如果不考虑GC惩罚，将最多有28-30GB的缓存。此外，这些缓存将会一直存在即使服务重启，然而进程内缓存需要在内存中重构（10GB缓存需要花费10分钟）或者它需要一个完全冷缓存启动（非常差的初始化性能）。它同时也简化了代码，因为现在所有的维护缓存和文件系统之间内聚的逻辑都在操作系统内部了，这使得这样做比one-off in-process attempts更加高效与准确。如果你的磁盘应用更加倾向于顺序读取，那么read-ahead在每次磁盘读取中实际上获取到这人缓存中的有用数据。 <ul><li>​以上这些建议了一个简单的设计：不同于维护尽可能多的内存缓存并且在需要的时候刷新到文件系统中，我们换一种思路。所有的数据不需要调用刷新程序，而是立刻将它写到一个持久化的日志中。事实上，这仅仅意味着，数据将被传输到内核页缓存中并稍后被刷新。我们可以增加一个配置项以让系统的用户来控制数据在什么时候被刷新到物理硬盘上。</li></ul></li></ul><h5 id="6-4-2-常数时间性能保证"><a href="#6-4-2-常数时间性能保证" class="headerlink" title="6.4.2 常数时间性能保证"></a>6.4.2 常数时间性能保证</h5><ul><li>​    消息系统中持久化数据结构的设计通常是维护者一个和消费队列有关的B树或者其它能够随机存取结构的元数据信息。B树是一个很好的结构，可以用在事务型与非事务型的语义中。但是它需要一个很高的花费，尽管B树的操作需要O(logN)。通常情况下，这被认为与常数时间等价，但这对磁盘操作来说是不对的。磁盘寻道一次需要10ms，并且一次只能寻一个，因此并行化是受限的。<ul><li>​直觉上来讲，一个持久化的队列可以构建在对一个文件的读和追加上，就像一般情况下的日志解决方案。尽管和B树相比，这种结构不能支持丰富的语义，但是它有一个优点，所有的操作都是常数时间，并且读写之间不会相互阻塞。这种设计具有极大的性能优势：最终系统性能和数据大小完全无关，服务器可以充分利用廉价的硬盘来提供高效的消息服务。</li><li>​事实上还有一点，磁盘空间的无限增大而不影响性能这点，意味着我们可以提供一般消息系统无法提供的特性。比如说，消息被消费后不是立马被删除，我们可以将这些消息保留一段相对比较长的时间（比如一个星期）。</li></ul></li></ul><h5 id="6-4-3-进一步提高效率"><a href="#6-4-3-进一步提高效率" class="headerlink" title="6.4.3 进一步提高效率"></a>6.4.3 进一步提高效率</h5><p>​    我们已经为效率做了非常多的努力。但是有一种非常主要的应用场景是：处理Web活动数据，它的特点是数据量非常大，每一次的网页浏览都会产生大量的写操作。更进一步，我们假设每一个被发布的消息都会被至少一个consumer消费，因此我们更要怒路让消费变得更廉价。<br>通过上面的介绍，我们已经解决了磁盘方面的效率问题，除此之外，在此类系统中还有两类比较低效的场景：</p><ul><li>太多小的I/O操作</li><li>过多的字节拷贝</li></ul><p>为了减少大量小I/O操作的问题，kafka的协议是围绕消息集合构建的。Producer一次网络请求可以发送一个消息集合，而不是每一次只发一条消息。在server端是以消息块的形式追加消息到log中的，consumer在查询的时候也是一次查询大量的线性数据块。消息集合即MessageSet，实现本身是一个非常简单的API，它将一个字节数组或者文件进行打包。所以对消息的处理，这里没有分开的序列化和反序列化的上步骤，消息的字段可以按需反序列化（如果没有需要，可以不用反序列化）。<br>另一个影响效率的问题就是字节拷贝。为了解决字节拷贝的问题，kafka设计了一种“标准字节消息”，Producer、Broker、Consumer共享这一种消息格式。Kakfa的message<br> log在broker端就是一些目录文件，这些日志文件都是MessageSet按照这种“标准字节消息”格式写入到磁盘的。<br>维持这种通用的格式对这些操作的优化尤为重要：持久化log 块的网络传输。流行的unix操作系统提供了一种非常高效的途径来实现页面缓存和socket之间的数据传递。在Linux操作系统中，这种方式被称作：sendfile system call（Java提供了访问这个系统调用的方法：FileChannel.transferTo api）。</p><p>为了理解sendfile的影响，需要理解一般的将数据从文件传到socket的路径：</p><ol><li>操作系统将数据从磁盘读到内核空间的页缓存中</li><li>应用将数据从内核空间读到用户空间的缓存中</li><li>应用将数据写回内核空间的socket缓存中</li><li>操作系统将数据从socket缓存写到网卡缓存中，以便将数据经网络发出</li></ol><p>这种操作方式明显是非常低效的，这里有四次拷贝，两次系统调用。如果使用sendfile，就可以避免两次拷贝：操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的。<br>我们期望一个主题上有多个消费者是一种常见的应用场景。利用上述的zero-copy，数据只被拷贝到页缓存一次，然后就可以在每次消费时被重得利用，而不需要将数据存在内存中，然后在每次读的时候拷贝到内核空间中。这使得消息消费速度可以达到网络连接的速度。这样以来，通过页面缓存和sendfile的结合使用，整个kafka集群几乎都已以缓存的方式提供服务，而且即使下游的consumer很多，也不会对整个集群服务造成压力。</p><h3 id="7-SHELL使用"><a href="#7-SHELL使用" class="headerlink" title="7.SHELL使用"></a>7.SHELL使用</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出所有topic</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper  <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --list</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看某topic的信息</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper  <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --describe --topic test1</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看某个数据日志的信息</span></span><br><span class="line">bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /var/local/kafka/<span class="keyword">data</span>/test-<span class="number">0</span>/<span class="number">00000000000000000000</span>.log  --print-data-log</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建某topic</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper  <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --create --topic cyb --partitions <span class="number">1</span> --replication-factor <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用alter configs命令更改或设置重写。这个例子更新了my主题的最大消息大小:</span></span><br><span class="line">bin/kafka-configs.sh --zookeeper <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --entity-type topics --entity-name test1 --alter --add-config max.message.bytes=<span class="number">128000</span></span><br><span class="line"></span><br><span class="line">bin/kafka-configs.sh --zookeeper <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span>  --entity-type topics --entity-name test1 --alter --delete-config max.message.bytes</span><br><span class="line"></span><br><span class="line"><span class="comment">#为Topic增加 partition数目kafka-add-partitions.sh</span></span><br><span class="line">bin/kafka-add-partitions.sh --topic singertest --partition <span class="number">2</span>  --zookeeper  <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> （为topic singertest增加<span class="number">2</span>个分区）</span><br><span class="line"></span><br><span class="line"><span class="comment">#删除topic,慎用，只会删除zookeeper中的元数据，消息文件须手动删除  位置在配置里 </span></span><br><span class="line">bin/kafka-topics.sh --delete --topic cyb --zookeeper <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span></span><br><span class="line"></span><br><span class="line">!通过配置config下server.properties在最下边加入一行</span><br><span class="line">delete.topic.enable=true</span><br><span class="line">这样删除topic时可以连带消息文件一起删除</span><br><span class="line"></span><br><span class="line"><span class="comment">#往某topic生产消息</span></span><br><span class="line">bin/kafka-console-producer.sh --broker-list BDS-CM:<span class="number">9092</span>,BDS-DATA1:<span class="number">9092</span>,BDS-DATA2:<span class="number">9092</span> --topic test1</span><br><span class="line"></span><br><span class="line"><span class="comment">#从某topic消费消息</span></span><br><span class="line">bin/kafka-console-consumer.sh --zookeeper <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --topic test1 --from-beginning</span><br><span class="line"></span><br><span class="line"><span class="comment">#登录zkClient</span></span><br><span class="line">cd /opt/cloudera/parcels/CDH/lib/zookeeper/bin</span><br><span class="line">./zkCli.sh -server BDS-CM:<span class="number">2181</span>,BDS-DATA1:<span class="number">2181</span>,BDS-DATA2:<span class="number">2181</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#给用户yuanbo分配读写test1这个topic的权限   默认是禁止的    默认不限制ip</span></span><br><span class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=<span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --add --allow-principal User:yuanbo --operation Read --operation Write --topic test1</span><br><span class="line"></span><br><span class="line"><span class="comment">#给俩用户授予从ip1和ip2两台机器上读写test1这个topic的权限</span></span><br><span class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=<span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --add --allow-principal User:yuanbo --allow-principal User:jinyu --allow-host <span class="number">192.168</span>.<span class="number">12.102</span> --allow-host <span class="number">192.168</span>.<span class="number">12.103</span> --allow-host <span class="number">192.168</span>.<span class="number">12.104</span> --operation Read --operation Write --topic test1</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看某个topic的全部acls信息</span></span><br><span class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=<span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span> --list --topic test2</span><br><span class="line"></span><br><span class="line"><span class="comment">#sasl消费</span></span><br><span class="line">bin/kafka-console-consumer-sasl.sh  --bootstrap-server <span class="number">192.168</span>.<span class="number">56.212</span>:<span class="number">9092</span> --topic test1 --consumer.config config/consumer.properties </span><br><span class="line"><span class="comment">#sasl生产</span></span><br><span class="line">bin/kafka-console-producer-sasl.sh  --broker-list <span class="number">192.168</span>.<span class="number">56.212</span>:<span class="number">9092</span> --topic test1 --producer.config config/producer.properties</span><br></pre></td></tr></table></figure><h3 id="8-Kafka-Leader选举"><a href="#8-Kafka-Leader选举" class="headerlink" title="8.Kafka  Leader选举"></a>8.Kafka  Leader选举</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">As with most distributed systems automatically handling failures requires having a precise definition of what it means <span class="keyword">for</span> a node to be <span class="string">"alive"</span>. <span class="keyword">For</span> Kafka node liveness has two conditions</span><br><span class="line">和大多数分布式系统一样，自动处理失败的节点。需要精确的定义什么样的节点是“活着”的，对于kafka的节点活着有<span class="number">2</span>个条件：</span><br><span class="line"><span class="number">1</span>.A node must be able to maintain its session with ZooKeeper (via ZooKeeper<span class="string">'s heartbeat mechanism)</span></span><br><span class="line"><span class="string">一个节点必须能维持与zookeeper的会话（通过zookeeper的心跳机制）</span></span><br><span class="line"><span class="string">2.If it is a slave it must replicate the writes happening on the leader and not fall "too far" behind</span></span><br><span class="line"><span class="string">如果它是一个slave，它必须复制leader并且不能落后"太多"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>单机Kafka服务器部署</title>
      <link href="/2018/05/02/%E5%8D%95%E6%9C%BAKafka%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2/"/>
      <url>/2018/05/02/%E5%8D%95%E6%9C%BAKafka%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h4 id="所需组件"><a href="#所需组件" class="headerlink" title="所需组件"></a>所需组件</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JDK1.8</span><br><span class="line">Zookeeper3.4.6</span><br><span class="line">kafka_2.11-0.10.0.0</span><br></pre></td></tr></table></figure><h4 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h4><p>配置jdk要先卸载centos自带的openjdk 先查看 rpm -qa | grep java 显示如下信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# rpm -qa | grep java</span><br><span class="line">java-1.8.0-openjdk-headless-1.8.0.65-3.b17.el7.x86_64</span><br><span class="line">javapackages-tools-3.4.1-11.el7.noarch</span><br><span class="line">java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64</span><br><span class="line">tzdata-java-2015g-1.el7.noarch</span><br><span class="line">java-1.7.0-openjdk-1.7.0.91-2.6.2.3.el7.x86_64</span><br><span class="line">java-1.7.0-openjdk-headless-1.7.0.91-2.6.2.3.el7.x86_64</span><br><span class="line">python-javapackages-3.4.1-11.el7.noarch</span><br></pre></td></tr></table></figure><p>卸载</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.65-3.b17.el7.x86_64</span><br><span class="line">rpm -e --nodeps java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64</span><br><span class="line">rpm -e --nodeps java-1.7.0-openjdk-1.7.0.91-2.6.2.3.el7.x86_64</span><br><span class="line">rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.91-2.6.2.3.el7.x86_64</span><br></pre></td></tr></table></figure><p>解压jdk在/usr/local并配置环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">在最后添加</span><br><span class="line">JAVA_HOME=/usr/local/jdk_1.<span class="number">8</span></span><br><span class="line">PATH=<span class="variable">$PATH:</span><span class="variable">$JAVA_HOME</span>/bin:</span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib</span><br><span class="line">export JAVA_HOME  PATH CLASSPATH</span><br><span class="line">更新配置文件</span><br><span class="line">source /etc/profile</span><br><span class="line">验证</span><br><span class="line">java -version</span><br><span class="line">javac</span><br></pre></td></tr></table></figure><h4 id="安裝Zookeeper"><a href="#安裝Zookeeper" class="headerlink" title="安裝Zookeeper"></a>安裝Zookeeper</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">解压tar zxvf zookeeper-<span class="number">3.4</span>.<span class="number">6</span>.tar.gz</span><br><span class="line"></span><br><span class="line">重命名mv zookeeper-<span class="number">3.4</span>.<span class="number">6</span> zookeeper</span><br><span class="line"></span><br><span class="line">修改配置文件</span><br><span class="line">cp zoo_simple.cfg zoo.cfg</span><br><span class="line">vim zoo.cfg</span><br><span class="line">修改dataDirzk的目录</span><br><span class="line">dataDir=/usr/local/zookeeper/<span class="keyword">data</span></span><br><span class="line">创建<span class="keyword">data</span>目录</span><br><span class="line"></span><br><span class="line">配置zk的环境变量(参考添加)</span><br><span class="line">vim /etc/profile</span><br><span class="line">export ZK_HOME=/usr/local/zookeeper</span><br><span class="line">PATH=<span class="variable">$PATH:</span><span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$ZK_HOME</span>/bin:</span><br><span class="line"></span><br><span class="line">更新配置文件</span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br><span class="line">启动</span><br><span class="line">zkServer.sh start</span><br><span class="line">zk使用</span><br><span class="line">可以使用命令zkCli.sh进入zk客户端</span><br></pre></td></tr></table></figure><p>图示成功</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/171228/JBKgk5cdaa.png?imageslim" alt="mark"></p><h4 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h4><p>解压在/usr/local        重命名为kafka方便修改</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/local/kafka/<span class="keyword">data</span>/<span class="comment">#创建kafka的数据目录</span></span><br><span class="line">cd /usr/local/kafka/config <span class="comment">#进入配置目录 </span></span><br><span class="line"></span><br><span class="line">vi server.properties <span class="comment">#编辑修改相应的参数 </span></span><br><span class="line"></span><br><span class="line">broker.id=<span class="number">0</span> <span class="comment">#注意此id为kafka服务器的唯一标示  不要与客户kafka 的id重复  只要是整数即可</span></span><br><span class="line">port=<span class="number">9092</span> <span class="comment">#这个参数很有意思  即使listeners里有端口号  也必须配置port 否则偶尔会出现问题</span></span><br><span class="line">listeners = PLAINTEXT://<span class="number">192.168</span>.<span class="number">56.212</span>:<span class="number">9092</span></span><br><span class="line">log.dirs=/var/local/kafka/<span class="keyword">data</span>/ <span class="comment">#日志存放路径，上面创建的目录 </span></span><br><span class="line">zookeeper.connect=<span class="number">192.168</span>.<span class="number">56.212</span>:<span class="number">2181</span> <span class="comment">#zookeeper地址和端口，单机配置部署，ip:2181 </span></span><br><span class="line"></span><br><span class="line">启动</span><br><span class="line">cd /usr/local/kafka</span><br><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure><h4 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/kafka</span><br><span class="line"></span><br><span class="line">vim kafkastart.sh</span><br><span class="line"><span class="comment">#启动kafka</span></span><br><span class="line">/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties &amp;</span><br><span class="line"></span><br><span class="line">vim kafkastop.sh</span><br><span class="line"><span class="comment">#关闭kafka</span></span><br><span class="line">/usr/local/kafka/bin/kafka-server-stop.sh /usr/local/kafka/config/server.properties &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加脚本执行权限</span></span><br><span class="line">chmod +x kafkastart.sh</span><br><span class="line">chmod +x kafkastop.sh</span><br></pre></td></tr></table></figure><h4 id="开启SASL认证-未成功"><a href="#开启SASL认证-未成功" class="headerlink" title="开启SASL认证(未成功)"></a>开启SASL认证(未成功)</h4><ul><li><h5 id="添加配置文件"><a href="#添加配置文件" class="headerlink" title="添加配置文件"></a>添加配置文件</h5></li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd config/</span><br><span class="line"><span class="comment">#服务端配置</span></span><br><span class="line">vim kafka_server_jaas.conf</span><br><span class="line"></span><br><span class="line">KafkaServer&#123;</span><br><span class="line">    org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class="line">    username=<span class="string">"admin"</span></span><br><span class="line">    password=<span class="string">"admin"</span></span><br><span class="line">    user_admin=<span class="string">"admin"</span></span><br><span class="line">    user_alice=<span class="string">"alice"</span>;</span><br><span class="line">&#125;;<span class="comment">#此处的用户和密码和linux账号无任何关系   </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#客户端配置</span></span><br><span class="line">vim kafka_client_jaas.conf</span><br><span class="line"></span><br><span class="line">KafkaClient &#123;</span><br><span class="line">  org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class="line">  username=<span class="string">"admin"</span></span><br><span class="line">  password=<span class="string">"admin"</span>;</span><br><span class="line">&#125;;<span class="comment">#必须为服务端配置里存在的账号和密码</span></span><br></pre></td></tr></table></figure><ul><li><h5 id="更改资源文件"><a href="#更改资源文件" class="headerlink" title="更改资源文件"></a>更改资源文件</h5></li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#核心文件server.properties</span></span><br><span class="line">vim server.properties</span><br><span class="line"><span class="comment">#在修改原有的listeners=PLAINTEXT://192.168.56.212:9092   并在其下加入sasl认证的配置</span></span><br><span class="line">listeners=SASL_PLAINTEXT://<span class="number">192.168</span>.<span class="number">56.212</span>:<span class="number">9092</span></span><br><span class="line">security.inter.broker.protocol=SASL_PLAINTEXT</span><br><span class="line">sasl.mechanism.inter.broker.protocol=PLAIN</span><br><span class="line">sasl.enabled.mechanisms=PLAIN</span><br><span class="line">authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer</span><br><span class="line">super.users=User:admin</span><br><span class="line"></span><br><span class="line"><span class="comment">#客户端资源文件   用于命令启动sh客户端进行验证使用</span></span><br><span class="line">vim producer.properties</span><br><span class="line"><span class="comment">#在最后加入</span></span><br><span class="line">security.protocol = SASL_PLAINTEXT</span><br><span class="line">sasl.mechanism = PLAIN</span><br><span class="line"></span><br><span class="line">vim consumer.properties</span><br><span class="line"><span class="comment">#在最后加入</span></span><br><span class="line">security.protocol = SASL_PLAINTEXT</span><br><span class="line">sasl.mechanism = PLAIN</span><br></pre></td></tr></table></figure><ul><li><h5 id="添加启动脚本"><a href="#添加启动脚本" class="headerlink" title="添加启动脚本"></a>添加启动脚本</h5></li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">cd ../bin/</span><br><span class="line"></span><br><span class="line">vim kafka-run-class.sh</span><br><span class="line"><span class="comment">#在最后加入KAFKA_SASL_OPTS变量值并在下方引用    注意变量引用的配置文件路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Launch mode</span></span><br><span class="line">KAFKA_SASL_OPTS=<span class="string">'-Djava.security.auth.login.config=/usr/local/kafka/config/kafka_server_jaas.conf'</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"x<span class="variable">$DAEMON_MODE</span>"</span> = <span class="string">"xtrue"</span> ]; then</span><br><span class="line">  nohup <span class="variable">$JAVA</span> <span class="variable">$KAFKA_HEAP_OPTS</span> <span class="variable">$KAFKA_JVM_PERFORMANCE_OPTS</span> <span class="variable">$KAFKA_GC_LOG_OPTS</span> <span class="variable">$KAFKA_SASL_OPTS</span> <span class="variable">$KAFKA_JMX_OPTS</span> <span class="variable">$KAFKA_LOG4J_OPTS</span> -cp <span class="variable">$CLASSPATH</span> <span class="variable">$KAFKA_OPTS</span> <span class="string">"$@"</span> &gt; <span class="string">"<span class="variable">$CONSOLE_OUTPUT_FILE</span>"</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span> &lt; /dev/null &amp;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  exec <span class="variable">$JAVA</span> <span class="variable">$KAFKA_HEAP_OPTS</span> <span class="variable">$KAFKA_JVM_PERFORMANCE_OPTS</span> <span class="variable">$KAFKA_GC_LOG_OPTS</span> <span class="variable">$KAFKA_SASL_OPTS</span> <span class="variable">$KAFKA_JMX_OPTS</span> <span class="variable">$KAFKA_LOG4J_OPTS</span> -cp <span class="variable">$CLASSPATH</span> <span class="variable">$KAFKA_OPTS</span> <span class="string">"$@"</span></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立sasl认证的生产者客户端</span></span><br><span class="line">vim kafka-console-producer-sasl.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#启用sasl验证生产脚本</span></span><br><span class="line">export KAFKA_OPTS=<span class="string">"-Djava.security.auth.login.config=/usr/local/kafka/config/kafka_client_jaas.conf"</span></span><br><span class="line">/usr/local/kafka/bin/kafka-console-producer.sh <span class="string">"$@"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#建立sasl认证的消费者客户端</span></span><br><span class="line">vim kafka-console-consumer-sasl.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#启用sasl验证消费脚本</span></span><br><span class="line">export KAFKA_OPTS=<span class="string">"-Djava.security.auth.login.config=/usr/local/kafka/config/kafka_client_jaas.conf"</span></span><br><span class="line">/usr/local/kafka/bin/kafka-console-consumer.sh --new-consumer <span class="string">"$@"</span></span><br></pre></td></tr></table></figure><ul><li><h5 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h5></li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">使用命令对topic赋予指定用户的读写权限</span><br><span class="line">启动sasl的客户端进行认证 </span><br><span class="line">本文不提供命令    参考kafka记录中SHELL标题</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CLOUDERA_MANAGER安装KAFKA</title>
      <link href="/2018/05/02/CLOUDERA_MANAGER%E5%AE%89%E8%A3%85KAFKA/"/>
      <url>/2018/05/02/CLOUDERA_MANAGER%E5%AE%89%E8%A3%85KAFKA/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h3><p><code>CDH 5.5.1</code></p><p><code>KAFKA-2.1.1-0.10.0</code></p><h3 id="准备软件"><a href="#准备软件" class="headerlink" title="准备软件"></a>准备软件</h3><p><strong>下载地址:</strong></p><p><strong><u><a href="http://archive.cloudera.com/kafka/parcels/2.1/" target="_blank" rel="noopener">http://archive.cloudera.com/kafka/parcels/2.1/</a></u></strong></p><p><code>KAFKA-2.1.1-1.2.1.1.p0.18-el6.parcel.sha1</code></p><p><code>KAFKA-2.1.1-1.2.1.1.p0.18-el6.parcel</code></p><p><strong>el6对应centos6系统版本</strong></p><h3 id="安装步奏"><a href="#安装步奏" class="headerlink" title="安装步奏"></a>安装步奏</h3><h4 id="初步安装"><a href="#初步安装" class="headerlink" title="初步安装"></a>初步安装</h4><p>使用ftp工具上传两个文件至CM节点/opt/cloudera/parcel-repo</p><p>重命名sha1码文件</p><p><code>mv KAFKA-2.1.1-1.2.1.1.p0.18-el6.parcel.sha1 KAFKA-2.1.1-1.2.1.1.p0.18-el6.parcel.sha</code></p><p>点击主机进入界面然后点击parcel</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cb8d2e3d22.png" alt="微信截图_20170623144116.png"></p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cb98d66620.png" alt="微信截图_20170623144606.png"></p><p>点击右上”检查新Parcel”</p><p>成功后会在左边栏CDH5的下边出现KAFKA（此图是已经激活好的页面）</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cb98e1ac74.png" alt="微信截图_20170623144643.png"></p><p>点击KAFKA然后点击右边的配置，配置完成后，点击激活</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cb98ddcdcf.png" alt="1498200435(1.png"></p><p>回到主界面点击左边栏右上▽添加服务</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cbcf0959a5.png" alt="天价服务.png"></p><p>选择Kafka</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cbcf0c3aeb.png" alt="选中.png"></p><p>选择Kafka Broker(其实就是kafka的实例，一台kafka服务器就是一个broker)</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cbcee55c56.png" alt="选择broker.png"></p><p>勾选主机</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cbcee32c78.png" alt="勾选.png"></p><p>点击继续进入配置页面</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cbcf067e4b.png" alt="继续.png"></p><p>然后等待启动完毕即可完成初步安装</p><h4 id="更改配置"><a href="#更改配置" class="headerlink" title="更改配置"></a>更改配置</h4><p><code>管理页面停止zk和kafka服务</code></p><h5 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看myid   myid在zk配置文件$ZK_HOME/conf/zoo.cfg里的dataDir=/var/lib/zookeeper/</span></span><br><span class="line">cat /var/lib/zookeeper/myid</span><br></pre></td></tr></table></figure><p>在Cloudera Manager里添加服务添加,然后在zoo.cfg最下方加入</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server.<span class="number">1</span>= <span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server.<span class="number">2</span>= <span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server.<span class="number">3</span>= <span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line"><span class="comment">#server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。      简单来讲    A对应myid</span></span><br></pre></td></tr></table></figure><h5 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h5><p><code>$KAFKA_HOME/config/server.properties</code></p><p><strong>注意！Cloudera Manager不会自动更改server.properties内的broker.id</strong><br><strong>查看id</strong></p><p><img src="http://osapnihnq.bkt.clouddn.com/%E6%9F%A5%E7%9C%8Bbrokerid.png" alt="查看brokerid"></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#根据查出的id去修改配置文件里server.properties的broker.id</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#监视</span></span><br><span class="line">host.name=<span class="number">192.168</span>.<span class="number">12.104</span></span><br><span class="line">port=<span class="number">9092</span> <span class="comment">#这个参数很有意思  即使listeners里有端口号  也必须配置port 否则偶尔会出现问题</span></span><br><span class="line">listeners=PLAINTEXT://<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">9092</span><span class="comment">#本机ip</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#接收网络请求的线程数</span></span><br><span class="line">num.network.threads=<span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#zk</span></span><br><span class="line">zookeeper.connect=<span class="number">192.168</span>.<span class="number">12.103</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.102</span>:<span class="number">2181</span>,<span class="number">192.168</span>.<span class="number">12.104</span>:<span class="number">2181</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#data&amp;log存储位置不用改  cloudera manager会覆盖这些配置</span></span><br><span class="line">（<span class="number">1</span>）存放kafka的log文件的位置</span><br><span class="line"></span><br><span class="line">默认是/var/log/kafka/ </span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）存放kafka的<span class="keyword">data</span>的位置</span><br><span class="line"></span><br><span class="line">默认是/var/local/kafka/<span class="keyword">data</span></span><br></pre></td></tr></table></figure><p>更改完成后需要重启机器</p><p><img src="https://ooo.0o0.ooo/2017/06/26/5950c68d39a59.png" alt="微信截图_20170626163141.png"></p><p>启动kafka时请注意启动日志  刚启动的时候回打印启动时kafka的参数  注意zookeeper是否是使用的集群里的zookeeper而不是kafka自带的。如果是使用kafka自带的,可以先停止kafka服务   去kafka目录使用shell启动</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/cloudera/parcels/KAFKA-<span class="number">2.1</span>.<span class="number">1</span>-<span class="number">1.2</span>.<span class="number">1.1</span>.p0.<span class="number">18</span>/lib/kafka</span><br><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure><p>然后在ctrl+c停止三台机器的kafka服务区cloudera manager页面去启动 再次注意启动日志</p><h3 id="问题说明"><a href="#问题说明" class="headerlink" title="问题说明"></a>问题说明</h3><p>值得一提的是  如果没有下载Kafka的parcel就去添加服务然后去启动，会出现如下的错误</p><p><img src="https://ooo.0o0.ooo/2017/06/23/594cc0ee1dc80.png" alt="kafka错误1.png"></p><p>点击查看日志的话会新开页面提示错误 <code>[Errno 2] No such file or directory: &#39;/var/log/kafka/server.log&#39;</code></p><p>点击右上<code>查看完整日志</code>的话会新开页面503</p><p><strong>重新安装kafka需要执行命令删除zk上的topic并删除物理数据并</strong></p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop群集安装（未写完）</title>
      <link href="/2018/05/02/Hadoop%E7%BE%A4%E9%9B%86%E5%AE%89%E8%A3%85%EF%BC%88%E6%9C%AA%E5%86%99%E5%AE%8C%EF%BC%89/"/>
      <url>/2018/05/02/Hadoop%E7%BE%A4%E9%9B%86%E5%AE%89%E8%A3%85%EF%BC%88%E6%9C%AA%E5%86%99%E5%AE%8C%EF%BC%89/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p>Hadoop 集群的安装配置大致为如下流程:</p><ol><li>选定一台机器作为 Master</li><li>在 Master 节点上配置 hadoop 用户、安装 SSH server、安装 Java 环境</li><li>在 Master 节点上安装 Hadoop，并完成配置</li><li>在其他 Slave 节点上配置 hadoop 用户、安装 SSH server、安装 Java 环境</li><li>将 Master 节点上的 /usr/local/hadoop 目录复制到其他 Slave 节点上</li><li>在 Master 节点上开启 Hadoop</li></ol><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>其他工作见我所写的Hadoop单机部署，此处只讲解ssh无密登陆</p><p>这个操作是要让 Master 节点可以无密码 SSH 登陆到各个 Slave 节点上。</p><p>首先生成 Master 节点的公匙，在 Master 节点的终端中执行（因为改过主机名，所以还需要删掉原有的再重新生成一次）：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh               <span class="comment"># 如果没有该目录，先执行一次ssh localhostrm ./id_rsa*            # 删除之前生成的公匙（如果有）ssh-keygen -t rsa       # 一直按回车就可以</span></span><br></pre></td></tr></table></figure><p>让 Master 节点需能无密码 SSH 本机，在 Master 节点上执行：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ./id_rsa.pub &gt;&gt; ./authorized_keys</span><br></pre></td></tr></table></figure><p>完成后可执行 <code>ssh localhost</code>证一下（可能需要输入 yes，成功后执行 <code>exit</code> 返回原来的终端）。接着在 Master 节点将上公匙传输到 Slave1 节点：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa.pub root@cluster_node1:/root/.ssh</span><br></pre></td></tr></table></figure><p>scp 是 secure copy 的简写，用于在 Linux 下进行远程拷贝文件，类似于 cp 命令，不过 cp 只能在本机中拷贝。执行 scp 时会要求输入 Slave1 上 root用户的密码(也可以使用其他用户，比如我的chi用户)，输入完成后会提示传输完毕，如下图所示：</p><p><img src="http://cdn.powerxing.com/imgs/install-hadoop-cluster-05-scp.png" alt="通过scp向远程主机拷贝文件"></p><p>通过scp向远程主机拷贝文件</p><p>接着在 Slave1 节点上，将 ssh 公匙加入授权：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.ssh       <span class="comment"># 如果不存在该文件夹需先创建，若已存在则忽略</span></span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keysrm ~/.ssh/id_rsa.pub    <span class="comment"># 用完就可以删掉了</span></span><br></pre></td></tr></table></figure><p>如果有其他 Slave 节点，也要执行将 Master 公匙传输到 Slave 节点、在 Slave 节点上加入授权这两步。</p><p>这样，在 Master 节点上就可以无密码 SSH 到各个 Slave 节点了，可在 Master 节点上执行如下命令进行检验，如下图所示：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh cluster_node1</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2017/08/24/599e9351b1fd5.png" alt="微信截图_20170824164948.png"></p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>集群/分布式模式需要修改 /usr/local/hadoop/etc/hadoop 中的5个配置文件，更多设置项可点击查看官方说明，这里仅设置了正常启动所必须的设置项： <strong>slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml</strong> 。</p><p>1, 文件 slaves，将作为 DataNode 的主机名写入该文件，每行一个，默认为 localhost，所以在伪分布式配置时，节点即作为 NameNode 也作为 DataNode。分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。</p><p>本教程让 Master 节点仅作为 NameNode 使用，因此将文件中原来的 localhost 删除，添加如下内容</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster_node1</span><br><span class="line">cluster_node2</span><br></pre></td></tr></table></figure><p>2,文件 <strong>core-site.xml</strong> 改为下面的配置：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/usr/local/hadoop2/tmp&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;temp dir&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://cluster_model:<span class="number">9000</span>&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;io.file.buffer.size&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="number">131072</span>&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>3, 文件 <strong>hdfs-site.xml</strong>，dfs.replication 一般设为 3，但我们只有两个 Slave 节点，所以 dfs.replication 的值还是设为 2：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt; </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;Master:<span class="number">50090</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt; </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;<span class="number">2</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt; </span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt; </span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/<span class="keyword">data</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>4, 文件 <strong>mapred-site.xml</strong> （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop单机安装</title>
      <link href="/2018/05/02/Hadoop%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85/"/>
      <url>/2018/05/02/Hadoop%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="准备软件"><a href="#准备软件" class="headerlink" title="准备软件"></a>准备软件</h3><pre><code>jdk-7u80-linux-x64.tar.gz,hadoop-2.6.4.tar.gz</code></pre><h3 id="安装步奏"><a href="#安装步奏" class="headerlink" title="安装步奏"></a>安装步奏</h3><h4 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h4><p>配置jdk要先卸载centos自带的openjdk<br>先查看 rpm -qa | grep java<br>显示如下信息：</p><pre><code>[root@localhost /]# rpm -qa | grep javajava-1.8.0-openjdk-headless-1.8.0.65-3.b17.el7.x86_64javapackages-tools-3.4.1-11.el7.noarchjava-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64tzdata-java-2015g-1.el7.noarchjava-1.7.0-openjdk-1.7.0.91-2.6.2.3.el7.x86_64java-1.7.0-openjdk-headless-1.7.0.91-2.6.2.3.el7.x86_64python-javapackages-3.4.1-11.el7.noarch</code></pre><p>卸载</p><pre><code>rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.65-3.b17.el7.x86_64rpm -e --nodeps java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-1.7.0.91-2.6.2.3.el7.x86_64rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.91-2.6.2.3.el7.x86_64</code></pre><p>解压jdk并配置环境变量</p><pre><code>vim /etc/profile在最后添加JAVA_HOME=/usr/local/jdk_1.7PATH=$PATH:$JAVA_HOME/bin:CLASSPATH=.:$JAVA_HOME/libexport JAVA_HOME  PATH CLASSPATH</code></pre><h4 id="安装SSH、配置SSH无密码登陆"><a href="#安装SSH、配置SSH无密码登陆" class="headerlink" title="安装SSH、配置SSH无密码登陆"></a>安装SSH、配置SSH无密码登陆</h4><pre><code>执行如下命令进行检验：[spark@localhost ~]$ rpm -qa | grep sshopenssh-6.6.1p1-22.el7.x86_64libssh2-1.4.3-10.el7.x86_64openssh-server-6.6.1p1-22.el7.x86_64openssh-clients-6.6.1p1-22.el7.x86_64此时是已经安装了</code></pre><p>若需要安装，则可以通过 yum 进行安装（安装过程中会让你输入 [y/N]，输入 y 即可）：</p><pre><code>sudo yum install openssh-clientssudo yum install openssh-server</code></pre><p>接着执行如下命令测试一下 SSH 是否可用：</p><pre><code>[spark@localhost ~]$ ssh localhostspark@localhost&apos;s password: Last login: Tue Feb  7 23:34:34 2017 from 192.168.15.1-bash: : No such file or directory</code></pre><p>但这样登陆是需要每次输入密码的，我们需要配置成SSH无密码登陆比较方便。</p><p>首先输入 exit 退出刚才的 ssh，就回到了我们原先的终端窗口，然后利用 ssh-keygen 生成密钥，并将密钥加入到授权中：</p><pre><code>[spark@localhost ~]$ exit# 退出刚才的 ssh localhostlogoutConnection to localhost closed.[spark@localhost ~]$ cd ~/.ssh/# 若没有该目录，请先执行一次ssh localhost[spark@localhost .ssh]$ lsknown_hosts[spark@localhost .ssh]$ ssh-keygen -t rsa# 会有提示，都按回车就可以Generating public/private rsa key pair.Enter file in which to save the key (/home/spark/.ssh/id_rsa):    Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/spark/.ssh/id_rsa.Your public key has been saved in /home/spark/.ssh/id_rsa.pub.The key fingerprint is:23:b2:30:77:8a:33:d8:93:84:c4:3a:57:4b:3e:bb:d4 spark@localhost.localdomainThe key&apos;s randomart image is:+--[ RSA 2048]----+|                 ||.                || o  o            ||o. + .           ||+ = * o S        || * * O . .       ||. B = E          ||   = .           ||    .            |+-----------------+[spark@localhost .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys# 加入授权[spark@localhost .ssh]$ chmod 600 ./authorized_keys# 修改文件权限在 Linux 系统中，~ 代表的是用户的主文件夹，即 “/home/用户名” 这个目录，如你的用户名为 hadoop，则 ~ 就代表 “/home/hadoop/”[spark@localhost .ssh]$ pwd/home/spark/.ssh</code></pre><p>此时再用 ssh localhost 命令，无需输入密码就可以直接登陆了</p><pre><code>[spark@localhost .ssh]$ ssh localhostLast login: Tue Feb  7 23:35:12 2017 from localhost-bash: : No such file or directory[spark@localhost ~]$ exitlogoutConnection to localhost closed. </code></pre><h4 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h4><p>Hadoop 解压后即可使用。输入如下命令来检查 Hadoop 是否可用，成功则会显示 Hadoop 版本信息：</p><pre><code>更改文件夹名方便配置文件mv hadoop-2.6.4 hadoopcd /usr/local/hadoop./bin/hadoop version</code></pre><p>设置 HADOOP 环境变量    </p><pre><code>vim /etc/profile# Hadoop Environment Variablesexport HADOOP_HOME=/usr/local/hadoopexport HADOOP_INSTALL=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin    </code></pre><p>执行如下命令使配置生效</p><pre><code>source /etc/profile </code></pre><p>修改配置文件 core-site.xml</p><pre><code>&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;        &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>修改配置文件 hdfs-site.xml</p><pre><code>&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>配置完成后，执行 NameNode 的格式化:</p><pre><code>./bin/hdfs namenode -format 成功的话，会看到 “successfully formatted” 和 “Exitting with status 0” 的提示， 若为 “Exitting with status 1” 则是出错。</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/06/59366587664c1.png" alt="下载.png"></p><p>==接着开启 NaneNode 和 DataNode 守护进程：==</p><pre><code>./sbin/start-dfs.sh若出现如下 SSH 的提示 “Are you sure you want to continue connecting”，输入 yes 即可。localhost: Error: JAVA_HOME is not set and could not be found.修改/etc/hadoop/hadoop-env.sh中设JAVA_HOMEexport JAVA_HOME=/usr/local/jdk_1.7 </code></pre><p>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode”和SecondaryNameNode（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。</p><p><img src="https://ooo.0o0.ooo/2017/06/06/5936658795db5.png" alt="下载 (2).png"></p><p>==通过查看启动日志分析启动失败原因==<br>有时 Hadoop 无法正确启动，如 NameNode 进程没有顺利启动，这时可以查看启动日志来排查原因，注意几点：</p><pre><code>启动时会提示形如 “dblab: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-dblab.out”，其中 dblab 对应你的主机名，但启动的日志信息是记录在 /usr/local/hadoop/logs/hadoop-hadoop-namenode-dblab.log 中，所以应该查看这个后缀为 .log 的文件；每一次的启动日志都是追加在日志文件之后，所以得拉到最后面看，看下记录的时间就知道了。一般出错的提示在最后面，也就是写着 Fatal、Error 或者 Java Exception 的地方。可以在网上搜索一下出错信息，看能否找到一些相关的解决方法。</code></pre><p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p><pre><code>./bin/hdfs dfs -mkdir -p /user/spark</code></pre><p>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/hadoop/input 中。我们使用的是 spark 用户，并且已创建相应的用户目录 /user/spark ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/spark/input:</p><pre><code>./bin/hdfs dfs -mkdir /user/spark/input./bin/hdfs dfs -put ./etc/hadoop/*.xml /user/spark/input</code></pre><p>复制完成后，可以通过如下命令查看 HDFS 中的文件列表：</p><pre><code>./bin/hdfs dfs -ls /user/spark/input</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/06/593665887edf2.png" alt="下载 (3).png"></p><p>我们也可以将运行结果取回到本地：</p><pre><code>rm -r ./output    # 先删除本地的 output 文件夹（如果存在）./bin/hdfs dfs -get /user/spark/output ./output     # 将 HDFS 上的 output 文件夹拷贝到本机cat ./output/*</code></pre><p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:<br>​<br>    ./bin/hdfs dfs -rm -r /user/spark/output    # 删除 output 文件夹<br>运行程序时，输出目录不能存在</p><p>运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时自动删除输出目录，避免繁琐的命令行操作：<br>​<br>    Configuration conf = new Configuration();<br>    Job job = new Job(conf);</p><pre><code>/* 删除输出目录 */Path outputPath = new Path(args[1]);outputPath.getFileSystem(conf).delete(outputPath, true);        </code></pre><p>==若要关闭 Hadoop，则运行==</p><pre><code>./sbin/stop-dfs.sh</code></pre><h4 id="启动YARN"><a href="#启动YARN" class="headerlink" title="启动YARN"></a>启动YARN</h4><p>有的读者可能会疑惑，怎么启动 Hadoop 后，见不到书上所说的 JobTracker 和 TaskTracker，<br>这是因为新版的 Hadoop 使用了新的 MapReduce 框架（MapReduce V2，<br>也称为 YARN，Yet Another Resource Negotiator）。<br>YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。<br>YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性，YARN 的更多介绍在此不展开，有兴趣的可查阅相关资料。<br>上述通过 ./sbin/start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们可以启动 YARN ，让 YARN 来负责资源管理与任务调度。<br>首先修改配置文件 mapred-site.xml，这边需要先进行重命名：</p><pre><code>mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml</code></pre><p>然后再进行编辑，vim ./etc/hadoop/mapred-site.xml ： </p><pre><code>&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;&lt;/configuration</code></pre><p>接着修改配置文件 yarn-site.xml：    </p><pre><code>vim ./etc/hadoop/yarn-site.xml &lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;     &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>==然后就可以启动 YARN 了（需要先执行过 ./sbin/start-dfs.sh）：==</p><pre><code>./sbin/start-yarn.sh      $ 启动YARN./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/06/59366587944ed.png" alt="下载 (4).png"></p><p>启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。<br>观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，<br>启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。<br>启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：<a href="http://192.168.15.131:8088/cluster，如下图所示。" target="_blank" rel="noopener">http://192.168.15.131:8088/cluster，如下图所示。</a></p><p><img src="https://ooo.0o0.ooo/2017/06/06/59366589dcbf1.png" alt="下载 (5).png"></p><p>但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑得稍慢些。因此在单机上是否开启 YARN 就看实际情况了。<br>==不启动 YARN 需重命名 mapred-site.xml==</p><p>如果不想启动 YARN，务必把配置文件 mapred-site.xml 重命名，<br>改成 mapred-site.xml.template，需要用时改回来就行。否则在该配置文件存在，<br>而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，<br>这也是为何该配置文件初始文件名为 mapred-site.xml.template。</p><h4 id="同样的，关闭-YARN-的脚本如下："><a href="#同样的，关闭-YARN-的脚本如下：" class="headerlink" title="同样的，关闭 YARN 的脚本如下："></a>同样的，关闭 YARN 的脚本如下：</h4><pre><code>./sbin/stop-yarn.sh./sbin/mr-jobhistory-daemon.sh stop historyserver</code></pre><h3 id="配置变量"><a href="#配置变量" class="headerlink" title="配置变量"></a>配置变量</h3><p>在前面我们设置 HADOOP 环境变量时，我们已经顺便设置了 PATH 变量</p><pre><code>（即 “export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin”），</code></pre><p>那么以后我们在任意目录中都可以直接通过执行start-dfs.sh 来启动 Hadoop 或者<br>执行 hdfs dfs -ls input 查看 HDFS 文件了，执行 hdfs dfs -ls input 试试看。</p><h3 id="命令整理"><a href="#命令整理" class="headerlink" title="命令整理"></a>命令整理</h3><h4 id="开启"><a href="#开启" class="headerlink" title="开启"></a>开启</h4><h5 id="开启-NaneNode-和-DataNode-守护进程："><a href="#开启-NaneNode-和-DataNode-守护进程：" class="headerlink" title="开启 NaneNode 和 DataNode 守护进程："></a>开启 NaneNode 和 DataNode 守护进程：</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/start-dfs.sh</span><br></pre></td></tr></table></figure><h5 id="启动-YARN（需要先执行过-sbin-start-dfs-sh）："><a href="#启动-YARN（需要先执行过-sbin-start-dfs-sh）：" class="headerlink" title="启动 YARN（需要先执行过 ./sbin/start-dfs.sh）："></a>启动 YARN（需要先执行过 ./sbin/start-dfs.sh）：</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./sbin/start-yarn.sh      $ 启动YARN</span><br><span class="line">./sbin/mr-jobhistory-daemon.sh start historyserver  <span class="comment"># 开启历史服务器，才能在Web中查看任务运行情况</span></span><br></pre></td></tr></table></figure><h4 id="关闭"><a href="#关闭" class="headerlink" title="关闭"></a>关闭</h4><h5 id="关闭-YARN"><a href="#关闭-YARN" class="headerlink" title="关闭 YARN"></a>关闭 YARN</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./sbin/stop-yarn.sh</span><br><span class="line">./sbin/mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure><h5 id="关闭-Hadoop"><a href="#关闭-Hadoop" class="headerlink" title="关闭 Hadoop"></a>关闭 Hadoop</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flume安装</title>
      <link href="/2018/05/02/flume%E5%AE%89%E8%A3%85/"/>
      <url>/2018/05/02/flume%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><p>添加agent节点 </p><p>在BDS部署</p><p>配置环境变量</p><h6 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h6><p><code>cp flume-env.sh.template flume-env.sh</code></p><p>加入jdk和hadoop的环境变量</p><p><code>flume-ng version</code>验证</p><p>创建agent.conf</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#source</span></span><br><span class="line">a1.sources = sysSrc</span><br><span class="line">a1.sources.sysSrc.type=syslogudp</span><br><span class="line">a1.sources.sysSrc.bind=<span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line">a1.sources.sysSrc.port=<span class="number">514</span></span><br><span class="line">a1.sources.sysSrc.channels=fileChannel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#channel</span></span><br><span class="line">a1.channels = fileChannel</span><br><span class="line">a1.channels.fileChannel.type =memory</span><br><span class="line">a1.channels.fileChannel.capacity=<span class="number">100000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#sink</span></span><br><span class="line">a1.sinks = kafkaSink</span><br><span class="line">a1.sinks.kafkaSink.channel=fileChannel</span><br><span class="line">a1.sinks.kafkaSink.type=org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.kafkaSink.brokerList=BDS:<span class="number">9092</span>,BDS-<span class="number">1</span>:<span class="number">9092</span>,BDS-<span class="number">2</span>:<span class="number">9092</span></span><br><span class="line">a1.sinks.kafkaSink.custom.partition.key=kafkaPartition</span><br><span class="line">a1.sinks.kafkaSink.topic=flumetest</span><br><span class="line">a1.sinks.kafkaSink.serializer.class=kafka.serializer.StringEncoder</span><br></pre></td></tr></table></figure><p>启动</p><p><code>bin/flume-ng agent --conf conf --conf-file conf/agent.conf --name a1 -Dflume.root.logger=INFO,console</code></p><p>启动消费者</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/cloudera/parcels/KAFKA-<span class="number">2.1</span>.<span class="number">1</span>-<span class="number">1.2</span>.<span class="number">1.1</span>.p0.<span class="number">18</span>/lib/kafka</span><br><span class="line"></span><br><span class="line">bin/kafka-console-consumer.sh --zookeeper BDS:<span class="number">2181</span>,BDS-<span class="number">1</span>:<span class="number">2181</span>,BDS-<span class="number">2</span>:<span class="number">2181</span> --topic flumetest --from-beginning</span><br></pre></td></tr></table></figure><p>使用测试工具发送信息进行测试 查看消费者是否收到</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>深入剖析volatile关键字</title>
      <link href="/2018/04/28/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90volatile%E5%85%B3%E9%94%AE%E5%AD%97/"/>
      <url>/2018/04/28/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90volatile%E5%85%B3%E9%94%AE%E5%AD%97/</url>
      <content type="html"><![CDATA[<ul><li><a href="#一内存模型的相关概念">一.内存模型的相关概念</a></li><li><a href="#二并发编程中的三个概念">二.并发编程中的三个概念</a><ul><li><a href="#1原子性">1.原子性</a></li><li><a href="#2可见性">2.可见性</a></li><li><a href="#3有序性">3.有序性</a></li></ul></li><li><a href="#三java内存模型">三.Java内存模型</a><ul><li><a href="#1原子性">1.原子性</a></li><li><a href="#2可见性">2.可见性</a></li><li><a href="#3有序性">3.有序性</a></li></ul></li><li><a href="#四深入剖析volatile关键字">四.深入剖析volatile关键字</a><ul><li><a href="#1volatile关键字的两层语义">1.volatile关键字的两层语义</a></li><li><a href="#2volatile保证原子性吗">2.volatile保证原子性吗？</a></li><li><a href="#3volatile能保证有序性吗">3.volatile能保证有序性吗？</a></li></ul></li><li><a href="#五使用volatile关键字的场景">五.使用volatile关键字的场景</a><ul><li><a href="#1状态标记量">1.状态标记量</a></li><li><a href="#2double-check">2.double check</a></li></ul></li></ul><p>&emsp;&emsp;volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。</p><p>&emsp;&emsp;volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。</p><h3 id="一-内存模型的相关概念"><a href="#一-内存模型的相关概念" class="headerlink" title="一.内存模型的相关概念"></a>一.内存模型的相关概念</h3><p>&emsp;&emsp;大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。</p><p>&emsp;&emsp;也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：</p><pre><code>i = i + 1;  </code></pre><p>&emsp;&emsp;当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。</p><p>&emsp;&emsp;这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。</p><p>&emsp;&emsp;比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？</p><p>&emsp;&emsp;可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。</p><p>&emsp;&emsp;最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。<br>　　<br>&emsp;&emsp;也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。</p><p>&emsp;&emsp;为了解决缓存不一致性问题，通常来说有以下2种解决方法：</p><p>&emsp;&emsp;1）通过在总线加LOCK#锁的方式</p><p>&emsp;&emsp;2）通过缓存一致性协议</p><p>&emsp;&emsp;这2种方式都是硬件层面上提供的方式。</p><p>&emsp;&emsp;在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。</p><p>&emsp;&emsp;但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。<br>&emsp;&emsp;所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。<br><img src="http://i1.piimg.com/567571/2c8fdb86b1860315.jpg" alt=""></p><h3 id="二-并发编程中的三个概念"><a href="#二-并发编程中的三个概念" class="headerlink" title="二.并发编程中的三个概念"></a>二.并发编程中的三个概念</h3><pre><code>在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念：</code></pre><h4 id="1-原子性"><a href="#1-原子性" class="headerlink" title="1.原子性"></a>1.原子性</h4><p>&emsp;&emsp;原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p><p>&emsp;&emsp;一个很经典的例子就是银行账户转账问题：</p><p>&emsp;&emsp;比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。</p><p>&emsp;&emsp;试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。</p><p>&emsp;&emsp;所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。</p><p>&emsp;&emsp;同样地反映到并发编程中会出现什么结果呢？</p><p>&emsp;&emsp;举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？</p><pre><code>i = 9;  </code></pre><p>假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。</p><p>那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。           </p><h4 id="2-可见性"><a href="#2-可见性" class="headerlink" title="2.可见性"></a>2.可见性</h4><p>可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</p><p>举个简单的例子，看下面这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//线程1执行的代码  </span></span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;  </span><br><span class="line">i = <span class="number">10</span>;  </span><br><span class="line"></span><br><span class="line"><span class="comment">//线程2执行的代码  </span></span><br><span class="line">j = i;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。</p><p>&emsp;&emsp;此时线程2执行 j =i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.</p><p>&emsp;&emsp;这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。</p><h4 id="3-有序性"><a href="#3-有序性" class="headerlink" title="3.有序性"></a>3.有序性</h4><p>&emsp;&emsp;有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;                </span><br><span class="line"><span class="keyword">boolean</span> flag = <span class="keyword">false</span>;  </span><br><span class="line">i = <span class="number">1</span>;                <span class="comment">//语句1    </span></span><br><span class="line">flag = <span class="keyword">true</span>;          <span class="comment">//语句2</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。</p><p>&emsp;&emsp;下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。</p><p>&emsp;&emsp;比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。</p><p>&emsp;&emsp;但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">10</span>;    <span class="comment">//语句1  </span></span><br><span class="line"><span class="keyword">int</span> r = <span class="number">2</span>;    <span class="comment">//语句2  </span></span><br><span class="line">a = a + <span class="number">3</span>;    <span class="comment">//语句3  </span></span><br><span class="line">r = a*a;     <span class="comment">//语句4</span></span><br></pre></td></tr></table></figure><p>这段代码有4个语句，那么可能的一个执行顺序是：</p><p><img src="http://i2.muimg.com/567571/57f70712db840e39.jpg" alt=""><br>那么可不可能是这个执行顺序呢： 语句2   语句1    语句4   语句3</p><p>&emsp;&emsp;不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。</p><p>&emsp;&emsp;虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//线程1:  </span></span><br><span class="line">context = loadContext();   <span class="comment">//语句1  </span></span><br><span class="line">inited = <span class="keyword">true</span>;             <span class="comment">//语句2  </span></span><br><span class="line"></span><br><span class="line"><span class="comment">//线程2:  </span></span><br><span class="line"><span class="keyword">while</span>(!inited )&#123;  </span><br><span class="line">  sleep()  </span><br><span class="line">&#125;  </span><br><span class="line">doSomethingwithconfig(context);</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此时线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。</p><p>&emsp;&emsp;从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。</p><p>&emsp;&emsp;也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。</p><h3 id="三-Java内存模型"><a href="#三-Java内存模型" class="headerlink" title="三.Java内存模型"></a>三.Java内存模型</h3><p>&emsp;&emsp;在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。</p><p>&emsp;&emsp;在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。</p><p>&emsp;&emsp;Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。</p><p>&emsp;&emsp;举个简单的例子：在java中，执行下面这个语句：</p><pre><code>i  = 10;  </code></pre><p>&emsp;&emsp;执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。</p><p>&emsp;&emsp;那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？</p><h4 id="1-原子性-1"><a href="#1-原子性-1" class="headerlink" title="1.原子性"></a>1.原子性</h4><p>&emsp;&emsp;在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。</p><p>&emsp;&emsp;上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：<br>　　请分析以下哪些操作是原子性操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">10</span>;         <span class="comment">//语句1  </span></span><br><span class="line">y = x;         <span class="comment">//语句2  </span></span><br><span class="line">x++;           <span class="comment">//语句3  </span></span><br><span class="line">x = x + <span class="number">1</span>;     <span class="comment">//语句4</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。</p><p>&emsp;&emsp;语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。</p><p>&emsp;&emsp;语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。</p><p>&emsp;&emsp;同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。</p><p>&emsp;&emsp;所以上面4个语句只有语句1的操作具备原子性。</p><p>&emsp;&emsp;也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。</p><p>&emsp;&emsp;不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。</p><p>&emsp;&emsp;从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。</p><h4 id="2-可见性-1"><a href="#2-可见性-1" class="headerlink" title="2.可见性"></a>2.可见性</h4><p>&emsp;&emsp;对于可见性，Java提供了volatile关键字来保证可见性。</p><p>&emsp;&emsp;当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。</p><p>&emsp;&emsp;而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。</p><p>&emsp;&emsp;另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。</p><h4 id="3-有序性-1"><a href="#3-有序性-1" class="headerlink" title="3.有序性"></a>3.有序性</h4><p>&emsp;&emsp;在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。</p><p>&emsp;&emsp;在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。</p><p>&emsp;&emsp;另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。</p><p>&emsp;&emsp;下面就来具体介绍下happens-before原则（先行发生原则）：</p><ul><li>程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作<ul><li>锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作</li><li>volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作</li><li>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C</li><li>线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作</li><li>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生</li><li>线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行</li><li>对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始</li></ul></li></ul><p>&emsp;&emsp;这8条原则摘自《深入理解Java虚拟机》。</p><p>&emsp;&emsp;这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。</p><p>&emsp;&emsp;下面我们来解释一下前4条规则：</p><p>&emsp;&emsp;对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。</p><p>&emsp;&emsp;第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。</p><p>&emsp;&emsp;第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。</p><p>&emsp;&emsp;第四条规则实际上就是体现happens-before原则具备传递性。</p><h3 id="四-深入剖析volatile关键字"><a href="#四-深入剖析volatile关键字" class="headerlink" title="四.深入剖析volatile关键字"></a>四.深入剖析volatile关键字</h3><p>&emsp;&emsp;在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。</p><h4 id="1-volatile关键字的两层语义"><a href="#1-volatile关键字的两层语义" class="headerlink" title="1.volatile关键字的两层语义"></a>1.volatile关键字的两层语义</h4><p>&emsp;&emsp;一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：</p><pre><code>1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。2）禁止进行指令重排序。</code></pre><p>&emsp;&emsp;先看一段代码，假如线程1先执行，线程2后执行：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//线程1  </span></span><br><span class="line"><span class="keyword">boolean</span> stop = <span class="keyword">false</span>;  </span><br><span class="line"><span class="keyword">while</span>(!stop)&#123;  </span><br><span class="line">doSomething();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">//线程2  </span></span><br><span class="line">stop = <span class="keyword">true</span>;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。</p><p>&emsp;&emsp;下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。</p><p>&emsp;&emsp;那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。</p><p>&emsp;&emsp;但是用volatile修饰之后就变得不一样了：</p><p>&emsp;&emsp;第一：使用volatile关键字会强制将修改的值立即写入主存；</p><p>&emsp;&emsp;第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；</p><p>&emsp;&emsp;第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。</p><p>&emsp;&emsp;那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。</p><p>&emsp;&emsp;那么线程1读取到的就是最新的正确的值。</p><h4 id="2-volatile保证原子性吗？"><a href="#2-volatile保证原子性吗？" class="headerlink" title="2.volatile保证原子性吗？"></a>2.volatile保证原子性吗？</h4><p>&emsp;&emsp;从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？<br>　　<br>&emsp;&emsp;下面看一个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">volatile</span> <span class="keyword">int</span> inc = <span class="number">0</span>;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">inc++;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">final</span> Test test = <span class="keyword">new</span> Test();  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;  </span><br><span class="line"><span class="keyword">new</span> Thread()&#123;  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">1000</span>;j++)  </span><br><span class="line">test.increase();  </span><br><span class="line">&#125;;  </span><br><span class="line">&#125;.start();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(Thread.activeCount()&gt;<span class="number">1</span>)  <span class="comment">//保证前面的线程都执行完  </span></span><br><span class="line">Thread.yield();  </span><br><span class="line">System.out.println(test.inc);  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。</p><p>&emsp;&emsp;可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。</p><p>&emsp;&emsp;这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。</p><p>&emsp;&emsp;在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：</p><p>&emsp;&emsp;假如某个时刻变量inc的值为10，</p><p>&emsp;&emsp;线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；</p><p>&emsp;&emsp;然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。</p><p>&emsp;&emsp;然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。</p><p>&emsp;&emsp;那么两个线程分别进行了一次自增操作后，inc只增加了1。</p><p>&emsp;&emsp;解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。</p><p>&emsp;&emsp;根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。</p><p>&emsp;&emsp;把上面的代码改成以下任何一种都可以达到效果：</p><p>&emsp;&emsp;采用synchronized：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;  </span><br><span class="line"><span class="keyword">public</span>  <span class="keyword">int</span> inc = <span class="number">0</span>;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">inc++;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">final</span> Test test = <span class="keyword">new</span> Test();  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;  </span><br><span class="line"><span class="keyword">new</span> Thread()&#123;  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">1000</span>;j++)  </span><br><span class="line">test.increase();  </span><br><span class="line">&#125;;  </span><br><span class="line">&#125;.start();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(Thread.activeCount()&gt;<span class="number">1</span>)  <span class="comment">//保证前面的线程都执行完  </span></span><br><span class="line">Thread.yield();  </span><br><span class="line">System.out.println(test.inc);  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;采用Lock：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;  </span><br><span class="line"><span class="keyword">public</span>  <span class="keyword">int</span> inc = <span class="number">0</span>;  </span><br><span class="line">Lock lock = <span class="keyword">new</span> ReentrantLock();  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span>  <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">lock.lock();  </span><br><span class="line"><span class="keyword">try</span> &#123;  </span><br><span class="line">inc++;  </span><br><span class="line">&#125; <span class="keyword">finally</span>&#123;  </span><br><span class="line">lock.unlock();  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">final</span> Test test = <span class="keyword">new</span> Test();  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;  </span><br><span class="line"><span class="keyword">new</span> Thread()&#123;  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">1000</span>;j++)  </span><br><span class="line">test.increase();  </span><br><span class="line">&#125;;  </span><br><span class="line">&#125;.start();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(Thread.activeCount()&gt;<span class="number">1</span>)  <span class="comment">//保证前面的线程都执行完  </span></span><br><span class="line">Thread.yield();  </span><br><span class="line">System.out.println(test.inc);  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;采用AtomicInteger：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;  </span><br><span class="line"><span class="keyword">public</span>  AtomicInteger inc = <span class="keyword">new</span> AtomicInteger();  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span>  <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">inc.getAndIncrement();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">final</span> Test test = <span class="keyword">new</span> Test();  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;  </span><br><span class="line"><span class="keyword">new</span> Thread()&#123;  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">1000</span>;j++)  </span><br><span class="line">test.increase();  </span><br><span class="line">&#125;;  </span><br><span class="line">&#125;.start();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(Thread.activeCount()&gt;<span class="number">1</span>)  <span class="comment">//保证前面的线程都执行完  </span></span><br><span class="line">Thread.yield();  </span><br><span class="line">System.out.println(test.inc);  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。</p><h4 id="3-volatile能保证有序性吗？"><a href="#3-volatile能保证有序性吗？" class="headerlink" title="3.volatile能保证有序性吗？"></a>3.volatile能保证有序性吗？</h4><p>&emsp;&emsp;在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。</p><p>&emsp;&emsp;volatile关键字禁止指令重排序有两层意思：</p><pre><code>1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。</code></pre><p>&emsp;&emsp;可能上面说的比较绕，举个简单的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//x、y为非volatile变量  </span></span><br><span class="line"><span class="comment">//flag为volatile变量  </span></span><br><span class="line"></span><br><span class="line">x = <span class="number">2</span>;        <span class="comment">//语句1  </span></span><br><span class="line">y = <span class="number">0</span>;        <span class="comment">//语句2  </span></span><br><span class="line">flag = <span class="keyword">true</span>;  <span class="comment">//语句3  </span></span><br><span class="line">x = <span class="number">4</span>;         <span class="comment">//语句4  </span></span><br><span class="line">y = -<span class="number">1</span>;       <span class="comment">//语句5</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。</p><p>&emsp;&emsp;并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。</p><p>&emsp;&emsp;那么我们回到前面举的一个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//线程1:  </span></span><br><span class="line">context = loadContext();   <span class="comment">//语句1  </span></span><br><span class="line">inited = <span class="keyword">true</span>;             <span class="comment">//语句2  </span></span><br><span class="line"></span><br><span class="line"><span class="comment">//线程2:  </span></span><br><span class="line"><span class="keyword">while</span>(!inited )&#123;  </span><br><span class="line">  sleep()  </span><br><span class="line">&#125;  </span><br><span class="line">doSomethingwithconfig(context);  </span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;前面举这个例子的时候，提到有可能语句<span class="number">2</span>会在语句<span class="number">1</span>之前执行，那么就可能导致context还没被初始化，而线程<span class="number">2</span>中就使用未初始化的context去进行操作，导致程序出错。</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;这里如果用<span class="keyword">volatile</span>关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句<span class="number">2</span>时，必定能保证context已经初始化完毕。</span><br><span class="line"><span class="number">4</span>.<span class="keyword">volatile</span>的原理和实现机制</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;前面讲述了源于<span class="keyword">volatile</span>关键字的一些使用，下面我们来探讨一下<span class="keyword">volatile</span>到底如何保证可见性和禁止指令重排序的。</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;下面这段话摘自《深入理解Java虚拟机》：</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;“观察加入<span class="keyword">volatile</span>关键字和没有加入<span class="keyword">volatile</span>关键字时所生成的汇编代码发现，加入<span class="keyword">volatile</span>关键字时，会多出一个lock前缀指令”</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供<span class="number">3</span>个功能：</span><br><span class="line"></span><br><span class="line">    <span class="number">1</span>）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；</span><br><span class="line">    <span class="number">2</span>）它会强制将对缓存的修改操作立即写入主存；</span><br><span class="line">    <span class="number">3</span>）如果是写操作，它会导致其他CPU中对应的缓存行无效。</span><br><span class="line">### 五.使用volatile关键字的场景</span><br><span class="line">&amp;emsp;&amp;emsp;<span class="keyword">synchronized</span>关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而<span class="keyword">volatile</span>关键字在某些情况下性能要优于<span class="keyword">synchronized</span>，但是要注意<span class="keyword">volatile</span>关键字是无法替代<span class="keyword">synchronized</span>关键字的，因为<span class="keyword">volatile</span>关键字无法保证操作的原子性。通常来说，使用<span class="keyword">volatile</span>必须具备以下<span class="number">2</span>个条件：</span><br><span class="line"></span><br><span class="line">    <span class="number">1</span>）对变量的写操作不依赖于当前值</span><br><span class="line">    <span class="number">2</span>）该变量没有包含在具有其他变量的不变式中</span><br><span class="line">&amp;emsp;&amp;emsp;实际上，这些条件表明，可以被写入 <span class="keyword">volatile</span> 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;事实上，我的理解就是上面的<span class="number">2</span>个条件需要保证操作是原子性操作，才能保证使用<span class="keyword">volatile</span>关键字的程序在并发时能够正确执行。</span><br><span class="line"></span><br><span class="line">&amp;emsp;&amp;emsp;下面列举几个Java中使用<span class="keyword">volatile</span>的几个场景。</span><br><span class="line"></span><br><span class="line">#### 1.状态标记量</span><br><span class="line"></span><br><span class="line">````java</span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">boolean</span> flag = <span class="keyword">false</span>;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(!flag)&#123;  </span><br><span class="line">doSomething();  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFlag</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">flag = <span class="keyword">true</span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">boolean</span> inited = <span class="keyword">false</span>;  </span><br><span class="line"><span class="comment">//线程1:  </span></span><br><span class="line">context = loadContext();    </span><br><span class="line">inited = <span class="keyword">true</span>;              </span><br><span class="line"></span><br><span class="line"><span class="comment">//线程2:  </span></span><br><span class="line"><span class="keyword">while</span>(!inited )&#123;  </span><br><span class="line">sleep()  </span><br><span class="line">&#125;  </span><br><span class="line">doSomethingwithconfig(context);</span><br></pre></td></tr></table></figure><h4 id="2-double-check"><a href="#2-double-check" class="headerlink" title="2.double check"></a>2.double check</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton</span></span>&#123;  </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">null</span>;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"></span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">if</span>(instance==<span class="keyword">null</span>) &#123;  </span><br><span class="line"><span class="keyword">synchronized</span> (Singleton.class) &#123;  </span><br><span class="line"><span class="keyword">if</span>(instance==<span class="keyword">null</span>)  </span><br><span class="line">instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="keyword">return</span> instance;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;于为何;需要这么写请参考：</p><p>&emsp;&emsp;《Java 中的双重检查（Double-Check）》<a href="http://blog.csdn.net/dl88250/article/details/5439024和http://www.iteye.com/topic/652440" target="_blank" rel="noopener">http://blog.csdn.net/dl88250/article/details/5439024和http://www.iteye.com/topic/652440</a></p><p>&emsp;&emsp;参考资料：<br>　　《深入理解Java虚拟机》</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>枚举实现单例连接数据库</title>
      <link href="/2018/04/28/%E6%9E%9A%E4%B8%BE%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2018/04/28/%E6%9E%9A%E4%B8%BE%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      <content type="html"><![CDATA[<p>创建一个jdbc.propertis文件，其内容如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">driverClass = com.mysql.jdbc.Driver</span><br><span class="line">jdbcUrl = jdbc:mysql:<span class="comment">//localhost:3306/liaokailin</span></span><br><span class="line">user = root</span><br><span class="line">password = mysqladmin</span><br><span class="line">maxPoolSize = <span class="number">20</span></span><br><span class="line">minPoolSize = <span class="number">5</span></span><br></pre></td></tr></table></figure><p>创建一个MyDataBaseSource的枚举：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.util.ResourceBundle;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.mchange.v2.c3p0.ComboPooledDataSource;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> MyDataBaseSource &#123;</span><br><span class="line">DATASOURCE;</span><br><span class="line"><span class="keyword">private</span> ComboPooledDataSource cpds = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">MyDataBaseSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">/*--------获取properties文件内容------------*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法一:</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * InputStream is =</span></span><br><span class="line"><span class="comment"> * MyDBSource.class.getClassLoader().getResourceAsStream("jdbc.properties");</span></span><br><span class="line"><span class="comment"> * Properties p = new Properties(); p.load(is);</span></span><br><span class="line"><span class="comment"> * System.out.println(p.getProperty("driverClass") );</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法二：(不需要properties的后缀)</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * ResourceBundle rb = PropertyResourceBundle.getBundle("jdbc") ;</span></span><br><span class="line"><span class="comment"> * System.out.println(rb.getString("driverClass"));</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法三：(不需要properties的后缀)</span></span><br><span class="line">ResourceBundle rs = ResourceBundle.getBundle(<span class="string">"jdbc"</span>);</span><br><span class="line">cpds = <span class="keyword">new</span> ComboPooledDataSource();</span><br><span class="line">cpds.setDriverClass(rs.getString(<span class="string">"driverClass"</span>));</span><br><span class="line">cpds.setJdbcUrl(rs.getString(<span class="string">"jdbcUrl"</span>));</span><br><span class="line">cpds.setUser(rs.getString(<span class="string">"user"</span>));</span><br><span class="line">cpds.setPassword(rs.getString(<span class="string">"password"</span>));</span><br><span class="line">cpds.setMaxPoolSize(Integer.parseInt(rs.getString(<span class="string">"maxPoolSize"</span>)));</span><br><span class="line">cpds.setMinPoolSize(Integer.parseInt(rs.getString(<span class="string">"minPoolSize"</span>)));    </span><br><span class="line"> System.out.println(<span class="string">"-----调用了构造方法------"</span>);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Connection <span class="title">getConnection</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">return</span> cpds.getConnection();</span><br><span class="line">&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">MyDataBaseSource.DATASOURCE.getConnection() ;</span><br><span class="line">MyDataBaseSource.DATASOURCE.getConnection() ;</span><br><span class="line">MyDataBaseSource.DATASOURCE.getConnection() ;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-----调用了构造方法------</span><br><span class="line"><span class="number">2013</span>-<span class="number">7</span>-<span class="number">17</span> <span class="number">17</span>:<span class="number">10</span>:<span class="number">57</span> com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource getPoolManager</span><br><span class="line">信息: Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -&gt; <span class="number">3</span>, acquireRetryAttempts -&gt; <span class="number">30</span>, acquireRetryDelay -&gt; <span class="number">1000</span>, autoCommitOnClose -&gt; <span class="keyword">false</span>, automaticTestTable -&gt; <span class="keyword">null</span>, breakAfterAcquireFailure -&gt; <span class="keyword">false</span>, checkoutTimeout -&gt; <span class="number">0</span>, connectionCustomizerClassName -&gt; <span class="keyword">null</span>, connectionTesterClassName -&gt; com.mchange.v2.c3p0.impl.DefaultConnectionTester, dataSourceName -&gt; <span class="number">1</span>hge16d8v1tgb0wppydrzz|<span class="number">2</span>c1e6b, debugUnreturnedConnectionStackTraces -&gt; <span class="keyword">false</span>, description -&gt; <span class="keyword">null</span>, driverClass -&gt; com.mysql.jdbc.Driver, factoryClassLocation -&gt; <span class="keyword">null</span>, forceIgnoreUnresolvedTransactions -&gt; <span class="keyword">false</span>, identityToken -&gt; <span class="number">1</span>hge16d8v1tgb0wppydrzz|<span class="number">2</span>c1e6b, idleConnectionTestPeriod -&gt; <span class="number">0</span>, initialPoolSize -&gt; <span class="number">3</span>, jdbcUrl -&gt; jdbc:mysql:<span class="comment">//localhost:3306/kaoqin, maxAdministrativeTaskTime -&gt; 0, maxConnectionAge -&gt; 0, maxIdleTime -&gt; 0, maxIdleTimeExcessConnections -&gt; 0, maxPoolSize -&gt; 20, maxStatements -&gt; 0, maxStatementsPerConnection -&gt; 0, minPoolSize -&gt; 5, numHelperThreads -&gt; 3, preferredTestQuery -&gt; null, properties -&gt; &#123;user=******, password=******&#125;, propertyCycle -&gt; 0, statementCacheNumDeferredCloseThreads -&gt; 0, testConnectionOnCheckin -&gt; false, testConnectionOnCheckout -&gt; false, unreturnedConnectionTimeout -&gt; 0, usesTraditionalReflectiveProxies -&gt; false ]</span></span><br></pre></td></tr></table></figure></p><p>很显然获得了三个Connection连接，但是只调用了一次枚举的构造方法,从而通过枚举实现了单例的设计</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>解决maven依赖</title>
      <link href="/2018/04/28/%E8%A7%A3%E5%86%B3maven%E4%BE%9D%E8%B5%96/"/>
      <url>/2018/04/28/%E8%A7%A3%E5%86%B3maven%E4%BE%9D%E8%B5%96/</url>
      <content type="html"><![CDATA[<p>[toc]</p><p>依赖过滤</p><p>（1）单依赖过滤</p><pre><code>同依赖过滤直接处理：可以过滤一个或者多个，如果过滤多个要写多个&lt;exclusion&gt;。这个也解决不了我的问题，或者说解决太麻烦，我那里知道hbase要依赖那些包，记不住。</code></pre><p>Java代码  </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>      </span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.94.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span>   </span><br><span class="line">     <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span>    </span><br><span class="line">           <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span>        </span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>            </span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>    </span><br><span class="line">           <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span>    </span><br><span class="line">     <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>（2）多依赖过滤</p><pre><code>把所以依赖都过滤了。手起刀落~啊，世界都安静了。</code></pre><p>Java代码  </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.94.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>*<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>*<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>编码与乱码</title>
      <link href="/2018/04/28/%E7%BC%96%E7%A0%81%E4%B8%8E%E4%B9%B1%E7%A0%81/"/>
      <url>/2018/04/28/%E7%BC%96%E7%A0%81%E4%B8%8E%E4%B9%B1%E7%A0%81/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="乱码的根源"><a href="#乱码的根源" class="headerlink" title="乱码的根源"></a>乱码的根源</h3><p>源编码与目标编码的不一致. 而中文window系统默认编码GBK,害惨了多少程序员.</p><p>要尽量减少出现乱码,我个人认为要做到5码合一, IDE(Eclipse/idea),页面(jsp/其他模板引擎),应用服务器(tomcat等), 源码(Java源码及周边文件),数据库编码.</p><h3 id="将Eclipse设置为UTF-8"><a href="#将Eclipse设置为UTF-8" class="headerlink" title="将Eclipse设置为UTF-8"></a>将Eclipse设置为UTF-8</h3><p>打开Eclipse安装目录下的eclipse.ini,在最末尾新增一行</p><pre><code>-Dfile.encoding=UTF-8</code></pre><p>修改之后的,重启eclipse即可.</p><h3 id="JSP页面编码"><a href="#JSP页面编码" class="headerlink" title="JSP页面编码"></a>JSP页面编码</h3><pre><code>&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; %&gt;可以设置eclipse的jsp设置</code></pre><h3 id="tomcat编码"><a href="#tomcat编码" class="headerlink" title="tomcat编码"></a>tomcat编码</h3><p>打开 tomcat安装目录下的 binsetenv.bat ,该文件通常不存在,新建之, 添加如下内容</p><pre><code>set JAVA_OPTS=-Dfile.encoding=UTF-8</code></pre><p>打开confserver.conf, 在8080端口所属的Connector节点,添加URIEncoding,可解决大部分GET请求中文乱码的问题</p><pre><code>URIEncoding=&quot;UTF-8&quot;</code></pre><h3 id="源码的编码"><a href="#源码的编码" class="headerlink" title="源码的编码"></a>源码的编码</h3><p>通常情况下, 文件本身的编码,取决于新建文件时,IDE或Project的编码.</p><p>另外一个隐藏的编码,是maven/ant编译java源文件时使用的编码</p><p>maven的配置如下</p><pre><code>&lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</code></pre><h3 id="数据库编码"><a href="#数据库编码" class="headerlink" title="数据库编码"></a>数据库编码</h3><p>通常来说,如果其他4码解决了,那大部分情况下是mysql会出现编码问题</p><p>mysql有4个编码</p><pre><code>Server characterset:    utf8      // 服务器字节集Db     characterset:    utf8      // 当前数据集字节集Client characterset:    utf8      // 客户端字节集Conn.  characterset:    utf8      // 当前连接的字节集</code></pre><p>修改my.ini的mysqld小节,设置服务器字符集,是最佳解决方式</p><pre><code>[mysqld]character-set-server = utf8</code></pre><p>然而,对于现有系统,全局修改的风险比较大,所以,可以在客户端解决,即jdbcurl上做配置</p><pre><code>jdbc:mysql://127.0.0.1/nutzdemo?useUnicode=true&amp;characterEncoding=UTF-8</code></pre><h3 id="Nutz的相关日志"><a href="#Nutz的相关日志" class="headerlink" title="Nutz的相关日志"></a>Nutz的相关日志</h3><p>nutz在启动时也会打印周围的编码信息,帮助排查.</p><pre><code>21:22:23.235 INFO  (NutLoading.java:55) load - Nutz Version : 1.r.59 21:22:23.235 INFO  (NutLoading.java:56) load - Nutz.Mvc[nutz] is initializing ...21:22:23.235 DEBUG (NutLoading.java:60) load - Web Container Information:21:22:23.237 DEBUG (NutLoading.java:61) load -  - Default Charset : UTF-821:22:23.237 DEBUG (NutLoading.java:62) load -  - Current . path  : D:\nutzbook\eclipse\.21:22:23.237 DEBUG (NutLoading.java:63) load -  - Java Version    : 1.8.0_11221:22:23.237 DEBUG (NutLoading.java:65) load -  - Timezone        : Asia/Shanghai21:22:23.238 DEBUG (NutLoading.java:66) load -  - OS              : Windows 7 amd6421:22:23.238 DEBUG (NutLoading.java:67) load -  - ServerInfo      : Apache Tomcat/9.0.0.M1321:22:23.238 DEBUG (NutLoading.java:68) load -  - Servlet API     : 4.021:22:23.238 DEBUG (NutLoading.java:73) load -  - ContextPath     : /nutzbook21:22:25.134 DEBUG (DaoSupport.java:199) invoke - JDBC Name   --&gt; MySQL Connector Java21:22:25.135 DEBUG (DaoSupport.java:201) invoke - JDBC URL    --&gt; jdbc:mysql://127.0.0.1:3306/nutzbook21:22:25.145 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_client=utf821:22:25.146 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_connection=utf821:22:25.146 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_database=utf821:22:25.146 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_filesystem=binary21:22:25.146 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_results=21:22:25.146 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_server=utf821:22:25.147 DEBUG (MysqlJdbcExpert.java:212) checkDataSource - Mysql : character_set_system=utf8</code></pre><p>Default Charset的编码,在Eclipse环境内, 通过eclipse.ini调整,在tomcat内的话,通过setenv.bat调整.</p><p>mysql的编码,通过修改my.ini或jdbc url进行调整</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>sql</title>
      <link href="/2018/04/28/sql/"/>
      <url>/2018/04/28/sql/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h4 id="时间分区表查询出指定日期-精确到天-的数据量"><a href="#时间分区表查询出指定日期-精确到天-的数据量" class="headerlink" title="时间分区表查询出指定日期(精确到天)的数据量"></a>时间分区表查询出指定日期(精确到天)的数据量</h4><p>数据库有一列为</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930dc8090c95.png" alt="下载.png"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String sql = <span class="string">"select count(*) from "</span>+libraryName+<span class="string">"."</span>+schemaName+<span class="string">"."</span> +tableName+<span class="string">" where to_char(OCCUR_TIME,'yyyy-mm-dd')='"</span>+dateStr+<span class="string">"'"</span>;</span><br></pre></td></tr></table></figure><h4 id="小松鼠执行hive-sql的时候出现missing-EFO-near…"><a href="#小松鼠执行hive-sql的时候出现missing-EFO-near…" class="headerlink" title="小松鼠执行hive sql的时候出现missing EFO near…"></a>小松鼠执行hive sql的时候出现missing EFO near…</h4><p>注意sql栏的状态是否上边藏了几个sql，有的话清掉。</p><h4 id="Hbase的sql时间查询-查询某天的-HAPPENTIME类型为-TIMESTAMP"><a href="#Hbase的sql时间查询-查询某天的-HAPPENTIME类型为-TIMESTAMP" class="headerlink" title="Hbase的sql时间查询  查询某天的 HAPPENTIME类型为:TIMESTAMP"></a>Hbase的sql时间查询  查询某天的 HAPPENTIME类型为:TIMESTAMP</h4><pre><code>select * from FJUDM4.HBASE_MD_OMS_T_COMBINEMONITOR_BUG where HAPPENTIME&gt;=to_date(&apos;2016-10-12 00:00:00&apos;) and HAPPENTIME&lt;to_date(&apos;2016-10-13 00:00:00&apos;)</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/02/5930dc8079553.png" alt="下载 (1).png"></p><h4 id="hive的sql时间分区查询"><a href="#hive的sql时间分区查询" class="headerlink" title="hive的sql时间分区查询"></a>hive的sql时间分区查询</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select * from fjudm4.hbase_md_all_op_ctrl where occur_time &gt;= <span class="number">2016</span>-<span class="number">11</span>-<span class="number">01</span> and occur_time &lt; <span class="number">2016</span>-<span class="number">11</span>-<span class="number">02</span></span><br><span class="line">没有加单引号报错</span><br><span class="line"></span><br><span class="line">select * from fjudm4.hbase_md_all_op_ctrl where occur_time = <span class="string">'2016-11-01'</span></span><br><span class="line">不可以直接用=</span><br><span class="line"></span><br><span class="line">select * from fjudm4.hbase_md_all_op_ctrl where occur_time &gt;= <span class="string">'2016-11-01'</span> and occur_time &lt; <span class="string">'2016-11-02'</span></span><br><span class="line">正确语法</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark学习记录</title>
      <link href="/2018/04/28/spark%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
      <url>/2018/04/28/spark%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h3><p> 用spark-submit命令提交任务运行，具体使用查看：spark-submit –help</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  --master MASTER_URL         spark:<span class="comment">//host:port, mesos://host:port, yarn, or local.</span></span><br><span class="line">  --deploy-<span class="function">mode DEPLOY_MODE   Whether to launch the driver program <span class="title">locally</span> <span class="params">(<span class="string">"client"</span>)</span> or</span></span><br><span class="line"><span class="function">                              on one of the worker machines inside the <span class="title">cluster</span> <span class="params">(<span class="string">"cluster"</span>)</span></span></span><br><span class="line"><span class="function">                              <span class="params">(Default: client)</span>.</span></span><br><span class="line"><span class="function">  --class CLASS_NAME          Your application's main <span class="title">class</span> <span class="params">(<span class="keyword">for</span> Java / Scala apps)</span>.</span></span><br><span class="line"><span class="function">  --name NAME                 A name of your application.</span></span><br><span class="line"><span class="function">  --jars JARS                 Comma-separated list of local jars to include on the driver</span></span><br><span class="line"><span class="function">                              and executor classpaths.</span></span><br><span class="line"><span class="function">  --packages                  Comma-separated list of maven coordinates of jars to include</span></span><br><span class="line"><span class="function">                              on the driver and executor classpaths. Will search the local</span></span><br><span class="line"><span class="function">                              maven repo, then maven central and any additional remote</span></span><br><span class="line"><span class="function">                              repositories given by --repositories. The format <span class="keyword">for</span> the</span></span><br><span class="line"><span class="function">                              coordinates should be groupId:artifactId:version.</span></span><br><span class="line"><span class="function">  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude <span class="keyword">while</span></span></span><br><span class="line"><span class="function">                              resolving the dependencies provided in --packages to avoid</span></span><br><span class="line"><span class="function">                              dependency conflicts.</span></span><br><span class="line"><span class="function">  --repositories              Comma-separated list of additional remote repositories to</span></span><br><span class="line"><span class="function">                              search <span class="keyword">for</span> the maven coordinates given with --packages.</span></span><br><span class="line"><span class="function">  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place</span></span><br><span class="line"><span class="function">                              on the PYTHONPATH <span class="keyword">for</span> Python apps.</span></span><br><span class="line"><span class="function">  --files FILES               Comma-separated list of files to be placed in the working</span></span><br><span class="line"><span class="function">                              directory of each executor.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  --conf PROP</span>=VALUE           Arbitrary Spark configuration property.</span><br><span class="line">  --properties-file FILE      Path to a file from which to load extra properties. If not</span><br><span class="line">                              specified, <span class="keyword">this</span> will look <span class="keyword">for</span> conf/spark-defaults.conf.</span><br><span class="line"></span><br><span class="line">  --driver-<span class="function">memory MEM         Memory <span class="keyword">for</span> <span class="title">driver</span> <span class="params">(e.g. <span class="number">1000</span>M, <span class="number">2</span>G)</span> <span class="params">(Default: <span class="number">1024</span>M)</span>.</span></span><br><span class="line"><span class="function">  --driver-java-options       Extra Java options to pass to the driver.</span></span><br><span class="line"><span class="function">  --driver-library-path       Extra library path entries to pass to the driver.</span></span><br><span class="line"><span class="function">  --driver-class-path         Extra class path entries to pass to the driver. Note that</span></span><br><span class="line"><span class="function">                              jars added with --jars are automatically included in the</span></span><br><span class="line"><span class="function">                              classpath.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  --executor-memory MEM       Memory per <span class="title">executor</span> <span class="params">(e.g. <span class="number">1000</span>M, <span class="number">2</span>G)</span> <span class="params">(Default: <span class="number">1</span>G)</span>.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  --proxy-user NAME           User to impersonate when submitting the application.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  --help, -h                  Show <span class="keyword">this</span> help message and exit</span></span><br><span class="line"><span class="function">  --verbose, -v               Print additional debug output</span></span><br><span class="line"><span class="function">  --version,                  Print the version of current Spark</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> Spark standalone with cluster deploy mode only:</span></span><br><span class="line"><span class="function">  --driver-cores NUM          Cores <span class="keyword">for</span> <span class="title">driver</span> <span class="params">(Default: <span class="number">1</span>)</span>.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> Spark standalone or Mesos with cluster deploy mode only:</span></span><br><span class="line"><span class="function">  --supervise                 If given, restarts the driver on failure.</span></span><br><span class="line"><span class="function">  --kill SUBMISSION_ID        If given, kills the driver specified.</span></span><br><span class="line"><span class="function">  --status SUBMISSION_ID      If given, requests the status of the driver specified.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> Spark standalone and Mesos only:</span></span><br><span class="line"><span class="function">  --total-executor-cores NUM  Total cores <span class="keyword">for</span> all executors.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> Spark standalone and YARN only:</span></span><br><span class="line"><span class="function">  --executor-cores NUM        Number of cores per executor. <span class="params">(Default: <span class="number">1</span> in YARN mode,</span></span></span><br><span class="line"><span class="function"><span class="params">                              or all available cores on the worker in standalone mode)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> YARN-only:</span></span><br><span class="line"><span class="function">  --driver-cores NUM          Number of cores used by the driver, only in cluster mode</span></span><br><span class="line"><span class="function">                              <span class="params">(Default: <span class="number">1</span>)</span>.</span></span><br><span class="line"><span class="function">  --queue QUEUE_NAME          The YARN queue to submit <span class="title">to</span> <span class="params">(Default: <span class="string">"default"</span>)</span>.</span></span><br><span class="line"><span class="function">  --num-executors NUM         Number of executors to <span class="title">launch</span> <span class="params">(Default: <span class="number">2</span>)</span>.</span></span><br><span class="line"><span class="function">  --archives ARCHIVES         Comma separated list of archives to be extracted into the</span></span><br><span class="line"><span class="function">                              working directory of each executor.</span></span><br><span class="line"><span class="function">  --principal PRINCIPAL       Principal to be used to login to KDC, <span class="keyword">while</span> running on</span></span><br><span class="line"><span class="function">                              secure HDFS.</span></span><br><span class="line"><span class="function">  --keytab KEYTAB             The full path to the file that contains the keytab <span class="keyword">for</span> the</span></span><br><span class="line"><span class="function">                              principal specified above. This keytab will be copied to</span></span><br><span class="line"><span class="function">                              the node running the Application Master via the Secure</span></span><br><span class="line"><span class="function">                              Distributed Cache, <span class="keyword">for</span> renewing the login tickets and the</span></span><br><span class="line"><span class="function">                              delegation tokens periodically.</span></span><br></pre></td></tr></table></figure><h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><p> Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources</p><pre><code>当前的集群的可用资源不能满足应用程序所请求的资源。我spark submit的时候给的资源太大了资源分2类： cores 和 ramCore代表对执行可用的executor slotsRam代表每个Worker上被需要的空闲内存来运行你的Application。解决方法：应用不要请求多余空闲可用资源的关闭掉已经执行结束的Application</code></pre><h3 id="spark-submit执行命令"><a href="#spark-submit执行命令" class="headerlink" title="spark-submit执行命令"></a>spark-submit执行命令</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master spark:<span class="comment">//FJ-DCLOUD-HDP01:7077 --conf "spark.scheduler.mode=FAIR" --total-executor-cores 8 --driver-memory 20g --executor-memory 20g /home/yarn/dev/cyb/a.jar </span></span><br><span class="line"></span><br><span class="line">a.jar不需要jar包   所要用的jar包放到spark服务器的lib下  例如：</span><br><span class="line">/home/yarn/spark-<span class="number">1.5</span>.2-bin-hadoop2.6/lib</span><br><span class="line">命令会默认读取改路径下的jar</span><br><span class="line">关于此设置的配置 见下条</span><br></pre></td></tr></table></figure><h3 id="spark-submit指定服务器jar包配置"><a href="#spark-submit指定服务器jar包配置" class="headerlink" title="spark-submit指定服务器jar包配置"></a>spark-submit指定服务器jar包配置</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[yarn@EPRI-DCLOUD-ETL01 conf]$ pwd</span><br><span class="line">/home/yarn/spark-<span class="number">1.5</span>.<span class="number">2</span>-bin-hadoop2.<span class="number">6</span>/conf</span><br><span class="line">[root@EPRI-DCLOUD-ETL01 conf]<span class="comment"># ls</span></span><br><span class="line">docker.properties.template  fairscheduler.xml.template  hive-site.xml  log4j.properties  metrics.properties.template  slaves  spark-defaults.conf  spark-env.sh</span><br><span class="line">[root@EPRI-DCLOUD-ETL01 conf]<span class="comment"># vi spark-env.sh </span></span><br><span class="line"></span><br><span class="line">export SPARK_YARN_MODE=true</span><br><span class="line">export MASTER=yarn-client</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.<span class="number">7.0</span>_55</span><br><span class="line">export SCALA_HOME=/usr/share/scala-<span class="number">2.11</span>.<span class="number">6</span></span><br><span class="line">export SPARK_MASTER_IP=EPRI-DCLOUD-HDP01</span><br><span class="line">export SPARK_CLASSPATH=<span class="variable">$SPARK_CLASSPATH:</span>/usr/share/spark-<span class="number">1.5</span>.<span class="number">2</span>-bin-hadoop2.<span class="number">6</span>/lib/*:/usr/share/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/*:/usr/share/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/etc/*:/usr/share/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/lib/*</span><br><span class="line">export HADOOP_HOME=/usr/share/hadoop-<span class="number">2.6</span>.<span class="number">0</span>export HADOOP_CONF_DIR=/usr/share/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/etc/hadoop</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MariaDB安装及操作</title>
      <link href="/2018/04/28/MariaDB%E5%AE%89%E8%A3%85%E5%8F%8A%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/04/28/MariaDB%E5%AE%89%E8%A3%85%E5%8F%8A%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="准备软件"><a href="#准备软件" class="headerlink" title="准备软件"></a>准备软件</h3><pre><code>cupid-mariadb-5.5.52mariadb-5.5.31-winx64</code></pre><h3 id="安装步奏"><a href="#安装步奏" class="headerlink" title="安装步奏"></a>安装步奏</h3><p>解压缩软件<br>文件夹中，一般包含5个MySQL自带的配置文件，</p><pre><code>my-small.ini、my-medium.ini、my-large.ini、my-huge.ini和my-innodb-heavy-4G.ini，</code></pre><p>请你根据自己机器的内存大小，选择其一，并把它重新命名为my.ini用作基本配置文件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[WinMySQLAdmin]</span><br><span class="line">Server=D:\YuanBo_Chi\mariadb-<span class="number">5.5</span>.31-winx64\bin\mysqld.exe</span><br><span class="line"></span><br><span class="line">[client]</span><br><span class="line">#password= [your_password]</span><br><span class="line">port= <span class="number">3306</span></span><br><span class="line">socket= /tmp/mysql.sock</span><br><span class="line"><span class="keyword">default</span>-character-set=utf-<span class="number">8</span></span><br><span class="line"></span><br><span class="line"># *** Application-specific options follow here ***</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># The MariaDB server</span><br><span class="line">#</span><br><span class="line">[mysqld]</span><br><span class="line"></span><br><span class="line"># generic configuration options</span><br><span class="line">port= <span class="number">3306</span></span><br><span class="line">socket= /tmp/mysql.sock</span><br><span class="line">basedir=D:\YuanBo_Chi\mariadb-<span class="number">5.5</span>.31-winx64</span><br><span class="line">datadir=D:\YuanBo_Chi\mariadb-<span class="number">5.5</span>.31-winx64\data</span><br><span class="line"><span class="keyword">default</span>-character-set=utf-<span class="number">8</span></span><br></pre></td></tr></table></figure><p>在目录下运行 mysqld –install servicename则会创建名为servicename的Windows服务。我使用的是</p><pre><code>mysqld --install MariaDB </code></pre><p>等待成功后，<br>输入 </p><pre><code>net start MariaDB </code></pre><p>即可启动服务开始你的MariaDB之旅了。<br> 如果需要停止该服务，</p><p> 输入 </p><pre><code>net stop MariaDB </code></pre><p>即可停止服务<br>将创建完的服务的启动类型设为自动启动，并启动MariaDB。启动MariaDB时，会在data目录内创建数据文件和日志文件。</p><p>注：启动后的MariaDB 有一个默认的 root用户，其访问密码为空。修改密码的方法与MySQL类似，执行如下命令，即可修改root的访问密码。</p><pre><code>mysqladmin -u root password &quot;root&quot;</code></pre><p>顺便提一句，删除的时候也很简单，输入 </p><pre><code>mysqld.exe --remove MariaDB</code></pre><p>即可    </p><h3 id="图形化操作"><a href="#图形化操作" class="headerlink" title="图形化操作"></a>图形化操作</h3><p>下载Navicat Premium</p><p>链接MariaDB</p><p><img src="http://i4.buimg.com/1949/8e38fb3dd22b97d8.png" alt="Markdown"></p><p>ok</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Log4j</title>
      <link href="/2018/04/28/LOG4J/"/>
      <url>/2018/04/28/LOG4J/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="个人配置"><a href="#个人配置" class="headerlink" title="个人配置"></a>个人配置</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">### 设置###</span><br><span class="line">log4j.rootLogger = info,stdout,D</span><br><span class="line"></span><br><span class="line">### 输出信息到控制抬 ###</span><br><span class="line">log4j.appender.stdout = org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.stdout.Target = System.out</span><br><span class="line">log4j.appender.stdout.layout = org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern = [%-<span class="number">5</span>p] %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; method:%l%n%m%n</span><br><span class="line"></span><br><span class="line">### 输出DEBUG 级别以上的日志到=E://logs/error.log ###</span><br><span class="line">log4j.appender.D = org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.D.Append = <span class="keyword">true</span></span><br><span class="line">log4j.appender.D.Threshold = DEBUG</span><br><span class="line">log4j.appender.D.layout = org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125;  [ %t:%r ] - [ %p ]  %m%n</span><br><span class="line"></span><br><span class="line">### 输出ERROR 级别以上的日志到=E://logs/error.log ###</span><br></pre></td></tr></table></figure><h3 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h3><p>日志记录器(Logger)是日志处理的核心组件。log4j具有5种正常级别(Level)。日志记录器(Logger)的可用级别Level (不包括自定义级别 Level)， 以下内容就是摘自log4j API (<a href="http://jakarta.apache.org/log4j/docs/api/index.html)" target="_blank" rel="noopener">http://jakarta.apache.org/log4j/docs/api/index.html)</a>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> Level WARN</span><br><span class="line">WARN level表明会出现潜在错误的情形。</span><br><span class="line"><span class="keyword">static</span> Level ERROR</span><br><span class="line">ERROR level指出虽然发生错误事件，但仍然不影响系统的继续运行。</span><br><span class="line"><span class="keyword">static</span> Level FATAL</span><br><span class="line">FATAL level指出每个严重的错误事件将会导致应用程序的退出。</span><br><span class="line">另外，还有两个可用的特别的日志记录级别: (以下描述来自log4j APIhttp:<span class="comment">//jakarta.apache.org/log4j/docs/api/index.html):</span></span><br><span class="line"><span class="keyword">static</span> Level ALL</span><br><span class="line">ALL Level是最低等级的，用于打开所有日志记录。</span><br><span class="line"><span class="keyword">static</span> Level OFF</span><br><span class="line">OFF Level是最高等级的，用于关闭所有日志记录。</span><br></pre></td></tr></table></figure><p>日志记录器（Logger）的行为是分等级的。如下表所示：<br>分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者您定义的级别。Log4j建议只使用四个级别，优先级从高到低分别是 ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来，也是说大于等于的级别的日志才输出。</p><p>日志记录的级别有继承性，子类会记录父类的所有的日志级别。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">logger日志设置：</span><br><span class="line"><span class="number">1</span>、加包：log4j-<span class="number">1.2</span>.16.jar  一般还会加入 commons-logging-<span class="number">1.1</span>.1.jar</span><br><span class="line"><span class="number">2</span>、在CLASSPATH 下建立log4j.properties</span><br><span class="line"></span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </span><br><span class="line">log4j.appender.stdout.Target=System.out  </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %<span class="number">5</span>p %c&#123;<span class="number">1</span>&#125;:%L - %m%n  </span><br><span class="line"></span><br><span class="line">log4j.appender.file=org.apache.log4j.RollingFileAppender  </span><br><span class="line">log4j.appender.file.File=$&#123;catalina.home&#125;/logs/ddoMsg.log  </span><br><span class="line">#log4j.appender.file.File=D:/SmgpAppService/logs/smgpApp.log  </span><br><span class="line">log4j.appender.file.MaxFileSize=<span class="number">1024</span>KB  </span><br><span class="line">log4j.appender.file.MaxBackupIndex=<span class="number">100</span>  </span><br><span class="line">log4j.appender.file.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.file.layout.ConversionPattern= %d&#123;yyyy-MM-dd HH:mm:ss&#125; %<span class="number">5</span>p %c %t: - %m%n  </span><br><span class="line"></span><br><span class="line">#INFO WARN ERROR DEBUG  </span><br><span class="line">log4j.rootLogger=WARN, file, stdout  </span><br><span class="line">#log4j.rootLogger=INFO,stdout  </span><br><span class="line">org.apache.commons.logging.Log=org.apache.commons.logging.impl.SimpleLog  </span><br><span class="line">#org.apache.commons.logging.simplelog.log.org.apache.commons.digester.Digester=debug  </span><br><span class="line">#org.apache.commons.logging.simplelog.log.org.apache.commons.digester.ObjectCreateRule=debug  </span><br><span class="line">#org.apache.commons.logging.simplelog.log.org.apache.commons.digester.Digester.sax=info  </span><br><span class="line"></span><br><span class="line">log4j.logger.com.jason.ddoMsg=debug</span><br></pre></td></tr></table></figure><p>在要输出的日志的类中<br>定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> org.apache.log4j.Logger logger = Logger.getLogger(类名.class);</span><br><span class="line">在类输位置：logger.info(XXX);</span><br></pre></td></tr></table></figure><p>logger 配置说明：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、 log4j.rootLogger=INFO, stdout , R</span><br><span class="line"></span><br><span class="line">此句为将等级为INFO的日志信息输出到stdout和R这两个目的地，stdout和R的定义在下面的代码，可以任意起名。等级可分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL，如果配置OFF则不打出任何信息，如果配置为INFO这样只显示INFO, WARN, ERROR的log信息，而DEBUG信息不会被显示，具体讲解可参照第三部分定义配置文件中的logger。</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>、log4j.appender.stdout=org.apache.log4j.ConsoleAppender</span><br><span class="line"></span><br><span class="line">此句为定义名为stdout的输出端是哪种类型，可以是</span><br><span class="line"></span><br><span class="line">org.apache.log4j.ConsoleAppender（控制台），</span><br><span class="line"></span><br><span class="line">org.apache.log4j.FileAppender（文件），</span><br><span class="line"></span><br><span class="line">org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），</span><br><span class="line"></span><br><span class="line">org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）</span><br><span class="line"></span><br><span class="line">org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>、log4j.appender.stdout.layout=org.apache.log4j.PatternLayout</span><br><span class="line"></span><br><span class="line">此句为定义名为stdout的输出端的layout是哪种类型，可以是</span><br><span class="line"></span><br><span class="line">org.apache.log4j.HTMLLayout（以HTML表格形式布局），</span><br><span class="line"></span><br><span class="line">org.apache.log4j.PatternLayout（可以灵活地指定布局模式），</span><br><span class="line"></span><br><span class="line">org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），</span><br><span class="line"></span><br><span class="line">org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>、log4j.appender.stdout.layout.ConversionPattern= [QC] %p [%t] %C.%M(%L) | %m%n</span><br><span class="line"></span><br><span class="line">如果使用pattern布局就要指定的打印信息的具体格式ConversionPattern，打印参数如下：</span><br><span class="line"></span><br><span class="line">%m 输出代码中指定的消息</span><br><span class="line"></span><br><span class="line">%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL</span><br><span class="line"></span><br><span class="line">%r 输出自应用启动到输出该log信息耗费的毫秒数</span><br><span class="line"></span><br><span class="line">%c 输出所属的类目，通常就是所在类的全名</span><br><span class="line"></span><br><span class="line">%t 输出产生该日志事件的线程名</span><br><span class="line"></span><br><span class="line">%n 输出一个回车换行符，Windows平台为“rn”，Unix平台为“n”</span><br><span class="line"></span><br><span class="line">%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyyy MMM dd HH:mm:ss,SSS&#125;，输出类似：<span class="number">2002</span>年<span class="number">10</span>月<span class="number">18</span>日 <span class="number">22</span>：<span class="number">10</span>：<span class="number">28</span>，<span class="number">921</span></span><br><span class="line"></span><br><span class="line">%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。</span><br><span class="line"></span><br><span class="line">[QC]是log信息的开头，可以为任意字符，一般为项目简称。</span><br><span class="line"></span><br><span class="line">输出的信息</span><br><span class="line"></span><br><span class="line">[TS] DEBUG [main] AbstractBeanFactory.getBean(<span class="number">189</span>) | Returning cached instance of singleton bean <span class="string">'MyAutoProxy'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>、 log4j.appender.R=org.apache.log4j.DailyRollingFileAppender</span><br><span class="line"></span><br><span class="line">此句与第<span class="number">3</span>行一样。定义名为R的输出端的类型为每天产生一个日志文件。</span><br><span class="line"></span><br><span class="line"><span class="number">6</span>、log4j.appender.R.File=D:\\Tomcat <span class="number">5.5</span>\\logs\\qc.log</span><br><span class="line"></span><br><span class="line">此句为定义名为R的输出端的文件名为D:\\Tomcat <span class="number">5.5</span>\\logs\\qc.log可以自行修改。</span><br><span class="line"></span><br><span class="line"><span class="number">7</span>、 log4j.appender.R.layout=org.apache.log4j.PatternLayout</span><br><span class="line"></span><br><span class="line">与第<span class="number">4</span>行相同。</span><br><span class="line"></span><br><span class="line"><span class="number">8</span>、 log4j.appender.R.layout.ConversionPattern=%d-[TS] %p %t %c - %m%n</span><br><span class="line"></span><br><span class="line">与第<span class="number">5</span>行相同。</span><br><span class="line"></span><br><span class="line"><span class="number">9</span>、 log4j.logger.com. neusoft =DEBUG</span><br><span class="line"></span><br><span class="line">指定com.neusoft包下的所有类的等级为DEBUG。</span><br><span class="line"></span><br><span class="line">可以把com.neusoft改为自己项目所用的包名。</span><br><span class="line"></span><br><span class="line"><span class="number">10</span>、  log4j.logger.com.opensymphony.oscache=ERROR</span><br><span class="line"></span><br><span class="line"><span class="number">11</span>、 log4j.logger.NET.sf.navigator=ERROR</span><br><span class="line"></span><br><span class="line">这两句是把这两个包下出现的错误的等级设为ERROR，如果项目中没有配置EHCache，则不需要这两句。</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>、log4j.logger.org.apache.commons=ERROR</span><br><span class="line"></span><br><span class="line"><span class="number">13</span>、 log4j.logger.org.apache.struts=WARN</span><br><span class="line"></span><br><span class="line">这两句是struts的包。</span><br><span class="line"></span><br><span class="line"><span class="number">14</span>、  log4j.logger.org.displaytag=ERROR</span><br><span class="line"></span><br><span class="line">这句是displaytag的包。（QC问题列表页面所用）</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>、 log4j.logger.org.springframework=DEBUG</span><br><span class="line"></span><br><span class="line">此句为spring的包。</span><br><span class="line"></span><br><span class="line"><span class="number">16</span>、 log4j.logger.org.hibernate.ps.PreparedStatementCache=WARN</span><br><span class="line"></span><br><span class="line"><span class="number">17</span>、log4j.logger.org.hibernate=DEBUG</span><br><span class="line"></span><br><span class="line">此两句是hibernate的包。</span><br><span class="line"></span><br><span class="line">以上这些包的设置可根据项目的实际情况而自行定制。</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM性能优化， Part 5  ―― Java的伸缩性</title>
      <link href="/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%205%20%20%E2%80%95%E2%80%95%20Java%E7%9A%84%E4%BC%B8%E7%BC%A9%E6%80%A7/"/>
      <url>/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%205%20%20%E2%80%95%E2%80%95%20Java%E7%9A%84%E4%BC%B8%E7%BC%A9%E6%80%A7/</url>
      <content type="html"><![CDATA[<p>很多程序员在解决JVM性能问题的时候，花开了很多时间去调优应用程序级别的性能瓶颈，当你读完这本系列文章之后你会发现我可能更加系统地看待这类的问题。我说过JVM的自身技术限制了Java企业级应用的伸缩性。首先我们先列举一些主导因素。</p><ul><li><p>主流的硬件服务器提供了大量的内存</p></li><li><p>分布式系统有大量内存的需求，而且该需求在持续增长</p></li><li><p>一个普通Java应用程序所持有的对空间大概在1GB~4GB，这远远低于一个硬件服务器的内存管理能力以及一个分布式应用程序的内存需求量。这被称之为Java内存墙，如下图所示(图中表述Java应用服务器和常规Java应用的内存使用量的演变史)。</p></li></ul><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180423/aH8h1m3BJ4.png?imageslim" alt="mark"></p><p>Java内存墙(1980~2010)   (图片来源：Azul Systems)</p><p>这给我们带来了如下JVM性能课题：</p><p>1) 如果分配给应用程序的内存太小，将导致内存不足。JVM 不能及时释放内存空间给应用程序，最终将引发内存不足，或者JVM完全关闭。所以你必须提供更多的内存给应用程序。</p><p>2) 如果给对响应时间敏感的应用增加内存，如果不重启你的系统或者优化你的应用，Java堆最终会碎片化。当碎片发生时，可能会导致应用中断100毫秒~100秒，这取决与你的Java应用，Java堆的大小以及其他的JVM调优参数。</p><p>关于停顿的讨论大部分都集中在平均停顿或者目标停顿，很少涉及到堆压缩时的最坏停顿时间，在生产环境中堆中每千兆字节的有效数据的都将会发生大约1秒的停顿。</p><p>2 ~ 4秒的停顿对大多数企业应用来说都是不能接受的，所以尽管实际的Java应用实例可能需要更多的内存空间，但实际只分配2~4GB的内存。在一些64位系统中带有很多关于伸缩性的JVM调优项，使得这些系统可以运行16GB乃至20GB的堆空间，并能满足典型响应时间的SLA。但是这些离现实较远，JVM目前的技术无法在进行堆压缩时避免停顿应用程序。Java应用开发人员苦于处理这两个为我们大多数人所抱怨的任务。</p><ul><li><p>架构/建模在大量的实例池之上，随之而来的是复杂的监控和管理操作。</p></li><li><p>反复的JVM和应用程序调优以避免“stop the world“引起的停顿。大多数程序员希望停顿不要发生在系统峰值负载期间。我称之为不可能的目标。</p></li></ul><p>现在让我们深入一点Java的可伸缩性问题。</p><p><strong>过度供给或过度实例化Java部署</strong></p><p>为了充分利用内存资源，普通的做法是将Java应用部署在多个应用服务器实例上而不是一个或者少数应用服务器实例上。当一台Server上运行16个应用服务器实例可以充分利用所有的内存资源，但如此无法解决的是多实例的监控以及管理所带来的成本，尤其是当你的应用部署在多个Server上。</p><p>另一个问题来了，峰值负载时的内存资源不是每天都需要的，这样就形成了巨大的浪费。有些情况下，一台物理机上可能只不是不超过3个“大应用服务器实例”，这样的部署更加不够经济也不够环保，尤其在非峰值负载期间。</p><p>让我们来比较一下这两种部署架构，下图中左边是多而小的应用服务器实例部署模式，右边是少而大的应用服务器实例部署模式。两种模式处理同样的负载，究竟哪一种部署架构更具经济性。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180423/c09mCc1LCK.png?imageslim" alt="mark"></p><p>大应用服务器部署场景 (图片来源：Azul Systems)</p><p>如我之前说过的，并发压缩使得大应用服务器部署模式变得可行，而且可以突破JVM可伸缩性的限制。目前只有Azul的Zing JVM可以提供并发压缩的技术，另外Zing是Server侧的JVM，我们很乐意看到越来越多的开发者在JVM层面去挑战Java可伸缩性的问题。</p><p>由于性能调优仍然是我们解决Java可伸缩性问题的主要手段，我们先来看有哪些主要的调优参数以及通过它们能达到什么样的效果。</p><p><strong>调优参数：一些事例</strong></p><p>最著名的调优参数莫过于”-Xmx”了，通过该参数可以指定Java的堆空间大小，实际上可能不同的JVM执行结果不太一样。</p><p>有的JVM包含了内部结构(如编译器线程，垃圾回收器结构，代码缓存等等)所需要的内存在“-Xmx”的设定中，而有的则不包含。因此用户Java进程的大小不一定跟“-Xmx”的设定相吻合。</p><p>如果你的应用程序分配对象的速率，对象的生命周期，或者对象的大小超过了JVM内存相关配置，一旦达到最大可使用内存的阈值将会发生内存溢出，用户进程则会停止。</p><p>当你的应用程序纠结于内存的可用性时，最有效的方法就是通过”-Xmx”指定更大的内存去重启当前应用进程。为了避免频繁的重启，大多数企业生产环境都倾向于指定峰值负载时所需要的内存，造成过度配置优化。</p><p><strong>提示：</strong>生产环境负载的调整</p><p>Java开发人员易犯的常见错误是在实验下的做的堆内存设置，在移植到生产环境是忘记重新调整。生产环境和实验室环境是不一样的，谨记根据生产环境的负载重新调整堆内存设置。</p><p><strong>分代垃圾回收器调优</strong></p><p>还有一些其他的优化选项”-Xns”和”-XX: NewSize”，用来调整年轻代的大小，用来指定堆中专门负责新对象分配的空间大小。</p><p>大多数开发者都试图基于实验室环境调整年轻代的大小，这意味着在生产负载下存在失败的风险。一般新生代的大小设置为堆大小的三分之一至二分之一左右，但这不是一个准则，毕竟实际还要视应用程序逻辑而定。因此最好先调查清楚年轻代到年老代的蜕变率以及年老代对象的大小，在此基础上(确保年老代的大小，年老代过小会频繁促发GC导致内存溢出错误)尽可能地调大年轻代的空间。</p><p>还有一个与年轻代相关的调优项”-XX:SurvivorRatio”，该选项用来指定年轻代中对象的生命周期，超过指定时长相关对象将被移至年老代。为了”正确”地设定该值，你需要知道年轻代空间回收的频率，能够估算到新对象在应用程序进程中被引用的时长，同时也取决于分配率。</p><p><strong>并发垃圾回收调优</strong></p><p>针对对停顿敏感的应用，建议使用并发垃圾回收，虽然并行的办法能够带来非常好的吞吐量基准测试分数，但是并行GC不利于缩短响应时间。并发 GC 是目前唯一有效的实现一致性和最少“stop the world”中断的方法。不同的JVM提供不同的并发GC的设定，Oracle JVM(hotspot)提供”-XX:+UseConcMarkSweepGC”,今后G1将成为Oracle JVM默认的并发垃圾回收器。</p><p><strong>性能调优并不是真正的解决办法</strong></p><p>或许你已经注意到上文中在讨论如何“正确“地设定调优此参数时，我刻意在”正确“二字上加了双引号。那是因为就我个人经验而言一旦涉及到性能参数调优，就没有严格意义上的正确设定。每一个设定值都是针对特定的场景。考虑到应用场景会发生变化，JVM 性能调整充其量是一个权宜之计。</p><p>以堆的设置为例：如果2GB的堆可以应对20万并发用户，但是可能不能应付40万的并发用户。</p><p>我们再以”-XX:SurvivorRatio”为例：当设定符合一个负载持续增长最高至每毫秒10000个交易的场景，当压力到达每毫秒50000个交易时又会发生什么呢？</p><p>大多数企业级应用负载都是动态的，Java语言的动态内存管理以及动态编译等技术使得Java更加适合企业级应用。我们来看看一下两个配置清单。</p><p>清单1. 应用程序(1)的启动选项</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;java -Xmx12g -XX:MaxPermSize=<span class="number">64</span>M -XX:PermSize=<span class="number">32</span>M -XX:MaxNewSize=<span class="number">2</span>g </span><br><span class="line">-XX:NewSize=<span class="number">1</span>g -XX:SurvivorRatio=<span class="number">16</span> -XX:+UseParNewGC </span><br><span class="line">-XX:+UseConcMarkSweepGC -XX:MaxTenuringThreshold=<span class="number">0</span> </span><br><span class="line">-XX:CMSInitiatingOccupancyFraction=<span class="number">60</span> -XX:+CMSParallelRemarkEnabled </span><br><span class="line">-XX:+UseCMSInitiatingOccupancyOnly -XX:ParallelGCThreads=<span class="number">12</span> </span><br><span class="line">-XX:LargePageSizeInBytes=<span class="number">256</span>m …</span><br></pre></td></tr></table></figure><p>清单2. 应用程序(2)的启动选项</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;java --Xms8g --Xmx8g --Xmn2g -XX:PermSize=<span class="number">64</span>M -XX:MaxPermSize=<span class="number">256</span>M </span><br><span class="line">-XX:-OmitStackTraceInFastThrow -XX:SurvivorRatio=<span class="number">2</span> -XX:-UseAdaptiveSizePolicy -XX:+UseConcMarkSweepGC </span><br><span class="line">-XX:+CMSConcurrentMTEnabled -XX:+CMSParallelRemarkEnabled -XX:+CMSParallelSurvivorRemarkEnabled </span><br><span class="line">-XX:CMSMaxAbortablePrecleanTime=<span class="number">10000</span> -XX:+UseCMSInitiatingOccupancyOnly </span><br><span class="line">-XX:CMSInitiatingOccupancyFraction=<span class="number">63</span> -XX:+UseParNewGC --Xnoclassgc …</span><br></pre></td></tr></table></figure><p>两者的配置区别很大，因为他们是两个不同应用程序。感觉根据各自的应用特设都做了”正确“的配置与调优。在实验室环境下都运行良好，但在生产环境中最终会表现出疲态。清单1由于没有考虑到动态负载，到了生产环境即表现不良。清单2没有考虑到应用程序在生产环境中的特性变化。这两种情况应该归咎于开发团队，但是该归咎于何处呢？</p><p><strong>变通办法可行吗？</strong></p><p>有些企业通过精确测量交易对象的大小定义极致的对象回收空间并”精简“其架构来适配该空间。这也许是办法来削减碎片以应对一整天的交易(在不做堆压缩的情况下)。还有一个办法就是通过程序设计确保对象被引用的时间在一个比较短的时间内从而阻止其在SurvivorRatio时间之后不被迁往年老代而直接被回收，避免内存压缩的场景。这两种办法都可以，但是对应用开发人员和设计人员有一定的挑战。</p><p><strong>谁保障应用程序的性能？</strong></p><p>一个门户应用可能会在其活动负载峰值点出现故障；一个交易应用可能会在每次市场下跌和上升时无法正常运行；电子商务网站可能会无法应对节假日购物高峰期。这些都是真实世界的案例基本都是JVM性能参数调优导致的。当产生了经济损失，开发团队就会受到责备。也许某些场合下开发团队应该要受到责备，但是JVM的提供商又应该负起什么样儿的责任呢？</p><p>首先JVM提供商应该要提供调优参数的优先顺序，至少这在短期内还是很有意义的。有一些新的调优选项是针对特定的、 新兴的企业应用程序场景。更多的调优选项是为了减轻JVM支持团队的工作负荷而将性能优化转嫁到应用开发者身上。但我个人认为这或将导致更加漫长的支持负荷，一些针对最糟糕场景的调优选项也将被延期，当然不是无限延期。</p><p>毋庸置疑JVM的开发团队也在努力地进行着他们的工作，同时也只有应用实施者才会更加清楚他们应用的特定需求。但是应用的实施者或开发者是无法预测期动态的负载需求。在过去，JVM提供商也会去分析关于Java的性能与可扩展性问题，哪些是他们能够解决的。不是提供调优参数，而是直接去优化或创新垃圾回收的算法。更有趣是我们可以想象一下如果OpenJDK的社区聚集在一起重新考虑Java垃圾回收器将会发生什么！</p><p><strong>JVM**</strong>性能的基准测试**</p><p>调优参数有时被JVM提供商作为其竞争的工具，因为不同的调优可以改善他们的JVM在可预见的环境中的性能表现，本系列的最后一片文章中将调查这些基准测试来衡量JVM的性能。</p><p><strong>JVM**</strong>开发者的挑战**</p><p>真正的企业级可伸缩性需求是要求JVM能够适应动态灵活的应用负载。这是在特定吞吐量和响应时间内保证持续稳定性能的关键。这是JVM开发者才能完成历史使命，因此是时候号召我们Java开发者社区来迎接真正的Java可伸缩性的挑战。</p><ul><li>持续调优</li></ul><p>对于给定的应用，在一开始需要告知其需要多大的内存，之后的工作都应该有JVM来负责 ，JVM需要适配动态的应用负载和运行场景。</p><ul><li>JVM实例数 vs. 实例的可扩展性</li></ul><p>现在的服务器都支持很大的内存，那么为什么JVM实例不能有效地利用它呢？将应用拆分部署许多小的应用服务器实例上，这从经济和环保角度都是一种浪费。现代的JVM需要跟上硬件和应用的发展潮流。</p><ul><li>真实世界的性能和可伸缩性</li></ul><p>企业不需要为其应用的性能需求去做极致的性能调优。JVM提供商和OpenJDK社区需要去解决Java可伸缩性的核心问题以及消除“stop the world“的操作。</p><p><strong>结论</strong></p><p>如果JVM做了这样的工作，并且提供了并发压缩的垃圾回收算法，JVM也不再成为Java可伸缩性的限制因素，Java应用开发者不需要花费痛苦的时间理解怎样配置JVM去获得最佳性能，从而将会有更多的有趣的Java应用层面的创新，而不是无休止的JVM调优。我要挑战JVM开发人员以及提供商所需要做的事情来相应甲骨文所提倡的“Make the Java Future“的活动。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：Eva Andreasson,译者：吴杰 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM性能优化， Part 4  ―― C4 垃圾回收</title>
      <link href="/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%204%20%E2%80%95%E2%80%95%20C4%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
      <url>/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%204%20%E2%80%95%E2%80%95%20C4%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
      <content type="html"><![CDATA[<p>本文是JVM性能优化 系列-第4篇。前3篇文章请参考文章结尾处的JVM优化系列文章。作为Eva Andreasson的JVM性能优化系列的第4篇，本文将对C4垃圾回收器进行介绍。使用C4垃圾回收器可以有效提升对低延迟有要求的企业级Java应用程序的伸缩性。</p><p>到目前为止，本系列的文章将stop-the-world式的垃圾回收视为影响Java应用程序伸缩性的一大障碍，而伸缩性又是现代企业级Java应用程序开发的基础要求，因此这一问题亟待改善。幸运的是，针对此问题，JVM中已经出现了一些新特性，所使用的方式或是对stop-the-world式的垃圾回收做微调，或是消除冗长的暂停（这样更好些）。在一些多核系统中，内存不再是稀缺资源，因此，JVM的一些新特性就充分利用多核系统的潜在优势来增强Java应用程序的伸缩性。</p><p>在本文中，我将着重介绍C4算法，该算法是Azul System公司中无暂停垃圾回收算法的新成果，目前只在Zing JVM上得到实现。此外，本文还将对Oracle公司的G1垃圾回收算法和IBM公司的Balanced Garbage Collection Policy算法做简单介绍。希望通过对这些垃圾回收算法的学习可以扩展你对Java内存管理模型和Java应用程序伸缩性的理解，并激发你对这方面内容的兴趣以便更深入的学习相关知识。至少，你可以学习到在选择JVM时有哪些需要关注的方面，以及在不同应用程序场景下要注意的事项。</p><p><strong>C4算法中的并发性</strong></p><p>Azul System公司的C4（Concurrent Continuously Compacting Collector，译者注，Azul官网给出的名字是Continuously Concurrent Compacting Collector）算法使用独一无二而又非常有趣的方法来实现低延迟的分代式垃圾回收。相比于大多数分代式垃圾回收器，C4的不同之处在于它认为垃圾回收并不是什么坏事（即应用程序产生垃圾很正常），而压缩是不可避免的。在设计之初，C4就是要牺牲各种动态内存管理的需求，以满足需要长时间运行的服务器端应用程序的需求。</p><p>C4算法将释放内存的过程从应用程序行为和内存分配速率中分离出来，并加以区分。这样就实现了并发运行，即应用程序可以持续运行，而不必等待垃圾回收的完成。其中的并发性是关键所在，正是由于并发性的存在才可以使暂停时间不受垃圾回收周期内堆上活动数据数量和需要跟踪与更新的引用数量的影响，将暂停时间保持在较低的水平。正如我在本系列<a href="https://github.com/chiyuanbo/cyb-mds/blob/master/java/jvm/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%203%20%20%E2%80%95%E2%80%95%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6.md" target="_blank" rel="noopener">第3篇</a>中介绍的一样，大多数垃圾回收器在工作周期内都包含了stop-the-world式的压缩过程，这就是说应用程序的暂停时间会随活动数据总量和堆中对象间引用的复杂度的上升而增加。使用C4算法的垃圾回收器可以并发的执行压缩操作，即压缩与应用程序线程同时工作，从而解决了影响JVM伸缩性的最大难题。</p><p>实际上，为了实现并发性，C4算法改变了现代Java企业级架构和部署模型的基本假设。想象一下拥有数百GB内存的JVM会是什么样的：</p><ul><li>部署Java应用程序时，对伸缩性的要求无需要多个JVM配合，在单一JVM实例中即可完成。这时的部署是什么样呢？</li><li>有哪些以往因GC限制而无法在内存存储的对象？</li><li>那些分布式集群（如缓存服务器、区域服务器，或其他类型的服务器节点）会有什么变化？当可以增加JVM内存而不会对应用程序响应时间造成负面影响时，传统的节点数量、节点死亡和缓存丢失的计算会有什么变化呢？</li></ul><p><strong>C4算法的3的阶段</strong></p><p>C4算法的一个基本假设是“垃圾回收不是坏事”和“压缩不可避免”。C4算法的设计目标是实现垃圾回收的并发与协作，剔除stop-the-world式的垃圾回收。C4垃圾回收算法包含一下3个阶段：</p><ol><li><em>标记（Marking）</em> — 找到活动对象</li><li><em>重定位（Relocation）</em> — 将存活对象移动到一起，以便可以释放较大的连续空间，这个阶段也可称为“压缩（compaction）”</li><li><em>重映射（Remapping）</em> — 更新被移动的对象的引用。</li></ol><p>下面的内容将对每个阶段做详细介绍。</p><p><strong>C4算法中的标记阶段</strong></p><p>在C4算法中，<em>标记阶段（marking phase）</em>使用了<em>并发标记（concurrent marking）</em>和引用跟踪<em>（reference-tracing）</em>的方法来标记活动对象，这方面内容已经在本系列的<a href="https://github.com/chiyuanbo/cyb-mds/blob/master/java/jvm/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%203%20%20%E2%80%95%E2%80%95%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6.md" title="Collection" target="_blank" rel="noopener">第3篇</a>中介绍过。</p><p>在标记阶段中，GC线程会从线程栈和寄存器中的活动对象开始，遍历所有的引用，标记找到的对象，这些GC线程会遍历堆上所有的可达（reachable）对象。在这个阶段，C4算法与其他并发标记器的工作方式非常相似。</p><p>C4算法的标记器与其他并发标记器的区别也是始于并发标记阶段的。在并发标记阶段中，如果应用程序线程修改未标记的对象，那么该对象会被放到一个队列中，以备遍历。这就保证了该对象最终会被标记，也因为如此，C4垃圾回收器或另一个应用程序线程不会重复遍历该对象。这样就节省了标记时间，消除了递归重标记（recursive remark）的风险。（注意，长时间的递归重标记有可能会使应用程序因无法获得足够的内存而抛出OOM错误，这也是大部分垃圾回收场景中的普遍问题。）</p><p><a href="http://www.importnew.com/?attachment_id=2411" target="_blank" rel="noopener"><img src="http://www.importnew.com/wp-content/uploads/2013/01/jvmseries4-fig1-300x164.png" alt="" title="jvmseries4-fig1"></a></p><p>Figure 1. Application threads traverse the heap just once during marking</p><p>如果C4算法的实现是基于脏卡表（dirty-card tables）或其他对已经遍历过的堆区域的读写操作进行记录的方法，那垃圾回收线程就需要重新访问这些区域做重标记。在极端条件下，垃圾回收线程会陷入到永无止境的重标记中 —— 至少这个过程可能会长到使应用程序因无法分配到新的内存而抛出OOM错误。但C4算法是基于<em>LVB（load value barrier）</em>实现的，LVB具有自愈能力，可以使应用程序线程迅速查明某个引用是否已经被标记过了。如果这个引用没有被标记过，那么应用程序会将其添加到GC队列中。一旦该引用被放入到队列中，它就不会再被重标记了。应用程序线程可以继续做它自己的事。</p><p><em>脏对象（dirty object）和卡表（card table）</em><br>由于某些原因（例如在一个并发垃圾回收周期中，对象被修改了），垃圾回收器需要重新访问某些对象，那么这些对象<em>脏对象（dirty object）</em>。这这些脏对象，或堆中脏区域的引用，通过会记录在一个专门的数据结构中，这就是卡表。</p><p>在C4算法中，并没有重标记（re-marking）这个阶段，在第一次便利整个堆时就会将所有可达对象做标记。因为运行时不需要做重标记，也就不会陷入无限循环的重标记陷阱中，由此而降低了应用程序因无法分配到内存而抛出OOM错误的风险。</p><p><strong>C4算法中的重定位 ——　应用程序线程与GC的协作</strong></p><p>C4算法中，<em>重定位阶段（reloacation phase）</em>是由GC线程和应用程序线程以协作的方式，并发完成的。这是因为GC线程和应用程序线程会同时工作，而且无论哪个线程先访问将被移动的对象，都会以协作的方式帮助完成该对象的移动任务。因此，应用程序线程可以继续执行自己的任务，而不必等待整个垃圾回收周期的完成。</p><p>正如Figure 2所示，碎片内存页中的活动对象会被重定位。在这个例子中，应用程序线程先访问了要被移动的对象，那么应用程序线程也会帮助完成移动该对象的工作的初始部分，这样，它就可以很快的继续做自己的任务。虚拟地址（指相关引用）可以指向新的正确位置，内存也可以快速回收。</p><p><a href="http://www.importnew.com/2410.html/jvmseries4-fig2" target="_blank" rel="noopener"><img src="http://www.importnew.com/wp-content/uploads/2013/01/jvmseries4-fig2-300x169.png" alt="" title="jvmseries4-fig2"></a></p><p>Figure 2. A page selected for relocation and the empty new page that it will be moved to</p><p>如果是GC线程先访问到了将被移动的对象，那事情就简单多了，GC线程会执行移动操作的。如果在重映射阶段（re-mapping phase，后续会提到）也访问这个对象，那么它必须检查该对象是否是要被移动的。如果是，那么应用程序线程会重新定位这个对象的位置，以便可以继续完成自己任务。（对大对象的移动是通过将该对象打碎再移动完成的。如果你对这部分内容感兴趣的话，推荐你阅读一下相关资源中的这篇白皮书“C4: The Continuously Concurrent Compacting Collector”）</p><p>当所有的活动对象都从某个内存也中移出后，剩下的就都是垃圾数据了，这个内存页也就可以被整体回收了。正如Figure 2中所示。</p><p><em>关于清理</em><br>在C4算法中并没有清理阶段（sweep phase），因此也就不需要这个在大多数垃圾回收算法中比较常用的操作。在指向被移动的对象的引用都更新为指向新的位置之前，from页中的虚拟地址空间必须被完整保留。所以C4算法的实现保证了，在所有指向这个页的引用处于稳定状态前，所有的虚拟地址空间都会被锁定。然后，算法会立即回收物理内存页。</p><p>很明显，无需执行stop-the-world式的移动对象是有很大好处的。由于在重定位阶段，所有活动对象都是并发移动的，因此它们可以被更有效率的放入到相邻的地址中，并且可以充分的压缩。通过并发执行重定位操作，堆被压缩为连续空间，也无需挂起所有的应用程序线程。这种方式消除了Java应用程序访问内存的传统限制（更多关于Java应用程序内存模型的内容参见ImportNew编译整理的第一篇《<a href="http://www.importnew.com/1774.html" target="_blank" rel="noopener">JVM性能优化， Part 1 ―― JVM简介</a>》）。</p><p>经过上述的过程后，如何更新引用呢？如何实现一个非stop-the-world式的操作呢？</p><p><strong>C4算法中的重映射</strong></p><p>在重定位阶段，某些指向被移动的对象的引用会自动更新。但是，在重定位阶段，那些指向了被移动的对象的引用并没有更新，仍然指向原处，所以它们需要在后续完成更新操作。C4算法中的<em>重映射阶段（re-mapping phase）</em>负责完成对那些活动对象已经移出，但仍指向那些的引用进行更新。当然，重映射也是一个协作式的并发操作。</p><p>Figure 3中，在重定位阶段，活动对象已经被移动到了一个新的内存页中。在重定位之后，GC线程立即开始更新那些仍然指向之前的虚拟地址空间的引用，将它们指向那些被移动的对象的新地址。垃圾回收器会一直执行此项任务，直到所有的引用都被更新，这样原先虚拟内存空间就可以被整体回收了。</p><p><a href="http://www.importnew.com/2410.html/jvmseries4-fig3" target="_blank" rel="noopener"><img src="http://www.importnew.com/wp-content/uploads/2013/01/jvmseries4-fig3-300x188.png" alt="" title="jvmseries4-fig3"></a></p><p>Figure 3. Whatever thread finds an invalid address enables an update to the correct new address</p><p>但如果在GC完成对所有引用的更新之前，应用程序线程想要访问这些引用的话，会出现什么情况呢？在C4算法中，应用程序线程可以很方便的帮助完成对引用进行更新的工作。如果在重映射阶段，应用程序线程访问了处于非稳定状态的引用，它会找到该引用的正确指向。如果应用程序线程找到了正确的引用，它会更新该引用的指向。当完成更新后，应用程序线程会继续自己的工作。</p><p>协作式的重映射保证了引用只会被更新一次，该引用下的子引用也都可以指向正确的新地址。此外，在大多数其他GC实现中，引用指向的地址不会被存储在该对象被移动之前的位置；相反，这些地址被存储在一个堆外结构（off-heap structure）中。这样，无需在对所有引用的更新完成之前，再花费精力保持整个内存页完好无损，这个内存页可以被整体回收。</p><p><strong>C4算法真的是无暂停的么？</strong></p><p>在C4算法的重映射阶段，正在跟踪引用的线程仅会被中断一次，而这次中断仅仅会持续到对该引用的检索和更新完成，在这次中断后，线程会继续运行。相比于其他并发算法来说，这种实现会带来巨大的性能提升，因为其他的并发立即回收算法需要等到每个线程都运行到一个安全点（safe point），然后同时挂起所有线程，再开始对所有的引用进行更新，完成后再恢复所有线程的运行。</p><p>对于并发压缩垃圾回收器来说，由于垃圾回收所引起的暂停从来都不是问题。在C4算法的重定位阶段中，也不会有再出现更糟的碎片化场景了。实现了C4算法的垃圾回收器也不会出现背靠背（back-to-back）式的垃圾回收周期，或者是因垃圾回收而使应用程序暂停数秒甚至数分钟。如果你曾经体验过这种stop-the-world式的垃圾回收，那么很有可能是你给应用程序设置的内存太小了。你可以试用一下实现了C4算法的垃圾回收器，并为其分配足够多的内存，而完全不必担心暂停时间过长的问题。</p><p><strong>评估C4算法和其他可选方案</strong></p><p>像往常一样，你需要针对应用程序的需求选择一款JVM和垃圾回收器。C4算法在设计之初就是无论堆中活动数据有多少，只要应用程序还有足够的内存可用，暂停时间都始终保持在较低的水平。正因如此，对于那些有大量内存可用，而对响应时间比较敏感的应用程来说，选择实现了C4算法的垃圾回收器正是不二之选。</p><p>而对于那些要求快速启动，内存有限的客户端应用程序来说，C4就不是那么适用。而对于那些对吞吐量有较高要求的应用程序来说，C4也并不适用。真正能够发挥C4威力的是那些为了提升应用程序工作负载而在每台服务器上部署了4到16个JVM实例的场景。此外，如果你经常要对垃圾回收器做调优的话，那么不妨考虑一下使用C4算法。综上所述，当响应时间比吞吐量占有更高的优先级时，C4是个不错的选择。而对那些不能接受长时间暂停的应用程序来说，C4是个理想的选择。</p><p>如果你正考虑在生产环境中使用C4，那么你可能还需要重新考虑一下如何部署应用程序。例如，不必为每个服务器配置16个具有2GB堆的JVM实例，而是使用一个64GB的JVM实例（或者增加一个作为热备份）。C4需要尽可能大的内存来保证始终有一个空闲内存页来为新创建的对象分配内存。（记住，内存不再是昂贵的资源了！）</p><p>如果你没有64GB，128GB，或1TB（或更多）内存可用，那么分布式的多JVM部署可能是一个更好的选择。在这种场景中，你可以考虑使用Oracle HotSpot JVM的G1垃圾回收器，或者IBM JVM的平衡垃圾回收策略（Balanced Garbage Collection Policy）。下面将对这两种垃圾回收器做简单介绍。</p><p><strong>Gargabe-First （G1） 垃圾回收器</strong></p><p>G1垃圾回收器是新近才出现的垃圾回收器，是Oracle HotSpot JVM的一部分，在最近的JDK1.6版本中首次出现（译者注，该文章写于2012-07-11）。在启动Oracle JDK时附加命令行选项<em>-XX:+UseG1GC</em>，可以启动G1垃圾回收器。</p><p>与C4类似，这款标记-清理（mark-and-sweep）垃圾回收器也可作为对低延迟有要求的应用程序的备选方案。G1算法将堆分为固定大小区域，垃圾回收会作用于其中的某些区域。在应用程序线程运行的同时，启用后台线程，并发的完成标记工作。这点与其他并发标记算法相似。</p><p>G1增量方法可以使暂停时间更短，但更频繁，而这对一些力求避免长时间暂停的应用程序来说已经足够了。另一方面，正如在本系列的[Part 3][4]中介绍的，使用G1垃圾回收器需要针对应用程序的实际需求做长时间的调优，而其GC中断又是stop-the-world式的。所以对那些对低延迟有很高要求的应用程序来说，G1并不是一个好的选择。进一步说，从暂停时间总长来看，G1长于CMS（Oracle JVM中广为人知的并发垃圾回收器）。</p><p>G1使用拷贝算法（在Part 3中介绍过）完成部分垃圾回收任务。这样，每次垃圾回收器后，都会产生完全可用的空闲空间。G1垃圾回收器定义了一些区域的集合作为年轻代，剩下的作为老年代。</p><p>G1已经吸引了足够多的注意，引起了不小的轰动，但是它真正的挑战在于如何应对现实世界的需求。正确的调优就是其中一个挑战 —— 回忆一下，对于动态应用程序负载来说，没有永远“正确的调优”。一个问题是如何处理与分区大小相近的大对象，因为剩余的空间会成为碎片而无法使用。还有一个性能问题始终困扰着低延迟垃圾回收器，那就是垃圾回收器必须管理额外的数据结构。就我来说，使用G1的关键问题在于如何解决stop-the-world式垃圾回收器引起的暂停。Stop-the-world式的垃圾回收引起的暂停使任何垃圾回收器的能力都受制于堆大小和活动数据数量的增长，对企业级Java应用程序的伸缩性来说是一大困扰。</p><p><strong>IBM JVM的平衡垃圾回收策略（Balanced Garbage Collection Policy）</strong></p><p>IBM JVM的平衡垃圾回收（Balanced Garbage Collection BGC）策略通过在启动IBM JDK时指定命令行选项<em>-Xgcpolicy:balanced</em>来启用。乍一看，BGC很像G1，它也是将Java堆划分成相同大小的空间，称为区间（region），执行垃圾回收时会对每个区间单独回收。为了达到最佳性能，在选择要执行垃圾回收的区间时使用了一些启发性算法。BGC中关于代的划分也与G1相似。</p><p>IBM的平衡垃圾回收策略仅在64位平台得到实现，是一种NUMA架构（Non-Uniform Memory Architecture），设计之初是为了用于具有4GB以上堆的应用程序。由于拷贝算法或压缩算法的需要，BGC的部分垃圾回收工作是stop-the-world式的，并非完全并发完成。所以，归根结底，BGC也会遇到与G1和其他没有实现并发压缩选法的垃圾回收器相似的问题。</p><p><strong>结论：回顾</strong></p><p>C4是基于引用跟踪的、分代式的、并发的、协作式垃圾回收算法，目前只在Azul System公司的Zing JVM得到实现。C4算法的真正价值在于：</p><ul><li>消除了重标记可能引起的重标记无限循环，也就消除了在标记阶段出现OOM错误的风险。</li><li>压缩，以自动、且不断重定位的方式消除了固有限制：堆中活动数据越多，压缩所引起的暂停越长。</li><li>垃圾回收不再是stop-the-world式的，大大降低垃圾回收对应用程序响应时间造成的影响。</li><li>没有了清理阶段，降低了在完成GC之前就因为空闲内存不足而出现OOM错误的风险。</li><li>内存可以以页为单位立即回收，使那些需要使用较多内存的Java应用程序有足够的内存可用。</li></ul><p>并发压缩是C4独一无二的优势。使应用程序线程GC线程协作运行，保证了应用程序不会因GC而被阻塞。C4将内存分配和提供足够连续空闲内存的能力完全区分开。C4使你可以为JVM实例分配尽可能大的内存，而无需为应用程序暂停而烦恼。使用得当的话，这将是JVM技术的一项革新，它可以借助于当今的多核、TB级内存的硬件优势，大大提升低延迟Java应用程序的运行速度。</p><p>如果你不介意一遍又一遍的调优，以及频繁的重启的话，如果你的应用程序适用于水平部署模型的话（即部署几百个小堆JVM实例而不是几个大堆JVM实例），G1也是个不错的选择。</p><p>对于动态低延迟启发性自适应（dynamic low-latency heuristic adaption）算法而言，BGC是一项革新，JVM研究者对此算法已经研究了几十年。该算法可以应用于较大的堆。而动态自调优算法（ dynamic self-tuning algorithm）的缺陷是，它无法跟上突然出现的负载高峰。那时，你将不得不面对最糟糕的场景，并根据实际情况再分配相关资源。</p><p>最后，为你的应用程序选择最适合的JVM和垃圾回收器时，最重要的考虑因素是应用程序中吞吐量和暂停时间的优先级次序。你想把时间和金钱花在哪？从纯粹的技术角度说，基于我十年来对垃圾回收的经验，我一直在寻找更多关于并发压缩的革新性技术，或其他可以以较小代价完成移动对象或重定位的方法。我想影响企业级Java应用程序伸缩性的关键就在于并发性。</p><p><strong>JVM 性能优化系列</strong></p><p>第一篇 《<a href="http://www.importnew.com/1774.html" target="_blank" rel="noopener">JVM性能优化， Part 1 ―― JVM简介</a> 》</p><p>第二篇《<a href="http://www.importnew.com/2009.html" target="_blank" rel="noopener">JVM性能优化， Part 2 ―― 编译器</a>》</p><p><strong>第三篇<a href="http://www.importnew.com/2233.html" target="_blank" rel="noopener">《JVM性能优化， Part 3 —— 垃圾回收》</a></strong></p>]]></content>
      
      
        <tags>
            
            <tag> 作者：Eva Andreasson,译者：曹旭东 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM性能优化， Part 3  ―― 垃圾回收</title>
      <link href="/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%203%20%20%E2%80%95%E2%80%95%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
      <url>/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%203%20%20%E2%80%95%E2%80%95%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
      <content type="html"><![CDATA[<p>Java平台的垃圾回收机制大大提高的开发人员的生产力，但实现糟糕的垃圾回收器却会大大消耗应用程序的资源。本文作为JVM性能优化系列的第3篇，Eva Andeasson将为Java初学者介绍Java平台的内存模型和GC机制。她将解释为什么碎片化（不是GC）是Java应用程序出现性能问题的主要原因，以及为什么当前主要通过分代垃圾回收和压缩，而不是其他最具创意的方法，来解决Java应用程序中碎片化的问题。</p><p>垃圾回收（GC）是旨在释放不可达Java对象所占用的内存的过程，是Java virtual machine（JVM）中动态内存管理系统的核心组成部分。在一个典型的垃圾回收周期中，所有仍被引用的对象，即可达对象，会被保留。没有被引用的Java对象所占用的内存会被释放并回收，以便分配给新创建的对象。</p><p>为了更好的理解垃圾回收与各种不同的GC算法，你首先需要了解一些关于Java平台内存模型的内容。</p><p><strong>垃圾回收与Java平台内存模型</strong></p><p>当你在启动Java应用程序时指定了启动参数<em>-Xmx</em>（例如，java -Xmx2g MyApp），则相应大小的内存会被分配给Java进程。这块内存即所谓的<em>Java堆</em>（或简称为<em>堆</em>）。这块专用的内存地址空间用于存储Java应用程序（有时是JVM）所创建的对象。随着Java应用程序的运行，会不断的创建新对象并为之分配内存，Java堆（即地址空间）会逐渐被填满。</p><p>最后，Java堆会被填满，这就是说想要申请内存的线程无法获得一块足够大的连续空闲空间来存放新创建的对象。此时，JVM判断需要启动垃圾回收器来回收内存了。当Java程序调用System.gc()方法时，也有可能会触发垃圾回收器以执行垃圾回收的工作。使用System.gc()方法并不能保证垃圾回收工作肯定会被执行。在执行垃圾回收前，垃圾回收机制首先会检查当前是否是一个“恰当的时机”，而“恰当的时机”指所有的应用程序活动线程都处于安全点（safe point），以便启动垃圾回收。简单举例，为对象分配内存时，或正在优化CPU指令（参见本系列的<a href="http://www.javaworld.com/javaworld/jw-09-2012/120905-jvm-performance-optimization-compilers.html" target="_blank" rel="noopener">前一篇文章</a>）时，就不是“恰当的时机”，因为你可能会丢失上下文信息，从而得到混乱的结果。</p><p>垃圾回收不应该回收当前有活动引用指向的对象所占用的内存；因为这样做将违反<a href="http://docs.oracle.com/javase/specs/jvms/se7/html/index.html" target="_blank" rel="noopener">JVM规范</a>。在JVM规范中，并没有强制要求垃圾回收器立即回收已死对象（dead object）。已死对象最终会在后续的垃圾回收周期中被释放掉。目前，已经有多种垃圾回收的实现，它们都包含两个沟通的假设。对垃圾回收来说，真正的挑战在于标识出所有活动对象（即仍有引用指向的对象），回收所有不可达对象所占用的内存，并尽可能不对正在运行的应用程序产生影响。因此，垃圾回收器运行的两个目标：</p><ol><li>快速释放不可达对象所占用的内存，防止应用程序出现OOM错误。</li><li>回收内存时，对应用程序的性能（指延迟和吞吐量）的影响要紧性能小。</li></ol><p><strong>两类垃圾回收</strong></p><p>在本系列的<a href="https://github.com/chiyuanbo/cyb-mds/blob/master/java/jvm/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%201%20%E2%80%95%E2%80%95%20JVM%E7%AE%80%E4%BB%8B.md" target="_blank" rel="noopener">第一篇文章</a>中，我提到了2种主要的垃圾回收方式，引用计数（reference counting）和引用追踪（tracing collector。译者注，在第一篇中，给出的名字是“reference tracing”，这里仍沿用之前的名字）。这里，我将深入这两种垃圾回收方式，并介绍用于生产环境的实现了引用追踪的垃圾回收方式的相关算法。</p><p><strong>引用计数垃圾回收器</strong></p><p>引用计数垃圾回收器会对指向每个Java对象的引用数进行跟踪。一旦发现指向某个对象的引用数为0，则立即回收该对象所占用的内存。引用计数垃圾回收的主要优点就在于可以立即访问被回收的内存。垃圾回收器维护未被引用的内存并不需要消耗很大的资源，但是保持并不断更新引用计数却代价不菲。</p><p>使用引用计数方式执行垃圾回收的主要困难在于保持引用计数的准确性，而另一个众所周知的问题在于解决循环引用结构所带来的麻烦。如果两个对象互相引用，并且没有其他存活东西引用它们，那么这两个对象所占用的内存将永远不会被释放，两个对象都会因引用计数不为0而永远存活下去。要解决循环引用带来的问题需要，而这会使算法复杂度增加，从而影响应用程序的运行性能。</p><p><strong>引用跟踪垃圾回收</strong></p><p>引用跟踪垃圾回收器基于这样一种假设，所有存活对象都可以通过迭代地跟踪从已知存活对象集中对象发出的引用及引用的引用来找到。可以通过对寄存器、全局域、以及触发垃圾回收时栈帧的分析来确定初始存活对象的集合（称为“根对象”，或简称为“根”）。在确定了初始存活对象集后，引用跟踪垃圾回收器会跟踪从这些对象中发出的引用，并将找到的对象标记为“活的（live）”。标记所有找到的对象意味着已知存活对象的集合会随时间而增长。这个过程会一直持续到所有被引用的对象（因此是“存活的”对象）都被标记。当引用跟踪垃圾回收器找到所有存活的对象后，就会开始回收未被标记的对象。</p><p>不同于引用计数垃圾回收器，引用跟踪垃圾回收器可以解决循环引用的问题。由于标记阶段的存在，大多数引用跟踪垃圾回收器无法立即释放“已死”对象所占用的内存。</p><p>引用跟踪垃圾回收器广泛用于动态语言的内存管理；到目前为止，在Java编程语言的视线中也是应用最广的，并且在多年的商业生产环境中，已经证明其实用性。在本文余下的内容中，我将从一些相关的实现算法开始，介绍引用跟踪垃圾回收器，</p><p><strong>引用跟踪垃圾回收器算法</strong></p><p>拷贝和<em>标记-清理</em>垃圾回收算法并非新近发明，但仍然是当今实现引用跟踪垃圾回收器最常用的两种算法。</p><p><strong>拷贝垃圾回收器</strong></p><p>传统的拷贝垃圾回收器会使用一个“from”区和一个“to”区，它们是堆中两个不同的地址空间。在执行垃圾回收时，from区中存活对象会被拷贝到to区。当from区中所有的存活对象都被拷贝到to后，垃圾回收器会回收整个from区。当再次分配内存时，会首先从to区中的空闲地址开始分配。</p><p>在该算法的早期实现中，from区和to区会在垃圾回收周期后进行交换，即当to区被填满后，将再次启动垃圾回收，这是to区会“变成”from区。如图Figure 1所示。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180420/kID01gDhm7.png?imageslim" alt="mark"><br>Figure 1. A traditional copying garbage collection sequence</p><p>在该算法的近期实现中，可以将堆中任意地址空间指定为from区和to区，这样就不再需要交换from区和to区，堆中任意地址空间都可以成为from区或to区。</p><p>拷贝垃圾回收器的一个优点是存活对象的位置会被to区中重新分配，紧凑存放，可以完全消除碎片化。碎片化是其他垃圾回收算法所要面临的一大问题，这点会在后续讨论。</p><p><strong>拷贝垃圾回收的缺陷</strong></p><p>通常来说，拷贝垃圾回收器是“stop-the-world”式的，即在垃圾回收周期内，应用程序是被挂起的，无法工作。在“stop-the-world”式的实现中，所需要拷贝的区域越大，对应用程序的性能所造成的影响也越大。对于那些非常注重响应时间的应用程序来说，这是难以接受的。使用拷贝垃圾回收时，你还需要考虑一下最坏情况，即当from区中所有的对象都是存活对象的时候。因此，你不得不给存活对象预留出足够的空间，也就是说to区必须足够大，大到可以将from区中所有的对象都放进去。正是由于这个缺陷，拷贝垃圾回收算法在内存使用效率上略有不足。</p><p><strong>标记-清理垃圾回收器</strong></p><p>大多数部署在企业生产环境的商业JVM都使用了标记-清理（或标记）垃圾回收器，这种垃圾回收器并不会想拷贝垃圾回收器那样对应用程序的性能有那么大的影响。其中最著名的几款是CMS、G1、GenPar和DeterministicGC（参见<a href="https://github.com/caoxudong/translation/blob/master/java/jvm/JVM_performance_optimization_Part_3_Garbage_collection.md#resources" target="_blank" rel="noopener">相关资源</a>）。<br>标记-清理垃圾回收器会跟踪引用，并使用标记位将每个找到的对象标记位“live”。通常来说，每个标记位都关联着一个地址或堆上的一个地址集合。例如，标记位可能是对象头（object header）中一位，一个位向量，或是一个位图。</p><p>当所有的存活对象都被标记位“live”后，将会开始<em>清理</em>阶段。一般来说，垃圾回收器的清理阶段包含了通过再次遍历堆（不仅仅是标记位live的对象集合，而是整个堆）来定位内存地址空间中未被标记的区域，并将其回收。然后，垃圾回收器会将这些被回收的区域保存到空闲列表（free list）中。在垃圾回收器中可以同时存在多个空闲列表——通常会按照保存的内存块的大小进行划分。某些JVM（例如JRockit实时系统， JRockit Real Time System）在实现垃圾回收器时会给予应用程序分析数据和对象大小统计数据来动态调整空闲列表所保存的区域块的大小范围。</p><p>当清理阶段结束后，应用程序就可以再次启动了。给新创建的对象分配内存时会从空闲列表中查找，而空闲列表中内存块的大小需要匹配于新创建的对象大小、某个线程中平均对象大小，或应用程序所设置的TLAB的大小。从空闲列表中为新创建的对象找到大小合适的内存区域块有助于优化内存的使用，减少内存中的碎片。</p><p><strong>标记-清理垃圾回收器的缺陷</strong></p><p>标记阶段的时长取决于堆中存活对象的总量，而清理阶段的时长则依赖于堆的大小。由于在<em>标记</em>阶段和<em>清理</em>阶段完成前，你无事可做，因此对于那些具有较大的堆和较多存活对象的应用程序来说，使用此算法需要想办法解决暂停时间（pause-time）较长这个问题。<br>对于那些内存消耗较大的应用程序来说，你可以使用一些GC调优选项来满足其在某些场景下的特殊需求。很多时候，调优至少可以将标记-清理阶段给应用程序或性能要求（SLA，SLA指定了应用程序需要达到的响应时间的要求，即延迟）所带来的风险推后。当负载和应用程序发生改变后，需要重新调优，因为某次调优只对特定的工作负载和内存分配速率有效。</p><p><strong>标记-清理算法的实现</strong></p><p>目前，标记-清理垃圾回收算法至少已有2种商业实现，并且都已在生产环境中被证明有效。其一是并行垃圾回收，另一个是并发（或多数时间并发）垃圾回收。</p><p><strong>并行垃圾回收器</strong></p><p>并行垃圾回收指的是垃圾回收是多线程并行完成的。大多数商业实现的并行垃圾回收器都是stop-the-world式的垃圾回收器，即在整个垃圾回收周期结束前，所有应用程序线程都会被挂起。挂起所有应用程序线程使垃圾回收器可以以并行的方式，更有效的完成标记和清理工作。并行使得效率大大提高，通常可以在像<a href="http://www.spec.org/jbb2005/" target="_blank" rel="noopener">SPECjbb</a>这样的吞吐量基准测试中跑出高分。如果你的应用程序好似有限考虑吞吐量的，那么并行垃圾回收是你最好的选择。</p><p>对于大多数并行垃圾回收器来说，尤其是考虑到应用于生产环境中，最大的问题是，像拷贝垃圾回收算法一样，在垃圾回收周期内应用程序无法工作。使用stop-the-world式的并行垃圾回收会对优先考虑响应时间的应用程序产生较大影响，尤其是当你有大量的引用需要跟踪，而此时恰好又有大量的、具有复杂结构的对象存活于堆中的时候，情况将更加糟糕。（记住，标记-清理垃圾回收器回收内存的时间取决于跟踪存活对象中所有引用的时间与遍历整个堆的时间之和。）以并行方式执行垃圾回收所导致的应用程序暂停会一直持续到整个垃圾回收周期结束。</p><p><strong>并发垃圾回收器</strong></p><p>并发垃圾回收器更适用于那些对响应时间比较敏感的应用程序。并发指的是一些（或大多数）垃圾回收工作可以与应用程序线程同时运行。由于并非所有的资源都由垃圾回收器使用，因此这里所面临的问题如何决定何时开始执行垃圾回收，可以保证垃圾回收顺利完成。这里需要足够的时间来跟踪存活对象即的引用，并在应用程序出现OOM错误前回收内存。如果垃圾回收器无法及时完成，则应用程序就会抛出OOM错误。此外，一直做垃圾回收也不好，会不必要的消耗应用程序资源，从而影响应用程序吞吐量。要想在动态环境中保持这种平衡就需要一些技巧，因此设计了启发式方法来决定何时开始垃圾回收，何时执行不同的垃圾回收优化任务，以及一次执行多少垃圾回收优化任务等。</p><p>并发垃圾回收器所面临的另一个挑战是如何决定何时执行一个需要完整堆快照的操作时安全的，例如，你需要知道是何时标记所有存活对象的，这样才能转而进入清理阶段。在大多数并行垃圾回收器采用的stop-the-world方式中，<em>阶段转换（phase-switching）</em>并不需要什么技巧，因为世界已静止（堆上对象暂时不会发生变化）。但是，在并发垃圾回收中，转换阶段时可能并不是安全的。例如，如果应用程序修改了一块垃圾回收器已经标记过的区域，可能会涉及到一些新的或未被标记的引用，而这些引用使其指向的对象成为存活状态。在某些并发垃圾回收的实现中，这种情况有可能会使应用程序陷入长时间运行重标记（re-mark）的循环，因此当应用程序需要分配内存时无法得到足够做的空闲内存。</p><p>到目前为止的讨论中，已经介绍了各种垃圾回收器和垃圾回收算法，他们各自适用于不同的场景，满足不同应用程序的需求。各种垃圾回收方式不仅在算法上有所区别，在具体实现上也不尽相同。所以，在命令行中指定垃圾回收器之前，最好能了解应用程序的需求及其自身特点。在下一节中，将介绍Java平台内存模型中的陷阱，在这里，陷阱指的是在动态生产环境中，Java程序员常常做出的一些中使性能更糟，而非更好的假设。</p><p><strong>为什么调优无法取代垃圾回收</strong></p><p>大多数Java程序员都知道，如果有不少方法可以最大化Java程序的性能。而当今众多的JVM实现，垃圾回收器实现，以及多到令人头晕的调优选项都可能会让开发人员将大量的时间消耗在无穷无尽的性能调优上。这种情况催生了这样一种结论，“GC是糟糕的，努力调优以降低GC的频率或时长才是王道”。但是，真这么做是有风险的。</p><p>考虑一下针对指定的应用程序需求做调优意味着什么。大多数调优参数，如内存分配速率，对象大小，响应时间，以及对象死亡速度等，都是针对特定的情况而来设定的，例如测试环境下的工作负载。例如。调优结果可能有以下两种：</p><ol><li>测试时正常，上线就失败。</li><li>一旦应用程序本身，或工作负载发生改变，就需要全部重调。</li></ol><p>调优是需要不断往复的。使用并发垃圾回收器需要做很多调优工作，尤其是在生产环境中。为满足应用程序的需求，你需要不断挑战可能要面对的最差情况。这样做的结果就是，最终形成的配置非常刻板，而且在这个过程中也浪费了大量的资源。这种调优方式（试图通过调优来消除GC）是一种堂吉诃德式的探索——以根本不存在的理由去挑战一个假想敌。而事实是，你针对某个特定的负载而垃圾回收器做的调优越多，你距离Java运行时的动态特性就越远。毕竟，有多少应用程序的工作负载能保持不变呢？你所预估的工作负载的可靠性又有多高呢？</p><p>那么，如果不从调优入手又该怎么办呢？有什么其他的办法可以防止应用程序出现OOM错误，并降低响应时间呢？这里，首先要做的是明确影响Java应用程序性能的真正因素。</p><p><strong>碎片化</strong></p><p>影响Java应用程序性能的罪魁祸首并不是垃圾回收器本身，而是碎片化，以及垃圾回收器如何处理碎片。碎片是Java堆中空闲空间，但由于连续空间不够大而无法容纳将要创建的对象。正如我在本系列<a href="https://github.com/chiyuanbo/cyb-mds/blob/master/java/jvm/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%202%20%E2%80%95%E2%80%95%20%E7%BC%96%E8%AF%91%E5%99%A8.md" target="_blank" rel="noopener">第2篇</a>中提到的，碎片可能是TLAB中的剩余空间，也可能是（这种情况比较多）被释放掉的具有较长生命周期的小对象所占用的空间。</p><p>随着应用程序的运行，这种无法使用的碎片会遍布于整个堆空间。在某些情况下，这种状态会因静态调优选项（如提升速率和空闲列表等）更糟糕，以至于无法满足应用程序的原定需求。这些剩下的空间（也就是碎片）无法被应用程序有效利用起来。如果你对此放任自流，就会导致不断垃圾回收，垃圾回收器会不断的释放内存以便创建新对象时使用。在最差情况下，甚至垃圾回收也无法腾出足够的内存空间（因为碎片太多），JVM会强制抛出OOM（out of memory）错误当然，你也可以重启应用程序来消除碎片，这样可以使Java堆焕然一新，于是就又可以为对象分配内存了。但是，重新启动会导致服务器停机，另外，一段时间之后，堆将再次充满碎片，你也不得不再次重启。</p><p>OOM错误（OutOfMemoryErrors）会挂起进程，日志中显示的垃圾回收器很忙，是垃圾回收器努力释放内存的标志，也说明了堆中碎片非常多。一些开发人员通过重新调优垃圾回收器来解决碎片化的问题，但我觉着在解决碎片问题成为垃圾回收的使命之前应该用一些更有新意的方法来解决这个问题。本文后面的内容将聚焦于能有效解决碎片化问题的方法：分代黛式垃圾回收和压缩。</p><p><strong>分代式垃圾回收</strong></p><p>这个理论你可以已经听说过，即在生产环境中，大部分对象的生命周期都很短。分代式垃圾回收就源于这个理论。在分代式垃圾回收中，堆被分为两个不同的空间（或成为“代”），每个空间存放具有不同年龄的对象，在这里，年龄是指该对象所经历的垃圾回收的次数（也就是该对象挺过了多少次垃圾回收而没有死掉）。</p><p>当新创建的对象所处的空间，即<em>年轻代</em>，被对象填满后，该空间中仍然存活的对象会被移动到老年代。（译者注，以HotSpot为例，这里应该是挺过若干次GC而不死的，才会被搬到老年代，而一些比较大的对象会直接放到老年代。）大多数的实现都将堆会分为两代，年轻代和老年代。通常来说，分代式垃圾回收器都是单向拷贝的，即从年轻代向老年代拷贝，这点在早先曾讨论过。近几年出现的年轻代垃圾回收器已经可以实现并行垃圾回收，当然也可以实现一些其他的垃圾回收算法实现对年轻代和老年代的垃圾回收。如果你使用拷贝垃圾回收器（可能具有并行收集功能）对年轻代进行垃圾回收，那垃圾回收是stop-the-world式的（参见前面的解释）。</p><p><strong>分代式垃圾回收的缺陷</strong></p><p>在分代式垃圾回收中，老年代执行垃圾回收的平率较低，而年轻代中较高，垃圾回收的时间较短，侵入性也较低。但在某些情况下，年轻代的存在会是老年代的垃圾回收更加频繁。典型的例子是，相比于Java堆的大小，年轻代被设置的太大，而应用程序中对象的生命周期又很长（又或者给年轻代对象提升速率设了一个“不正确”的值）。在这种情况下，老年代因太小而放不下所有的存活对象，因此垃圾回收器就会忙于释放内存以便存放从年轻代提升上来的对象。但一般来说，使用分代式垃圾回收器可以使用应用程序的性能和系统延迟保持在一个合适的水平。</p><p>使用分代式垃圾回收器的一个额外效果是部分解决了碎片化的问题，或者说，发生最差情况的时间被推迟了。可能造成碎片的小对象被分配于年轻代，也在年轻代被释放掉。老年代中的对象分布会相对紧凑一些，因为这些对象在从年轻代中提升上来的时候会被会紧凑存放。但随着应用程序的运行，如果运行时间够长的话，老年代也会充满碎片的。这时就需要对年轻代和老年代执行一次或多次stop-the-world式的全垃圾回收，导致JVM抛出<em>OOM错误</em>或者表明提升失败的错误。但年轻代的存在使这种情况的出现被推迟了，对某些应用程序来说，这就就足够了。（在某些情况下，这种糟糕情况会被推迟到应用程序完全不关心GC的时候。）对大多数应用程序来说，对于大多数使用年轻代作为缓冲的应用程序来说，年轻代的存在可以降低出现stop-the-world式垃圾回收频率，减少抛出OOM错误的次数。</p><p><strong> 调优分代式垃圾回收</strong></p><p>正如上面提到的，由于使用了分代式垃圾回收，你需要针对每个新版本的应用程序和不同的工作负载来调整年轻代大小和对象提升速度。我无法完整评估出固定运行时的代价：由于针对某个指定工作负载而设置了一系列优化参数，垃圾回收器应对动态变化的能力降低了，而变化是不可避免的。</p><p>对于调整年轻代大小来说，最重要的规则是要确保年轻代的大小不应该使因执行stop-the-world式垃圾回收而导致的暂停过长。（假设年轻代中使用的并行垃圾回收器。）还要记住的是，你要在堆中为老年代留出足够的空间来存放那些生命周期较长的对象。下面还有一些在调优分代式垃圾回收器时需要考虑的因素：</p><ol><li><p>大多数年轻代垃圾回收都是stop-the-world式的，年轻代越大，相应的暂停时间越长。所以，对于那些受GC暂停影响较大的应用程序来说，应该仔细斟酌年轻代的大小。</p></li><li><p>你可以综合考虑不同代的垃圾回收算法。可以在年轻代使用并行垃圾回收，而在老年代使用并行垃圾回收。</p></li><li><p>当提升失败频繁发生时，这通常说明老年代中的碎片较多。提升失败指的是老年代中没有足够大的空间来存放年轻代中的存活对象。当出现提示失败时，你可以微调对象提升速率（即调整对象提升时年龄），或者确保老年代垃圾回收算法会将对象进行压缩（将在下一节讨论），并以一种适合当前应用程序工作负载的方式调整压缩。你也可以增大堆和各个代的大小，但这会使老年代垃圾回收的暂停时间延长——记住，碎片化是不可避免的。</p></li><li><p>分代式垃圾回收最适用于那些具有大量短生命周期对象的应用程序，这些对象的生命周期短到活不过一次垃圾回收周期。在这种场景中，分代式垃圾回收可有效的减缓碎片化的趋势，主要是将碎片化随带来的影响推出到将来，而那时可能应用程序对此毫不关心。</p></li></ol><p><strong>压缩</strong></p><p>尽管分代式垃圾回收推出了碎片化和OOM错误出现的时机，但压缩仍然是唯一真正解决碎片化的方法。<em>压缩</em>是将对象移动到一起，以便释放掉大块连续内存空间的GC策略。因此，压缩可以生成足够大的空间来存放新创建的对象。</p><p>移动对象并修改相关引用是一个stop-the-world式的操作，这会对应用程序的性能造成影响。（只有一种情况是个例外，将在本系列的下一篇文章中讨论。）存活对象越多，垃圾回收造成的暂停也越长。假如堆中的空间所剩无几，而且碎片化又比较严重（这通常是由于应用程序运行的时间很长了），那么对一块存活对象多的区域进行压缩可能会耗费数秒的时间。而如果因出现OOM而导致应用程序无法运行，因此而对整个堆进行压缩时，所消耗的时间可达数十秒。</p><p>压缩导致的暂停时间的长短取决于需要移动的存活对象所占用的内存有多大以及有多少引用需要更新。当堆比较大时，从统计上讲，存活对象和需要更新的引用都会很多。从已观察到的数据看，每压缩1到2GB存活数据的需要约1秒钟。所以，对于4GB的堆来说，很可能会有至少25%的存活数据，从而导致约1秒钟的暂停。</p><p><strong>压缩与应用程序内存墙</strong></p><p>应用程序内存墙涉及到在GC暂停时间对应用程序的影响大到无法达到满足预定需求之前所能设置的的堆的最大值。目前，大部分Java应用程序在碰到内存墙时，每个JVM实例的堆大小介于4GB到20GB之间，具体数值依赖于具体的环境和应用程序本身。这也是大多数企业及应用程序会部署多个小堆JVM而不是部署少数大堆（50到60GB）JVM的原因之一。在这里，我们需要思考一下：现代企业中有多少Java应用程序的设计与部署架构受制于JVM中的压缩？在这种情况下，我们接受多个小实例的部署方案，以增加管理维护时间为代价，绕开为处理充满碎片的堆而执行stop-the-world式垃圾回收所带来的问题。考虑到现今的硬件性能和企业级Java应用程序中对内存越来越多的访问要求，这种方案是在非常奇怪。为什么仅仅只能给每个JVM实例设置这么小的堆？并发压缩是一种可选方法，它可以降低内存墙带来的影响，这将是本系列中下一篇文章的主题。</p><p>从已观察到的数据看，每压缩1到2GB存活数据的需要约1秒钟。所以，对于4GB的堆来说，很可能会有至少25%的存活数据，从而导致约1秒钟的暂停。</p><p><strong>总结：回顾</strong></p><p>本文对垃圾回收做了总体介绍，目的是为了使你能了解垃圾回收的相关概念和基本知识。希望本文能激发你继续深入阅读相关文章的兴趣。这里所介绍的大部分内容，它们。在下一篇文章中，我将介绍一些较新颖的概念，并发压缩，目前只有Azul公司的Zing JVM实现了这一技术。并发压缩是对GC技术的综合运用，这些技术试图重新构建Java内存模型，考虑当今内存容量与处理能力的不断提升，这一点尤为重要。</p><p>现在，回顾一下本文中所介绍的关于垃圾回收的一些内容：</p><ol><li><p>不同的垃圾回收算法的方式是为满足不同的应用程序需求而设计。目前在商业环境中，应用最为广泛的是引用跟踪垃圾回收器。</p></li><li><p>并行垃圾回收器会并行使用可用资源执行垃圾回收任务。这种策略的常用实现是stop-the-world式垃圾回收器，使用所有可用系统资源快速完成垃圾回收任务。因此，并行垃圾回收可以提供较高的吞吐量，但在垃圾回收的过程中，所有应用程序线程都会被挂起，对延迟有较大影响。</p></li><li><p>并发垃圾回收器可以与应用程序并发工作。使用并发垃圾回收器时要注意的是，确保在应用程序发生OOM错误之前完成垃圾回收。</p></li><li><p>分代式垃圾回收可以推迟碎片化的出现，但并不能消除碎片化。它将堆分为两块空间，一块用于存放“年轻对象”，另一块用于存放从年轻代中存活下来的存活对象。对于那些使用了很多具有较短生命周期活不过几次垃圾回收周期的Java应用程序来说，使用分代式垃圾回收是非常合适的。</p></li><li><p>压缩是可以完全解决碎片化的唯一方法。大多数垃圾回收器在压缩的时候是都stop-the-world式的。应用程序运行的时间越长，对象间的引就用越复杂，对象大小的异质性也越高。相应的，完成压缩所需要的时间也越长。如果堆的大小较大的话也会对压缩所占产生的暂停有影响，因为较大的堆就会有更多的活动数据和更多的引用需要处理。</p></li><li><p>调优可以推迟OOM错误的出现，但过度调优是无意义的。在通过试错方式初始调优前，一定要明确生产环境负载的动态性，以及应用程序中的对象类型和对象间的引用情况。在动态负载下，过于刻板的配置很容会失效。在设置非动态调优选项前一定要清楚这样做后果。</p></li></ol>]]></content>
      
      
        <tags>
            
            <tag> 作者：Eva Andreasson,译者：曹旭东 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM性能优化， Part 2 ―― 编译器</title>
      <link href="/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%202%20%E2%80%95%E2%80%95%20%E7%BC%96%E8%AF%91%E5%99%A8/"/>
      <url>/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%202%20%E2%80%95%E2%80%95%20%E7%BC%96%E8%AF%91%E5%99%A8/</url>
      <content type="html"><![CDATA[<p>[toc]</p><p><strong>什么是编译器</strong></p><p>简单来说，编译器就是将一种编程语言作为输入，输出另一种可执行语言的工具。大家都熟悉的javac就是一个编译器，所有标准版的JDK中都带有这个工具。javac以Java源代码作为输入，将其翻译为可由JVM执行的字节码。翻译后的字节码存储在.class文件中，在启动Java进程的时候，被载入到Java运行时中。</p><p>标准CPU并不能识别字节码，它需要被转换为当前平台所能理解的本地指令。在JVM中，有专门的组件负责将字节码编译为平台相关指令，实际上，这也是一种编译器。有些JVM编译器可以处理多层级的编译工作，例如，编译器在最终将字节码转换为平台相关指令前，会为相关的字节码建立多层级的中间表示（intermediate representation）。</p><p><em>字节码与JVM</em></p><p>如果你想了解更多有关字节码与JVM的信息，请阅读 <a href="http://www.javaworld.com/javaworld/jw-09-1996/jw-09-bytecodes.html" target="_blank" rel="noopener">“Bytecode basics”</a>(Bill Venners, JavaWorld)</p><p>以平台未知的角度看，我们希望尽可能的保持平台独立性，因此，最后一级的编译，也就是从最低级表示到实际机器码的转换，是与具体平台的处理器架构息息相关的。在最高级的表示上，会因使用静态编译器还是动态编译器而有所区别。在这里，我们可以选择应用程序所以来的可执行环境，期望达到的性能要求，以及我们所面临的资源限制。在本系列的第1篇文章的<a href="http://www.javaworld.com/javaworld/jw-08-2012/120821-jvm-performance-optimization-overview.html" target="_blank" rel="noopener">静态编译器与动态编译器</a>一节中，已经对此有过简要介绍。我将在本文的后续章节中详细介绍这部分内容。</p><p><strong>静态编译器与动态编译器</strong></p><p>前文提到的javac就是使用静态编译器的例子。静态编译器解释输入的源代码，并输出程序运行时所需的可执行文件。如果你修改了源代码，那么就需要使用编译器来重新编译代码，否则输出的可执行性文件不会发生变化；这是因为静态编译器的输入是静态的普通文件。</p><p>使用静态编译器时，下面的Java代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add7</span><span class="params">( <span class="keyword">int</span> x )</span> </span>&#123;</span><br><span class="line">     <span class="keyword">return</span> x+<span class="number">7</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会生成类似如下的字节码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iload0</span><br><span class="line">bipush <span class="number">7</span></span><br><span class="line">iadd</span><br><span class="line">ireturn</span><br></pre></td></tr></table></figure><p>动态编译器会动态的将一种编程语言编译为另一种，即在程序运行时执行编译工作。动态编译与优化使运行时可以根据当前应用程序的负载情况而做出相应的调整。动态编译器非常适合用于Java运行时中，因为Java运行时通常运行在无法预测而又会随着运行而有所变动的环境中。大部分JVM都会使用诸如Just-In-Time编译器的动态编译器。这里面需要注意的是，大部分动态编译器和代码优化有时需要使用额外的数据结构、线程和CPU资源。要做的优化或字节码上下文分析越高级，编译过程所消耗的资源就越多。在大多数运行环境中，相比于经过动态编译和代码优化所获得的性能提升，这些损耗微不足道。</p><p><strong>_ JVM的多样性与Java平台的独立性_</strong></p><p>所有的JVM实现都有一个共同点，即它们都试图将应用程序的字节码转换为本地机器指令。一些JVM在载入应用程序后会解释执行应用程序，同时使用性能计数器来查找“热点”代码。还有一些JVM会调用解释执行的阶段，直接编译运行。资源密集型编译任务对应用程序来说可能会产生较大影响，尤其是那些客户端模式下运行的应用程序，但是资源密集型编译任务可以执行一些比较高级的优化任务。更多相关内容请参见<a href="https://github.com/caoxudong/translation/blob/master/java/jvm/JVM_performance_optimization_Part_2_Compilers.md#%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90" target="_blank" rel="noopener">相关资源</a></p><p>如果你是Java初学者，JVM本身错综复杂结构会让你晕头转向的。不过，好消息是你无需精通JVM。JVM自己会做好代码编译和优化的工作，所以你无需关心如何针对目标平台架构来编写应用程序才能编译、优化，从而生成更好的本地机器指令。</p><p><strong>从字节码到可运行的程序</strong></p><p>当你编写完Java源代码并将之编译为字节码后，下一步就是将字节码指令编译为本地机器指令。这一步会由解释器或编译器完成。</p><p><strong>解释</strong></p><p>解释是最简单的字节码编译形式。解释器查找每条字节码指令对应的硬件指令，再由CPU执行相应的硬件指令。</p><p>你可以将解释器想象为一个字典：每个单词（字节码指令）都有准确的解释（本地机器指令）。由于解释器每次读取一个字节码指令并立即执行，因此它就没有机会对某个指令集合进行优化。由于每次执行字节码时，解释器都需要做相应的解释工作，因此程序运行起来就很慢。解释执行可以准确执行字节码，但是未经优化而输出的指令集难以发挥目标平台处理器的最佳性能。</p><p><strong>编译</strong></p><p>另一方面，编译执行应用程序时，<em>编译器</em>会将加载运行时会用到的全部代码。因为编译器可以将字节码编译为本地代码，因此它可以获取到完整或部分运行时上下文信息，并依据收集到的信息决定到底应该如何编译字节码。编译器是根据诸如指令的不同执行分支和运行时上下文数据等代码信息来指定决策的。</p><p>当字节码序列被编译为机器代码指令集合时，就可以对这个指令集合做一些优化操作了，优化后的指令集合会被存储到成为code cache的数据结构中。当下一次执行这部分字节码序列时，就会执行这些经过优化后被存储到code cache的指令集合。在某些情况下，性能计数器会失效，并覆盖掉先前所做的优化，这时，编译器会执行一次新的优化过程。使用code cache的好处是优化后的指令集可以立即执行 —— 无需像解释器一样再经过查找的过程或编译过程！这可以加速程序运行，尤其是像Java应用程序这种同一个方法会被多次调用应用程序。</p><p><strong>优化</strong></p><p>随着动态编译器一起出现的是性能计数器。例如，编译器会插入性能计数器，以统计每个字节码块（对应与某个被调用的方法）的调用次数。在进行相关优化时，编译器会使用收集到的数据来判断某个字节码块有多“热”，这样可以最大程度的降低对当前应用程序的影响。运行时数据监控有助于编译器完成多种代码优化工作，进一步提升代码执行性能。随着收集到的运行时数据越来越多，编译器就可以完成一些额外的、更加复杂的代码优化工作，例如编译出更高质量的目标代码，使用运行效率更高的代码替换原代码，甚至是剔除冗余操作等。</p><p><strong>示例</strong></p><p>考虑如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add7</span><span class="params">( <span class="keyword">int</span> x )</span> </span>&#123;</span><br><span class="line">     <span class="keyword">return</span> x+<span class="number">7</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码经过javac编译后会产生如下的字节码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iload0</span><br><span class="line">bipush <span class="number">7</span></span><br><span class="line">iadd</span><br><span class="line">ireturn</span><br></pre></td></tr></table></figure><p>当调用这段代码时，字节码块会被动态的编译为本地机器指令。当性能计数器（如果这段代码应用了性能计数器的话）发现这段代码的运行次数超过了某个阈值后，动态编译器会对这段代码进行优化编译。后带的代码可能会是下面这个样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lea rax,[rdx+<span class="number">7</span>]</span><br><span class="line">ret</span><br></pre></td></tr></table></figure><p><strong>各擅胜场</strong></p><p>不同的Java应用程序需要满足不同的需求。相对来说，企业级服务器端应用程序需要长时间运行，因此可以做更多的优化，而稍小点的客户端应用程序可能要求快速启动运行，占资源少。接下来我们考察三种编译器设置及其各自的优缺点。</p><p><strong>客户端编译器</strong></p><p>即大家熟知的优化编译器C1。在启动应用程序时，添加JVM启动参数“-client”可以启用C1编译器。正如启动参数所表示的，C1是一个客户端编译器，它专为客户端应用程序而设计，资源消耗更少，并且在大多数情况下，对应用程序的启动时间很敏感。C1编译器使用性能计数器来收集代码的运行时信息，执行一些简单、无侵入的代码优化任务。</p><p><strong>服务器端编译器</strong></p><p>对于那些需要长时间运行的应用程序，例如服务器端的企业级Java应用程序来说，客户端编译器所实现的功能还略有不足，因此服务器端的编译会使用类似C2这类的编译器。启动应用程序时添加命令行参数“-server”可以启用C2编译器。由于大多数服务器端应用程序都会长时间运行，因此相对于运行时间稍短的轻量级客户端应用程序，在服务器端应用程序中启用C2编译器可以收集到更多的运行时数据，也就可以执行一些更高级的编译技术与算法。</p><p><strong><em>提示：给服务器端编译器热身</em></strong></p><p>对于服务器端编译器来说，在应用程序开始运行之后，编译器可能会在一段时间之后才开始优化“热点”代码，所以服务器端编译器通常需要经过一个“热身”阶段。在服务器端编译器执行性能优化任务之前，要确保应用程序的各项准备工作都已就绪。给予编译器足够多的时间来完成编译、优化的工作才能取得更好的效果。（更多关于编译器热身与监控原理的内容请参见JavaWorld的文章”<a href="http://www.javaworld.com/javaqa/2003-04/01-qa-0411-hotspot.html" target="_blank" rel="noopener">Watch your HotSpot compiler go</a>“。）</p><p>在执行编译任务优化任务时，服务器端编译器要比客户端编译器综合考虑更多的运行时信息，执行更复杂的分支分析，即对哪种优化路径能取得更好的效果作出判断。获取的运行时数据越多，编译优化所产生的效果越好。当然，要完成一些复杂的、高级的性能分析任务，编译器就需要消耗更多的资源。使用了C2编译器的JVM会消耗更多的资源，例如更多的线程，更多的CPU指令周期，以及更大的code cache等。</p><p><strong>层次编译</strong></p><p>层次编译综合了服务器端编译器和客户端编译器的特点。Azul首先在其Zing JVM中实现了层次编译。最近（就是Java SE 7版本），Oracle Java HotSpot VM也采用了这种设计。在应用程序启动阶段，客户端编译器最为活跃，执行一些由较低的性能计数器阈值出发的性能优化任务。此外，客户端编译器还会插入性能计数器，为一些更复杂的性能优化任务准备指令集，这些任务将在后续的阶段中由服务器端编译器完成。层次编译可以更有效的利用资源，因为编译器在执行一些对应用程序影响较小的编译活动时仍可以继续收集运行时信息，而这些信息可以在将来用于完成更高级的优化任务。使用层次编译可以比解释性的代码性能计数器手机到更多的信息。</p><p>Figure 1中展示了纯解释运行、客户端模式运行、服务器端模式运行和层次编译模式运行下性能之间的区别。X轴表示运行时间（单位时间）Y轴表示性能（每单位时间内的操作数）。</p><p><img src="http://osapnihnq.bkt.clouddn.com/blog/180420/5Gkal6f7F3.png?imageslim" alt="mark"></p><p>Figure 1. Performance differences between compilers (click to enlarge)</p><p><strong>编译性能对比</strong></p><p>相比于纯解释运行的的代码，以客户端模式编译运行的代码在性能（指单位时间执行的操作）上可以达到约5到10倍，因此而提升了应用程序的运行性能。其间的区别主要在于编译器的效率、编译器所作的优化，以及应用程序在设计实现时针对目标平台做了何种程度的优化。实际上，最后一条不在Java程序员的考虑之列。</p><p>相比于客户端编译器，使用服务器端编译器通常会有30%到50%的性能提升。在大多数情况下，这种程度的性能提升足以弥补使用服务器端编译所带来的额外资源消耗。</p><p>层次编译综合了服务器端编译器和客户端编译器的优点，使用客户端编译模式实现快速启动和快速优化，使用服务器端编译模式在后续的执行周期中完成高级优化的编译任务。</p><p><strong>常用编译优化手段</strong></p><p>到目前为止，已经介绍了优化代码的价值，以及常用JVM编译器是如何以及何时编译代码的。接下来，将用一些实际的例子做个总结。JVM所作的性能优化通常在字节码这一层级（或者是更底层的语言表示），但这里我将使用Java编程语言对优化措施进行介绍。在这一节中，我无法涵盖JVM中所作的所有性能优化，相反，我希望可以激发你的兴趣，使你主动挖掘并学习编译器技术中所包含了数百种高级优化技术（参见相关资源）。</p><p><strong>死代码剔除</strong></p><p>死代码剔除指的是，将用于无法被调用的代码，即“死代码”，从源代码中剔除。如果编译器在运行时发现某些指令是不必要的，它会简单的将其从可执行指令集中剔除。例如，在Listing 1中，变量被赋予了确定值，却从未被使用，因此可以在执行时将其完全忽略掉。在字节码这一层级，也就不会有将数值载入到寄存器的操作。没有载入操作意味着可以更少的CPU时间，更好的运行性能，尤其是当这段代码是“热点”代码的时候。</p><p>Listing 1中展示了示例代码，其中被赋予了固定值的代码从未被使用，属于无用不必要的操作。</p><p>Listing 1. Dead code</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">timeToScaleMyApp</span><span class="params">(<span class="keyword">boolean</span> endlessOfResources)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> reArchitect = <span class="number">24</span>;</span><br><span class="line">  <span class="keyword">int</span> patchByClustering = <span class="number">15</span>;</span><br><span class="line">  <span class="keyword">int</span> useZing = <span class="number">2</span>;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">if</span>(endlessOfResources)</span><br><span class="line">      <span class="keyword">return</span> reArchitect + useZing;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">return</span> useZing;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在字节码这一层级，如果变量被载入但从未使用，编译器会检测到并剔除这个死代码，如Listing 2所示。剔除死代码可以节省CPU时间，从而提升应用程序的运行速度。</p><p>Listing 2. The same code following optimization</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">timeToScaleMyApp</span><span class="params">(<span class="keyword">boolean</span> endlessOfResources)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> reArchitect = <span class="number">24</span>;</span><br><span class="line">  <span class="comment">//unnecessary operation removed here...</span></span><br><span class="line">  <span class="keyword">int</span> useZing = <span class="number">2</span>;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">if</span>(endlessOfResources)</span><br><span class="line">      <span class="keyword">return</span> reArchitect + useZing;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">return</span> useZing;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>冗余剔除是一种类似的优化手段，通过剔除掉重复的指令来提升应用程序性能。</p><p><strong>内联</strong></p><p>许多优化手段都试图消除机器级跳转指令（例如，x86架构的JMP指令）。跳转指令会修改指令指针寄存器，因此而改变了执行流程。相比于其他汇编指令，跳转指令是一个代价高昂的指令，这也是为什么大多数优化手段会试图减少甚至是消除跳转指令。内联是一种家喻户晓而且好评如潮的优化手段，这是因为跳转指令代价高昂，而内联技术可以将经常调用的、具有不容入口地址的小方法整合到调用方法中。Listing 3到Listing 5中的Java代码展示了使用内联的用法。</p><p>Listing 3. Caller method</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">whenToEvaluateZing</span><span class="params">(<span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> daysLeft(y) + daysLeft(<span class="number">0</span>) + daysLeft(y+<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Listing 4. Called method</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">daysLeft</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (x == <span class="number">0</span>)</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">     <span class="keyword">return</span> x - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Listing 5. Inlined method</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">whenToEvaluateZing</span><span class="params">(<span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">if</span>(y == <span class="number">0</span>) temp += <span class="number">0</span>; <span class="keyword">else</span> temp += y - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span>(<span class="number">0</span> == <span class="number">0</span>) temp += <span class="number">0</span>; <span class="keyword">else</span> temp += <span class="number">0</span> - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span>(y+<span class="number">1</span> == <span class="number">0</span>) temp += <span class="number">0</span>; <span class="keyword">else</span> temp += (y + <span class="number">1</span>) - <span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> temp; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Listing 3到Listing 5的代码中，展示了将调用3次小方法进行内联的示例，这里我们认为使用内联比跳转有更多的优势。</p><p>如果被内联的方法本身就很少被调用的话，那么使用内联也没什么意义，但是对频繁调用的“热点”方法进行内联在性能上会有很大的提升。此外，经过内联处理后，就可以对内联后的代码进行进一步的优化，正如Listing 6中所展示的那样。</p><p>Listing 6. After inlining, more optimizations can be applied</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">whenToEvaluateZing</span><span class="params">(<span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(y == <span class="number">0</span>) <span class="keyword">return</span> y;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (y == -<span class="number">1</span>) <span class="keyword">return</span> y - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> y + y - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>循环优化</strong></p><p>当涉及到需要减少执行循环时的性能损耗时，循环优化起着举足轻重的作用。执行循环时的性能损耗包括代价高昂的跳转操作，大量的条件检查，和未经优化的指令流水线（即引起CPU空操作或额外周期的指令序列）等。循环优化可以分为很多种，在各种优化手段中占有重要比重。其中值得注意的包括以下几种：</p><ul><li><p>合并循环：当两个相邻循环的迭代次数相同时，编译器会尝试将两个循环体进行合并。当两个循环体中没有相互引用的情况，即各自独立时，可以同时执行（并行执行）。</p></li><li><p>反转循环：基本上将就是用do-while循环体换掉常规的while循环，这个do-while循环嵌套在if语句块中。这个替换操作可以节省两次跳转操作，但是，会增加一个条件检查的操作，因此增加的代码量。这种优化方式完美的展示了以少量增加代码量为代价换取较大性能的提升 —— 编译器需要在运行时需要权衡这种得与失，并制定编译策略。</p></li><li><p>分块循环：重新组织循环体，以便迭代数据块时，便于缓存的应用。</p></li><li><p>展开循环：减少判断循环条件和跳转的次数。你可以将之理解为将一些迭代的循环体“内联”到一起，而无需跨越循环条件。展开循环是有风险的，它有可能会降低应用程序的运行性能，因为它会影响流水线的运行，导致产生了冗余指令。再强调一遍，展开循环是编译器在运行时根据各种信息来决定是否使用的优化手段，如果有足够的收益的话，那么即使有些性能损耗也是值得的。</p></li></ul><p>至此，已经简要介绍了编译器对字节码层级（以及更底层）进行优化，以提升应用程序在目标平台的执行性能的几种方式。这里介绍的几种优化手段是比较常用的几种，只是众多优化技术中的几种。在介绍优化方法时配以简单示例和相关解释，希望可以洗发你进行深度探索的兴趣。更多相关内容请参见相关资源。</p><p><strong>总结：回顾</strong></p><p>为满足不同需要而使用不同的编译器。</p><ul><li>解释是将字节码转换为本地机器指令的最简单方式，其工作方式是基于对本地机器指令表的查找。</li><li>编译器可以基于性能计数器进行性能优化，但是需要消耗更多的资源（如code cache，优化线程等）。</li><li>相比于纯解释执行代码，客户端编译器可以将应用程序的执行性能提升一个数量级（约5到10倍）。</li><li>相比于客户端编译器，服务器端编译器可以将应用程序的执行性能提升30%到50%，但会消耗更多的资源。</li><li>层次编译综合了客户端编译器和服务器端编译器的优点，既可以像客户端编译器那样快速启动，又可以像服务器端编译器那样，在长时间收集运行时信息的基础上，优化应用程序的性能。</li></ul><p>目前，已经出现了很多代码优化的手段。对编译器来说，一个主要的任务就是分析所有的可能性，权衡使用某种优化手段的利弊，在此基础上编译代码，优化应用程序的性能。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：Eva Andreasson,译者：曹旭东 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM性能优化， Part 1 ―― JVM简介</title>
      <link href="/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%201%20%E2%80%95%E2%80%95%20JVM%E7%AE%80%E4%BB%8B/"/>
      <url>/2018/04/28/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%8C%20Part%201%20%E2%80%95%E2%80%95%20JVM%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>[toc]</p><p>JVM性能调优：</p><ul><li>第一部分：概述</li><li>第二部分：编译工具</li><li>第三部分：垃圾回收</li><li>第四部分：并发压缩GC</li><li>第五部分：可扩展性</li></ul><h5 id="Java的性能与“一次编写，到处运行”的挑战"><a href="#Java的性能与“一次编写，到处运行”的挑战" class="headerlink" title="Java的性能与“一次编写，到处运行”的挑战"></a><strong>Java的性能与“一次编写，到处运行”的挑战</strong></h5><p>有不少人认为，Java平台本身就挺慢。其主要观点简单来说就是，Java性能低已经有些年头了 ―― 最早可以追溯到Java第一次用于企业级应用程序开发的时候。但这早就是老黄历了。事实是，如果你对不同的开发平台上运行简单的、静态的、确定性任务的运行结果做比较，你就会发现使用经过机器级优化（machine-optimized）代码的平台比任何使用虚拟环境进行运算的都要强，JVM也不例外。但是，在过去的10年中，Java的性能有了大幅提升。市场上不断增长的需求催生了垃圾回收算法的出现和编译技术的革新，在不断探索与优化的过程中，JVM茁壮成长。在这个系列文章中，我将介绍其中的一些内容。</p><p>JVM技术中最迷人的地方也正是其最具挑战性的地方：“一次编写，到处运行”。JVM并不对具体的用例、应用程序或用户负载进行优化，而是在应用程序运行过程中不断收集运行时信息，并以此为根据动态的进行优化。这种动态的运行时特性带来了很多动态问题。在设计优化方案时，以JVM为工作平台的程序无法依靠静态编译和可预测的内存分配速率（predictable allocation rates）对应用程序做性能评估，至少在对生产环境进行性能评估时是不行的。</p><p>机器级优化过的代码有时可以达到更好的性能，但它是以牺牲可移植性为代价的，在企业级应用程序中，动态负载和快速迭代更新是更加重要的。大多数企业会愿意牺牲一点机器级优化代码带来的性能，以此换取Java平台的诸多优势：</p><ul><li>编码简单，易于实现（意味着可以更快的推向市场）</li><li>有很多非常有才的程序员</li><li>使用Java API和标准库实现快速开发</li><li>可移植性 ―― 无需为每个平台都编写一套代码</li></ul><h5 id="从源代码到字节码"><a href="#从源代码到字节码" class="headerlink" title="从源代码到字节码"></a><strong>从源代码到字节码</strong></h5><p>作为一名Java程序员，你可以已经对编码、编译和运行这一套流程比较熟悉了。假如说，现在你写了一个程序代码MyApp.java，准备编译运行。为了运行这个程序，首先，你需要使用JDK内建的Java语言编译器，javac，对这个文件进行编译，它可以将Java源代码编译为字节码。javac将根据Java程序的源代码生成对应的可执行字节码，并将其保存为同名类文件：MyApp.class。在经过编译阶段后，你就可以在命令行中使用java命令或其他启动脚本载入可执行的类文件来运行程序，并且可以为程序添加启动参数。之后，类会被载入到运行时（这里指的是正在运行的JVM），程序开始运行。</p><p>上面所描述的就是在运行Java应用程序时的表面过程，但现在，我们要深入挖掘一下，在调用Java命令时，到底发生了什么？JVM到底是什么？大多数程序员是通过不断的调优，即使用相应的启动参数，与JVM进行交互，使Java程序运行的更快，同时避免程序出现“out of memory”错误。但你是否想过，为什么我们必须要通过JVM来运行Java应用程序呢？</p><h5 id="什么是JVM"><a href="#什么是JVM" class="headerlink" title="什么是JVM"></a><strong>什么是JVM</strong></h5><p>简单来说，JVM是用于执行Java应用程序和字节码的软件模块，并且可以将字节码转换为特定硬件和特定操作系统的本地代码。正因如此，JVM使Java程序做到了“一次编写，到处运行”。Java语言的可移植性是得到企业级应用程序开发者青睐的关键：开发者无需因平台不同而把程序重新编写一遍，因为有JVM负责处理字节码到本地代码的转换和平台相关优化的工作。</p><blockquote><p>基本上来说，JVM是一个虚拟运行环境，对于字节码来说就像是一个机器一样，可以执行任务，并通过底层实现执行内存相关的操作。</p></blockquote><p>JVM也可以在运行java应用程序时，很好的管理动态资源。这指的是他可以正确的分配、回收内存，在不同的上维护一个具有一致性的线程模型，并且可以为当前的CPU架构组织可执行指令。JVM解放了程序员，使程序员不必再关系对象的生命周期，使程序员不必再关心应该在何时释放内存。而这，正是使用着类似C语言的非动态语言的程序员心中永远的痛。</p><p>你可以将JVM当做是一种专为Java而生的特殊的操作系统，它的工作是管理运行Java应用程序的运行时环境。简单来说，JVM就是运行字节码指令的虚拟执行环境，并且可以分配执行任务，或通过底层实现对内存进行操作。</p><h5 id="JVM组件简介"><a href="#JVM组件简介" class="headerlink" title="JVM组件简介"></a><strong>JVM组件简介</strong></h5><p>关于JVM内部原理与性能优化有很多内容可写。作为这个系列的开篇文章，我简单介绍JVM的内部组件。这个简要介绍对于那些JVM新手比较有帮助，也是为后面的深入讨论做个铺垫。</p><h5 id="从一种语言到另一种-――-关于Java编译器"><a href="#从一种语言到另一种-――-关于Java编译器" class="headerlink" title="从一种语言到另一种 ―― 关于Java编译器"></a><strong>从一种语言到另一种 ―― 关于Java编译器</strong></h5><p><code>编译器</code>以一种语言为输入，生成另一种可执行语言作为输出。Java编译器主要完成2个任务：</p><ol><li>实现Java语言的可移植性，不必局限于某一特定平台；</li><li>确保输出代码可以在目标平台能够有效率的运行。</li></ol><p>编译器可以是静态的，也可以是动态的。静态编译器，如javac，它以Java源代码为输入，将其编译为字节码（一种可以运行JVM中的语言）。<em>静态编译器</em>解释输入的源代码，而生成可执行输出代码则会在程序真正运行时用到。因为输入是静态的，所有输出结果总是相同的。只有当你修改的源代码并重新编译时，才有可能看到不同的编译结果。</p><p><em>动态编译器</em>，如使用<a href="https://github.com/caoxudong/translation/blob/master/java/jvm/JVM_performance_optimization_Part_1_A_JVM_technology_primer.md#%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90" title="相关资源" target="_blank" rel="noopener">Just-In-Time(JIT，即时编译)</a>技术的编译器，会动态的将一种编程语言编译为另一种语言，这个过程是在程序运行中同时进行的。JIT编译器会收集程序的运行时数据（在程序中插入性能计数器），再根据运行时数据和当前运行环境数据动态规划编译方案。动态编译可以生成更好的序列指令，使用更有效率的指令集合替换原指令集合，或剔除冗余操作。收集到的运行时数据的越多，动态编译的效果就越好；这通常称为代码优化或重编译。</p><p>动态编译使你的程序可以应对在不同负载和行为下对新优化的需求。这也是为什么动态编译器非常适合Java运行时。这里需要注意的地方是，动态编译器需要动用额外的数据结构、线程资源和CPU指令周期，才能收集运行时信息和优化的工作。若想完成更高级点的优化工作，就需要更多的资源。但是在大多数运行环境中，相对于获得的性能提升来说，动态编译的带来的性能损耗其实是非常小的 ―― 动态编译后的代码的运行效率可以比纯解释执行（即按照字节码运行，不做任何修改）快5到10倍。</p><h5 id="内存分配与垃圾回收"><a href="#内存分配与垃圾回收" class="headerlink" title="内存分配与垃圾回收"></a><strong>内存分配与垃圾回收</strong></h5><p><code>内存分配</code>是以线程为单位，在“Java进程专有内存地址空间”中，也就是Java堆中分配的。在普通的客户端Java应用程序中，内存分配都是单线程进行的。但是，在企业级应用程序和服务器端应用程序中，单线程内存分配却并不是个好办法，因为它无法充分利用现代多核时代的并行特性。</p><p>并行应用程序设计要求JVM确保多线程内存分配不会在同一时间将同一块地址空间分配给多个线程。你可以在整个内存空间中加锁来解决这个问题，但是这个方法（即所谓的“堆锁”）开销较大，因为它迫使所有线程在分配内存时逐个执行，对资源利用和应用程序性能有较大影响。多核程序的一个额外特点是需要有新的资源分配方案，避免出现单线程、序列化资源分配的性能瓶颈。</p><p>常用的解决方案是将堆划分为几个区域，每个区域都有适当的大小，当然具体的大小需要根据实际情况做相应的调整，因为不同应用程序之间，内存分配速率、对象大小和线程数量的差别是非常大的。Thread Local Allocation Buffer（TLAB），有时也称为Thraed Local Area（TLA），是线程自己使用的专用内存分配区域，在使用的时候无需获取堆锁。当这个区域用满的时候，线程会申请新的区域，直到堆中所有预留的区域都用光了。当堆中没有足够的空间来分配内存时，堆就“满”了，即堆上剩余的空间装不下待分配空间的对象。当堆满了的时候，垃圾回收就开始了。</p><h5 id="碎片化"><a href="#碎片化" class="headerlink" title="碎片化"></a><strong>碎片化</strong></h5><p>使用TLAB的一个风险是，由于堆上内存碎片的增加，使用内存的效率会下降。如果应用程序创建的对象的大小无法填满TLAB，而这块TLAB中剩下的空间又太小，无法分配给新的对象，那么这块空间就被浪费了，这就是所谓的“碎片”。如果“碎片”周围已分配出去的内存长时间无法回收，那么这块碎片研究长时间无法得到利用。</p><p><code>碎片化</code>是指堆上存在了大量的<code>碎片</code>，由于这些小碎片的存在而使堆无法得到有效利用，浪费了堆空间。为应用程序设置TLAB的大小时，若是没有对应用程序中对象大小和生命周期和合理评估，导致TLAB的大小设置不当，就会是使堆逐渐碎片化。随着应用程序的运行，被浪费的碎片空间会逐渐增多，导致应用程序性能下降。这是因为系统无法为新线程和新对象分配空间，于是为防止出现OOM（out-of-memory）错误，而频繁GC的缘故。</p><p>对于TLAB产生的空间浪费这个问题，可以采用“曲线救国”的策略来解决。例如，可以根据应用程序的具体环境调整TLAB的大小。这个方法既可以临时，也可以彻底的避免堆空间的碎片化，但需要随着应用程序内存分配行为的变化而修改TLAB的值。此外，还可以使用一些复杂的JVM算法和其他的方法来组织堆空间来获得更有效率的内存分配行为。例如，JVM可以实现空闲列表（free-list），空闲列表中保存了堆中指定大小的空闲块。具有类似大小空闲块保存在一个空闲列表中，因此可以创建多个空闲列表，每个空闲列表保存某个范围内的空闲块。在某些事例中，使用空闲列表会比使用按实际大小分配内存的策略更有效率。线程为某个对象分配内存时，可以在空闲列表中寻找与对象大小最接近的空间块使用，相对于使用固定大小的TLAB，这种方法更有利于避免碎片化的出现。</p><h5 id="GC往事"><a href="#GC往事" class="headerlink" title="GC往事"></a><strong>GC往事</strong></h5><blockquote><p>早期的垃圾回收器有多个老年代，但实际上，存在多个老年代是弊大于利的。</p></blockquote><p>另一种对抗碎片化的方法是创建一个所谓的年轻代，在这个专有的堆空间中，保存了所有新创建的对象。堆空间中剩余的空间就是所谓的老年代。老年代用于保存具有较长生命周期的对象，即当对象能够挺过几轮GC而不被回收，或者对象本身很大（一般来说，大对象都具有较长的寿命周期）时，它们就会被保存到老年代。为了让你能够更好的理解这个方法，我们有必要谈谈垃圾回收。</p><h5 id="垃圾回收与应用程序性能"><a href="#垃圾回收与应用程序性能" class="headerlink" title="垃圾回收与应用程序性能"></a><strong>垃圾回收与应用程序性能</strong></h5><p>垃圾回收就是JVM释放那些没有引用指向的堆内存的操作。当垃圾回收首次触发时，有引用指向的对象会被保存下来，那些没有引用指向的对象占用的空间会被回收。当所有可回收的内存都被回收后，这些空间就可以被分配给新的对象了。</p><p>垃圾回收不会回收仍有引用指向的对象；否则就会违反JVM规范。这个规则有一个例外，就是对软引用或弱引用的使用，当垃圾回收器发现内存快要用完时，会回收只有软引用或<a href="http://java.sun.com/docs/books/performance/1st_edition/html/JPAppGC.fm.html" title="weak reference" target="_blank" rel="noopener">弱引用</a>指向的对象所占用的内存。我的建议是，尽量避免使用弱引用，因为Java规范中存在的模糊的表述可能会使你对弱引用的使用产生误解。此外，Java本身是动态内存管理的，你没必要考虑什么时候该释放哪块内存。</p><p>对于垃圾回收来说，挑战在于，如何将垃圾回收对应用程序造成的影响降到最小。如果垃圾回收执行的不充分，那么应用程序迟早会发生OOM错误；如果垃圾回收执行的太频繁，会对应用程序的吞吐量和响应时间造成影响，当然，这都不是好的影响。</p><h5 id="GC算法"><a href="#GC算法" class="headerlink" title="GC算法"></a><strong>GC算法</strong></h5><p>目前已经出现了很多垃圾回收算法。在这个系列文章中将对其中的一些进行介绍。概括来说，垃圾回收主要有两种方式，引用计数（reference counting）和引用追踪（reference tracing）。</p><ul><li>引用计数垃圾回收器会记录指向某个对象的引用的数目。当指向某个对象引用数位0时，该对象占用的内存就可以被回收了，这是引用计数垃圾回收的一个主要优点。使用引用计数垃圾回收的需要克服的难点在于如何解决循环引用带来的问题，以及如何保证引用计数的实效性。</li><li>引用追踪垃圾回收器会标记所有仍有引用指向的对象，并从已标记的对象出发，继续标记这些对象指向的对象。当所有仍有引用指向的对象都被标记为“live”后，所有未标记的对象会被回收。这种方式可以解决循环引用结果带来的问题，但是大多数情况下，垃圾回收器必须等待标记完全结束才能开始进行垃圾回收。</li></ul><p>上面提到的两种算法有多种不同的实现方法，其中最著名可算是标记或拷贝算法（marking or copying algorithm）和并行或并发算法（parallel or concurrent algorithm）。我将在后续的文章中对它们进行介绍。</p><p>分代垃圾回收的意思是，将堆划分为几个不同的区域，分别用于存储新对象和老对象。其中“老对象”指的是挺过了几轮垃圾回收而不死的对象。将堆空间分为年轻代和老年代，分别用于存储新对象和老对象可以通过回收生命周期较短的对象，并将生命周期较长的对象从年轻代提升到老年代的方法来减少堆空间中的碎片，降低堆空间碎片化的风险。此外，使用年轻代还有一个好处是，它可以推出对老年代进行垃圾回收的需求（对老年代进行垃圾回收的代价比较大，因为老年代中那些生命周期较长的对象通常包含有更多的引用，遍历一次需要花费更多的时间），因那些生命周期较短的对通常会重用年轻代中的空间。</p><p>还有一个值得一提的算法改进是压缩，它可以用来管理堆空间中的碎片。基本上将，压缩就是将对象移动到一起，再释放掉较大的连续空间。如果你对磁盘碎片和处理磁盘碎片的工具比较熟悉的话你就会理解压缩的含义了，只不过这里的压缩是工作在Java堆空间中的。我将在该系列后续的内容中对压缩进行介绍。</p><h5 id="结论：回顾与展望"><a href="#结论：回顾与展望" class="headerlink" title="结论：回顾与展望"></a><strong>结论：回顾与展望</strong></h5><p>JVM实现了可移植性（“一次编写，到处运行”）和动态内存管理，这两个特点也是其广受欢迎，并且具有较高生产力的原因。</p><p>作为这个系列文章的第一篇，我介绍了编译器如何将字节码转换为平台相关指令的语言，以及如何<code>动态</code>优化Java程序的运行性能。不同的编译器迎合了不同应用程序的需要。</p><p>此外，简单介绍了内存分配和垃圾回收的一点内容，及其与Java应用程序性能的关系。基本上将，Java应用程序运行的速度越快，填满Java堆所需的时间就越短，触发垃圾回收的频率也越高。这里遇到的问题就是，在应用程序出现OOM错误之前，如何在对应用程序造成的影响尽可能小的情况下，回收足够多的内存空间。将后续的文章中，我们将对传统垃圾回收方法和现今的垃圾回收方法对JVM性能优化的影响做详细讨论。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：Eva Andreasson,译者：曹旭东 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>jdk1.7和1.8共存及切换</title>
      <link href="/2018/04/28/jdk1.7%E5%92%8C1.8%E5%85%B1%E5%AD%98%E5%8F%8A%E5%88%87%E6%8D%A2/"/>
      <url>/2018/04/28/jdk1.7%E5%92%8C1.8%E5%85%B1%E5%AD%98%E5%8F%8A%E5%88%87%E6%8D%A2/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="所需软件"><a href="#所需软件" class="headerlink" title="所需软件"></a>所需软件</h3><p>jdk 1.7和1.8 64位</p><h3 id="安装步奏"><a href="#安装步奏" class="headerlink" title="安装步奏"></a>安装步奏</h3><p>1.7版本是普通的安装，但是1.8会在c盘创建几个文件，==以及修改注册表==。</p><h3 id="修改步奏"><a href="#修改步奏" class="headerlink" title="修改步奏"></a>修改步奏</h3><p>首先删掉1.8自动生成的环境变量，即：<br>C:\ProgramData\Oracle\Java\javapath;<br>并将此目录下的三个快捷方式删掉<br>然后删除1.8生成的几个文件 即 C:\Windows\System32下的java.exe，javaw.exe,javaws.exe<br>然后进入dos运行java -version<br>那么 ok  报错了   has value’1.8’，but ‘1.7’……<br><img src="http://i1.piimg.com/567571/ee8ac9f3c3023fc4.png" alt="">    </p><p>运行regedit打开注册表<strong>HKEY_LOCAL_MACHINE\SOFTWARE\JavaSoft\Java Runtime Environment</strong><br>点击它<br>然后点击右侧的CurrentVersion  将值1.8修改为1.7 然后确定<br>重新java -verison   成功</p><p><img src="http://i1.piimg.com/567571/aae8840adaf94c50.png" alt="">    </p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java操作Spark学习</title>
      <link href="/2018/04/28/Java%E6%93%8D%E4%BD%9CSpark%E5%AD%A6%E4%B9%A0/"/>
      <url>/2018/04/28/Java%E6%93%8D%E4%BD%9CSpark%E5%AD%A6%E4%B9%A0/</url>
      <content type="html"><![CDATA[<p>[toc]</p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>131072<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/yarn/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/yarn/journal<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.yarn.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>EPRI-DCLOUD-HDP01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.yarn.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">从hadoop/ect/hadoop里扒过来</span><br><span class="line">不需要最后一行配置</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/yarn/hadoop-2.6.0/etc/hadoop/excludes<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">所需配置如下</span><br><span class="line">&lt;?xml version="1.0"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>nn0,nn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn0<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>EPRI-DCLOUD-HDP01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn0<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>EPRI-DCLOUD-HDP01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>EPRI-DCLOUD-HDP02:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>EPRI-DCLOUD-HDP02:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://EPRI-DCLOUD-HDP01:8485;EPRI-DCLOUD-HDP02:8485;EPRI-DCLOUD-HDP03:8485/ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>EPRI-DCLOUD-HDP01,EPRI-DCLOUD-HDP02,EPRI-DCLOUD-HDP03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.session-timeout.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/yarn/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/yarn/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/yarn/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.qjournal.write-txns.timeout.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>600000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h4><pre><code>从hive的conf扒过来</code></pre><h3 id="所需jar文件"><a href="#所需jar文件" class="headerlink" title="所需jar文件"></a>所需jar文件</h3><pre><code>jar包从linux上扒下来</code></pre><h3 id="打jar方式"><a href="#打jar方式" class="headerlink" title="打jar方式"></a>打jar方式</h3><p><img src="http://i2.muimg.com/567571/2e8a84dbfbe2aae9.png" alt=""><br><img src="http://i4.buimg.com/567571/f134fd407fe7dd60.png" alt=""></p><h3 id="代码方面"><a href="#代码方面" class="headerlink" title="代码方面"></a>代码方面</h3><p>demo1：</p><pre><code class="java">SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"hivePartion"</span>);SparkContext sc = <span class="keyword">new</span> SparkContext(conf);HiveContext hiveCtx = <span class="keyword">new</span> HiveContext(sc);String sql = <span class="string">"select * from fjudm4.hbase_md_load_bus_hisdata limit 1"</span>;Row[] rows = hiveCtx.sql(sql).collect();<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rows.length; i++) {    Row row = rows[i];    System.out.println(<span class="string">"i为"</span> + i + <span class="string">"    i对应的row为"</span> + row.toString());}    sc.stop();</code></pre><pre><code>#Row[] rows里装的是所有的查出来的数据  所有条   注意 它toString无法显示他的所有数据  只显示地址#row是一条数据  不是数组也不是list  格式:[20161103,115967690991992834,null,福建.半兰山/220kV.1负荷,null,ss,r,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2016-11-04,2016-11-03]#row.get()类似于sql里的rs.getString();</code></pre><h2 id="开发中遇到的问题"><a href="#开发中遇到的问题" class="headerlink" title="开发中遇到的问题"></a>开发中遇到的问题</h2><p>phoenix-4.6.0-HBase-1.1-client.jar和spark-assembly-1.5.2-hadoop2.6.0.jar会冲突thrift包</p><pre><code class="java">Exception in thread <span class="string">"main"</span> java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClientat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">346</span>)at org.apache.spark.sql.hive.client.ClientWrapper.&lt;init&gt;(ClientWrapper.scala:<span class="number">171</span>)at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class="number">57</span>)at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)at java.lang.reflect.Constructor.newInstance(Constructor.java:<span class="number">526</span>)at org.apache.spark.sql.hive.client.IsolatedClientLoader.liftedTree1$<span class="number">1</span>(IsolatedClientLoader.scala:<span class="number">183</span>)at org.apache.spark.sql.hive.client.IsolatedClientLoader.&lt;init&gt;(IsolatedClientLoader.scala:<span class="number">179</span>)at org.apache.spark.sql.hive.HiveContext.metadataHive$lzycompute(HiveContext.scala:<span class="number">226</span>)at org.apache.spark.sql.hive.HiveContext.metadataHive(HiveContext.scala:<span class="number">185</span>)at org.apache.spark.sql.hive.HiveContext.setConf(HiveContext.scala:<span class="number">392</span>)at org.apache.spark.sql.hive.HiveContext.defaultOverrides(HiveContext.scala:<span class="number">174</span>)at org.apache.spark.sql.hive.HiveContext.&lt;init&gt;(HiveContext.scala:<span class="number">177</span>)at com.sgcc.epri.dcloud.dm_hive_datacheck.query.impl.HiveQueryImpl.queryCount(HiveQueryImpl.java:<span class="number">59</span>)at com.sgcc.epri.dcloud.dm_hive_datacheck.common.QueryAndCompare.doCheck(QueryAndCompare.java:<span class="number">48</span>)at com.sgcc.epri.dcloud.dm_hive_datacheck.common.Common.check(Common.java:<span class="number">35</span>)at com.sgcc.epri.dcloud.dm_hive_datacheck.main.MainCompare.main(MainCompare.java:<span class="number">18</span>)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:<span class="number">674</span>)at org.apache.spark.deploy.SparkSubmit$.doRunMain$<span class="number">1</span>(SparkSubmit.scala:<span class="number">180</span>)at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:<span class="number">205</span>)at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:<span class="number">120</span>)at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient    at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:<span class="number">1412</span>)    at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:<span class="number">62</span>)    at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:<span class="number">72</span>)    at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:<span class="number">2453</span>)    at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:<span class="number">2465</span>)    at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:<span class="number">340</span>)    ... <span class="number">25</span> moreCaused by: java.lang.reflect.InvocationTargetException    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class="number">57</span>)    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)    at java.lang.reflect.Constructor.newInstance(Constructor.java:<span class="number">526</span>)    at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:<span class="number">1410</span>)    ... <span class="number">30</span> moreCaused by: java.lang.NoSuchMethodError: org.apache.thrift.protocol.TProtocol.getScheme()Ljava/lang/Class;    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$set_ugi_args.write(ThriftHiveMetastore.java)    at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:<span class="number">63</span>)    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.send_set_ugi(ThriftHiveMetastore.java:<span class="number">3260</span>)    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.set_ugi(ThriftHiveMetastore.java:<span class="number">3251</span>)    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:<span class="number">352</span>)    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:<span class="number">214</span>)    ... <span class="number">35</span> more</code></pre><p>删除了phoenix包里的scheme包解决了</p><p>hiveSQL查询不出数据</p><pre><code class="sql"><span class="keyword">select</span> * <span class="keyword">from</span> fjudm4.HBASE_MD_MEASANALOG_BREAKER <span class="keyword">where</span> <span class="keyword">timestamp</span> &gt;= <span class="keyword">to_date</span>(<span class="string">'2016-11-01 00:00:00.0'</span>) <span class="keyword">and</span> <span class="keyword">timestamp</span> &lt; <span class="keyword">to_date</span>(<span class="string">'2016-11-01 00:05:00.0'</span>) <span class="keyword">limit</span> <span class="number">3</span>;</code></pre><p>sql错了，hive不可以用timestamp直接比较 应该用时间分区列date=’2016-11-01’</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Exception</title>
      <link href="/2018/04/28/Exception/"/>
      <url>/2018/04/28/Exception/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><h4 id="Unsupported-major-minor-version-52-0"><a href="#Unsupported-major-minor-version-52-0" class="headerlink" title="Unsupported major.minor version 52.0"></a>Unsupported major.minor version 52.0</h4><p>Java虚拟机报错，jdk版本不匹配，右键项目properties</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d955056f4.png" alt="1.png"></p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d9521ef64.png" alt="2.png"><br>当时jre7是灰色的，是不可用的，show all runtimes后选择jre8版本可以解决，或者等会再打开这个界面，会出现原来的版本jre7</p><h4 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h4><p>今天出了个空指针的错，给String泛型的list添加(0+””)竟然给报错，经检查，是声明list的时候没有给它开辟空间，list添加0+””不会报错，会把0添加进去。</p><h4 id="连接服务器使用hive连接时FileNotFoundException"><a href="#连接服务器使用hive连接时FileNotFoundException" class="headerlink" title="连接服务器使用hive连接时FileNotFoundException"></a>连接服务器使用hive连接时FileNotFoundException</h4><pre><code>log4j:ERROR setFile(null,true) call failed.java.io.FileNotFoundException: /home/yarn/hadoop-2.6.0/logs/flume-hadoop/flume-hadoop.log (Permission denied)    at java.io.FileOutputStream.open(Native Method)    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:221)    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:142)    at org.apache.log4j.FileAppender.setFile(FileAppender.java:294)    at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165)    at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:223)    at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307)    at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172)    at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104)    at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842)    at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768)    at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648)    at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514)    at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:580)    at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:526)    at org.apache.log4j.LogManager.&lt;clinit&gt;(LogManager.java:127)    at org.slf4j.impl.Log4jLoggerFactory.getLogger(Log4jLoggerFactory.java:66)    at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:270)    at org.apache.commons.logging.impl.SLF4JLogFactory.getInstance(SLF4JLogFactory.java:155)    at org.apache.commons.logging.impl.SLF4JLogFactory.getInstance(SLF4JLogFactory.java:132)    at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:657)    at org.apache.hadoop.util.VersionInfo.&lt;clinit&gt;(VersionInfo.java:37)log4j:ERROR Either File or DatePattern options are not set for appender [File].SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/home/yarn/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</code></pre><p>这个是因为使用的用户的权限不够<br>noClassFound一般是jar包依赖</p><h4 id="Java操作phoenix连接需要配置host文件"><a href="#Java操作phoenix连接需要配置host文件" class="headerlink" title="Java操作phoenix连接需要配置host文件"></a>Java操作phoenix连接需要配置host文件</h4><p>url：C:\Windows\System32\drivers\etc</p><p>连接hivejdbc的时候一个报错</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d9545532a.png" alt="3.png"><br>一番查找之后发现是phoenix-4.6.0-HBase-1.1-client.jar导致的</p><h4 id="fat-jar打包"><a href="#fat-jar打包" class="headerlink" title="fat-jar打包"></a>fat-jar打包</h4><p>用fat-jar打成jar包放在服务器上运行，有可能会丢失依赖的jar包导致程序运行出错，或者不报错却查不出数据，使用eclipse本身自带的打jar工具，右键export,选择Java里的runnable JAR file</p><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d954e38e8.png" alt="4.png"><br>改变项目路径的时候，需要把新的路径–build path–use as source folder<br>build的路径会成为固定路径 比如com.baidu.demo<br>如果只有com包就build，.java的package为baidu.demo</p><p>上传maven项目时</p><pre><code>-Dmaven.multiModuleProjectDirectory system property is not set. Check $M2_HOME environment variable and mvn script match..添加M2_HOME的环境变量2.Preference-&gt;Java-&gt;Installed JREs-&gt;Edit 选择一个jdk,添加  -Dmaven.multiModuleProjectDirectory=$M2_HOME-Dmaven.multiModuleProjectDirectory=$M2_HOME</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d954e56fb.png" alt="5.png"></p><h4 id="执行hive查询时-Error-while-processing-statement-FAILED-Execution-Error-return-code-1-from-org-apache-hadoop-hive-ql-exec-mr-MapRedTask"><a href="#执行hive查询时-Error-while-processing-statement-FAILED-Execution-Error-return-code-1-from-org-apache-hadoop-hive-ql-exec-mr-MapRedTask" class="headerlink" title="执行hive查询时 Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask"></a>执行hive查询时 Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</h4><pre><code>java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask    at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)    at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:392)    at org.apache.hive.jdbc.HivePreparedStatement.executeQuery(HivePreparedStatement.java:109)    at com.sgcc.epri.dcloud.dm_hive_datacheck.query.HiveQuery.queryHiveLoadCount(HiveQuery.java:39)    at com.sgcc.epri.dcloud.dm_hive_datacheck.common.ReadExcelAndCompare.readLoad(ReadExcelAndCompare.java:90)    at com.sgcc.epri.dcloud.dm_hive_datacheck.main.MainLoad_Forecast.main(MainLoad_Forecast.java:14)</code></pre><p><img src="https://ooo.0o0.ooo/2017/06/02/5930d954287b9.png" alt="6.png"><br>这是hdfs没有空间了</p><h4 id="hive查询聚合函数-找不到COUNT这个列"><a href="#hive查询聚合函数-找不到COUNT这个列" class="headerlink" title="hive查询聚合函数 找不到COUNT这个列"></a>hive查询聚合函数 找不到COUNT这个列</h4><p>使用count = rs.getString(1);来取 不要用count = rs.getString(“COUNT”);</p><pre><code>select count(1) as COUNT from fjudm4.hbase_md_load_bus_fc_96lc_submit_balance where date = &apos;2016-01-01&apos;java.sql.SQLException        at org.apache.hadoop.hive.jdbc.HiveBaseResultSet.findColumn(HiveBaseResultSet.java:81)        at org.apache.hadoop.hive.jdbc.HiveBaseResultSet.getString(HiveBaseResultSet.java:484)        at com.sgcc.epri.dcloud.dm_hive_datacheck.query.HiveQuery.queryHiveLoadCount(HiveQuery.java:47)        at com.sgcc.epri.dcloud.dm_hive_datacheck.common.ReadExcelAndCompare.readLoad(ReadExcelAndCompare.java:120)        at com.sgcc.epri.dcloud.dm_hive_datacheck.main.MainLoad_ForecastCount.main(MainLoad_ForecastCount.java:16)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:606)        at org.eclipse.jdt.internal.jarinjarloader.JarRsrcLoader.main(JarRsrcLoader.java:58)</code></pre><h4 id="maven配置ojdbc"><a href="#maven配置ojdbc" class="headerlink" title="maven配置ojdbc"></a>maven配置ojdbc</h4><p>因为ojdbc是收费的！(/哭)只能自己下载ojdbc对应的版本jar包，在当前路径打开dos，比如我是在桌面，我执行命令将它安装到本地仓库</p><pre><code>mvn install:install-file -DgroupId=com.Oracle -DartifactId=ojdbc14 -Dversion=10.2.0.2.0 -Dpackaging=jar -Dfile=C:\Users\Administrator\Desktop\ojdbc14-10.2.0.2.0.jar</code></pre>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Elasticsearch-Head插件</title>
      <link href="/2018/04/28/Elasticsearch-Head%E6%8F%92%E4%BB%B6/"/>
      <url>/2018/04/28/Elasticsearch-Head%E6%8F%92%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>[toc]</p><p>Apache Lucene将所有信息写到一个成为倒排索引的结构中。</p><h3 id="ES与MYSQL对应关系"><a href="#ES与MYSQL对应关系" class="headerlink" title="ES与MYSQL对应关系"></a>ES与MYSQL对应关系</h3><p><img src="https://ooo.0o0.ooo/2017/06/08/5938e8d6b2bcf.png" alt="20160717132008382.png"></p><p>以上表为依据，<br>ES中的新建文档（在Index/type下）相当于Mysql中（在某Database的Table）下插入一行数据。</p><h3 id="新增"><a href="#新增" class="headerlink" title="新增"></a>新增</h3><p><img src="https://ooo.0o0.ooo/2017/06/08/5938ea18205aa.png" alt="20160717132135758.png"></p><h3 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h3><p>查询全部文档如下： </p><p><img src="https://ooo.0o0.ooo/2017/06/08/5938ea1842289.png" alt="20160717132224477.png"></p><p>复合查询 </p><p><img src="https://ooo.0o0.ooo/2017/06/08/5938eba553d23.png" alt="微信截图_20170608141549.png"></p><h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p><img src="https://ooo.0o0.ooo/2017/06/08/5938edfc39280.png" alt="微信截图_20170608142552.png"></p><p><img src="https://ooo.0o0.ooo/2017/06/08/5938edcef011c.png" alt="1496903100(1.png"></p><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p><img src="https://ooo.0o0.ooo/2017/06/08/5938ee2917fe9.png" alt="12312.png"></p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>AtomicInteger</title>
      <link href="/2018/04/28/AtomicInteger/"/>
      <url>/2018/04/28/AtomicInteger/</url>
      <content type="html"><![CDATA[<p>AtomicInteger 是一个支持原子操作的 Integer 类，就是保证对AtomicInteger类型变量的增加和减少操作是原子性的，不会出现多个线程下的数据不一致问题。通常情况下，在Java里面，++i或者–i不是线程安全的，这里面有三个独立的操作：获取变量当前值，为该值+1/-1，然后写回新的值。在没有额外资源可以利用的情况下，只能使用加锁才能保证读-改-写这三个操作时“原子性”的。</p><p>先看AtomicInteger中的几个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">addAndGet</span><span class="params">(<span class="keyword">int</span> delta)</span></span></span><br><span class="line"><span class="function"> 以原子方式将给定值与当前值相加。实际上就是等于线程安全版本的i</span>=i+delta操作。</span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> expect, <span class="keyword">int</span> update)</span></span></span><br><span class="line"><span class="function"> 如果当前值 </span>==预期值，则以原子方式将该值设置为给定的更新值。如果成功就返回<span class="keyword">true</span>，否则返  回<span class="keyword">false</span>，并且不修改原值。</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">decrementAndGet</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  以原子方式将当前值减 1。相当于线程安全版本的--i操作。</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  获取当前值。</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getAndAdd</span><span class="params">(intdelta)</span></span></span><br><span class="line"><span class="function"> 以原子方式将给定值与当前值相加。相当于线程安全版本的t</span>=i;i+=delta;returnt;操作。</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getAndDecrement</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> 以原子方式将当前值减 1。相当于线程安全版本的i--操作。</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getAndIncrement</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> 以原子方式将当前值加 1。相当于线程安全版本的i++操作。</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getAndSet</span><span class="params">(intnewValue)</span></span></span><br><span class="line"><span class="function"> 以原子方式设置为给定值，并返回旧值。相当于线程安全版本的t</span>=i;i=newValue;returnt;操作。</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  以原子方式将当前值加 1。相当于线程安全版本的++i操作。</span></span><br></pre></td></tr></table></figure><p>再看源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sun.misc.Unsafe;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicInteger</span> <span class="keyword">extends</span> <span class="title">Number</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;  </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">6214790243416807050L</span>;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// setup to use Unsafe.compareAndSwapInt for updates  </span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe unsafe = Unsafe.getUnsafe();  </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> valueOffset;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> &#123;  </span><br><span class="line">  <span class="keyword">try</span> &#123;  </span><br><span class="line">valueOffset = unsafe.objectFieldOffset  </span><br><span class="line">(AtomicInteger.class.getDeclaredField(<span class="string">"value"</span>));  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception ex) &#123; <span class="keyword">throw</span> <span class="keyword">new</span> Error(ex); &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> value;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AtomicInteger</span><span class="params">(<span class="keyword">int</span> initialValue)</span> </span>&#123;  </span><br><span class="line">value = initialValue;  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AtomicInteger</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">get</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">return</span> value;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(<span class="keyword">int</span> newValue)</span> </span>&#123;  </span><br><span class="line">value = newValue;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">lazySet</span><span class="params">(<span class="keyword">int</span> newValue)</span> </span>&#123;  </span><br><span class="line">unsafe.putOrderedInt(<span class="keyword">this</span>, valueOffset, newValue);  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">   <span class="comment">//以原子方式设置为给定值，并返回旧值。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndSet</span><span class="params">(<span class="keyword">int</span> newValue)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, newValue))  </span><br><span class="line"><span class="keyword">return</span> current;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">   <span class="comment">//如果当前值 ==预期值，则以原子方式将该值设置为给定的更新值。如果成功就返回，否则返回，并且不修改原值。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> expect, <span class="keyword">int</span> update)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">return</span> unsafe.compareAndSwapInt(<span class="keyword">this</span>, valueOffset, expect, update);  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">weakCompareAndSet</span><span class="params">(<span class="keyword">int</span> expect, <span class="keyword">int</span> update)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">return</span> unsafe.compareAndSwapInt(<span class="keyword">this</span>, valueOffset, expect, update);  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">//以原子方式将当前值加1。相当于线程安全版本的i++操作。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndIncrement</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current + <span class="number">1</span>;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> current;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">  <span class="comment">//以原子方式将当前值减 1相当于线程安全版本的i--操作。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndDecrement</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current - <span class="number">1</span>;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> current;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">//以原子方式将给定值与当前值相加。相当于线程安全版本的操作。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndAdd</span><span class="params">(<span class="keyword">int</span> delta)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current + delta;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> current;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">  <span class="comment">//以原子方式将当前值加 1相当于线程安全版本的++i操作。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current + <span class="number">1</span>;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> next;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">   <span class="comment">//以原子方式将当前值减 1。相当于线程安全版本的--i操作。  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">decrementAndGet</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current - <span class="number">1</span>;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> next;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">   <span class="comment">//以原子方式将给定值与当前值相加。实际上就是等于线程安全版本的i=i+delta操作  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">addAndGet</span><span class="params">(<span class="keyword">int</span> delta)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current + delta;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> next;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过源码可以发现，AtomicInteger并没有使用Synchronized关键字实现原子性，几乎所有的数据更新都用到了compareAndSet(int expect, int update)这个方法。那么就不难看出AtomicInteger这个类的最核心的函数就是compareAndSet(int expect, int update)。</p><p>那么compareAndSet(int expect, int update)是干什么的呢？？？？</p><p>我们以getAndIncrement()方法为例，它的源码如下：    </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (;;) &#123;  </span><br><span class="line"><span class="keyword">int</span> current = get();  </span><br><span class="line"><span class="keyword">int</span> next = current + <span class="number">1</span>;  </span><br><span class="line"><span class="keyword">if</span> (compareAndSet(current, next))  </span><br><span class="line"><span class="keyword">return</span> current;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>==单看这段 代码 很难保证原子性， 因为根本没有更新value 的操作==</p><p> 重点在于compareAndSet() 函数</p><pre><code>public final boolean compareAndSet(int expect,int update)</code></pre><p>如果==当前值== == ==预期值==，则以原子方式将== 当前值 设置为给定的更新值。==</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">参数：</span><br><span class="line">expect - 预期值</span><br><span class="line">update - 新值</span><br><span class="line">返回：</span><br><span class="line">如果成功，则返回 <span class="keyword">true</span>。返回 False 指示实际值与预期值不相等。</span><br></pre></td></tr></table></figure><p>该函数 只有两个参数，可操作的确实三个值 ，即 value ,expect, update. 他使用了 由硬件保证其原子性的指令 CAS （compare and swap）。</p><p>compareAndSet  函数保证了 比较，赋值这两步操作可以通过一个原子操作完成。</p><p>然后看整个函数， 所有代码被放到了一个循环里面， </p><p>如果compareAndSet（）执行失败，则说明 在int current = get(); 后，其他线程对value进行了更新， 于是就循环一次，重新获取当前值，直到compareAndSet（）执行成功为止。<br>这里需要注意的是AtomicInteger所利用的是基于冲突检测的乐观并发策略（CAS自旋锁）。 所以这种乐观在线程数目非常多的情况下，失败的概率会指数型增加。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《JAVA与模式》之单例模式</title>
      <link href="/2018/04/28/%E3%80%8AJAVA%E4%B8%8E%E6%A8%A1%E5%BC%8F%E3%80%8B%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"/>
      <url>/2018/04/28/%E3%80%8AJAVA%E4%B8%8E%E6%A8%A1%E5%BC%8F%E3%80%8B%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>[toc]</p><p>在阎宏博士的《JAVA与模式》一书中开头是这样描述单例模式的：</p><p>　　==作为对象的创建模式，单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。这个类称为单例类。==</p><h3 id="单例模式的结构"><a href="#单例模式的结构" class="headerlink" title="单例模式的结构"></a>单例模式的结构</h3><p>==单例模式的特点：==</p><pre><code>单例类只能有一个实例。单例类必须自己创建自己的唯一实例。单例类必须给所有其他对象提供这一实例。</code></pre><h4 id="饿汉式单例类"><a href="#饿汉式单例类" class="headerlink" title="饿汉式单例类"></a>饿汉式单例类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EagerSingleton</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> EagerSingleton instance = <span class="keyword">new</span> EagerSingleton();</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 私有默认构造子</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">EagerSingleton</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 静态工厂方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> EagerSingleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　上面的例子中，在这个类被加载时，静态变量instance会被初始化，此时类的私有构造子会被调用。这时候，单例类的唯一实例就被创建出来了。</p><p>　　饿汉式其实是一种比较形象的称谓。既然饿，那么在创建对象实例的时候就比较着急，饿了嘛，于是在装载类的时候就创建对象实例。</p><pre><code>private static EagerSingleton instance = new EagerSingleton();</code></pre><p>　　饿汉式是典型的空间换时间，当类装载的时候就会创建类的实例，不管你用不用，先创建出来，然后每次调用的时候，就不需要再判断，节省了运行时间。</p><h4 id="懒汉式单例类"><a href="#懒汉式单例类" class="headerlink" title="懒汉式单例类"></a>懒汉式单例类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LazySingleton</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> LazySingleton instance = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 私有默认构造子</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">LazySingleton</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 静态工厂方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> LazySingleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">            instance = <span class="keyword">new</span> LazySingleton();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　上面的懒汉式单例类实现里对静态工厂方法使用了同步化，以处理多线程环境。　　</p><p>懒汉式其实是一种比较形象的称谓。既然懒，那么在创建对象实例的时候就不着急。会一直等到马上要使用对象实例的时候才会创建，懒人嘛，总是推脱不开的时候才会真正去执行工作，因此在装载对象的时候不创建对象实例。</p><pre><code>private static LazySingleton instance = null;</code></pre><p>懒汉式是典型的时间换空间,就是每次获取实例都会进行判断，看是否需要创建实例，浪费判断的时间。当然，如果一直没有人使用的话，那就不会创建实例，则节约内存空间</p><p>由于懒汉式的实现是线程安全的，这样会降低整个访问的速度，而且每次都要判断。那么有没有更好的方式实现呢？</p><h4 id="双重检查加锁"><a href="#双重检查加锁" class="headerlink" title="双重检查加锁"></a>双重检查加锁</h4><p>可以使用“双重检查加锁”的方式来实现，就可以既实现线程安全，又能够使性能不受很大的影响。那么什么是“双重检查加锁”机制呢？</p><p>所谓“双重检查加锁”机制，指的是：并不是每次进入getInstance方法都需要同步，而是先不同步，进入方法后，先检查实例是否存在，如果不存在才进行下面的同步块，这是第一重检查，进入同步块过后，再次检查实例是否存在，如果不存在，就在同步的情况下创建一个实例，这是第二重检查。这样一来，就只需要同步一次了，从而减少了多次在同步情况下进行判断所浪费的时间。</p><p>　　“双重检查加锁”机制的实现会使用关键字volatile，它的意思是：被volatile修饰的变量的值，将不会被本地线程缓存，所有对该变量的读写都是直接操作共享内存，从而确保多个线程能正确的处理该变量。</p><p>　　注意：在java1.4及以前版本中，很多JVM对于volatile关键字的实现的问题，会导致“双重检查加锁”的失败，因此“双重检查加锁”机制只只能用在java5及以上的版本。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">null</span>;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//先检查实例是否存在，如果不存在才进入下面的同步块</span></span><br><span class="line">        <span class="keyword">if</span>(instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="comment">//同步块，线程安全的创建实例</span></span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">                <span class="comment">//再次检查实例是否存在，如果不存在才真正的创建实例</span></span><br><span class="line">                <span class="keyword">if</span>(instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　这种实现方式既可以实现线程安全地创建实例，而又不会对性能造成太大的影响。它只是第一次创建实例的时候同步，以后就不需要同步了，从而加快了运行速度。</p><p>　　==提示：由于volatile关键字可能会屏蔽掉虚拟机中一些必要的代码优化，所以运行效率并不是很高。因此一般建议，没有特别的需要，不要使用。也就是说，虽然可以使用“双重检查加锁”机制来实现线程安全的单例，但并不建议大量采用，可以根据情况来选用。==</p><p>　　根据上面的分析，常见的两种单例实现方式都存在小小的缺陷，那么有没有一种方案，既能实现延迟加载，又能实现线程安全呢？</p><h4 id="Lazy-initialization-holder-class模式"><a href="#Lazy-initialization-holder-class模式" class="headerlink" title="Lazy initialization holder class模式"></a>Lazy initialization holder class模式</h4><p>　　这个模式综合使用了Java的类级内部类和多线程缺省同步锁的知识，很巧妙地同时实现了延迟加载和线程安全。</p><h5 id="1-相应的基础知识"><a href="#1-相应的基础知识" class="headerlink" title="1.相应的基础知识"></a>1.相应的基础知识</h5><p>　什么是类级内部类？<br>　　简单点说，类级内部类指的是，有static修饰的成员式内部类。如果没有static修饰的成员式内部类被称为对象级内部类。</p><p>　　类级内部类相当于其外部类的static成分，它的对象与外部类对象间不存在依赖关系，因此可直接创建。而对象级内部类的实例，是绑定在外部对象实例中的。</p><p>　　类级内部类中，可以定义静态的方法。在静态方法中只能够引用外部类中的静态成员方法或者成员变量。</p><p>　　类级内部类相当于其外部类的成员，只有在第一次被使用的时候才被会装载。</p><p>　多线程缺省同步锁的知识<br>　　大家都知道，在多线程开发中，为了解决并发问题，主要是通过使用synchronized来加互斥锁进行同步控制。但是在某些情况中，JVM已经隐含地为您执行了同步，这些情况下就不用自己再来进行同步控制了。这些情况包括：</p><pre><code>1.由静态初始化器（在静态字段上或static{}块中的初始化器）初始化数据时2.访问final字段时3.在创建线程之前创建对象时4.线程可以看见它将要处理的对象时</code></pre><h5 id="2-解决方案的思路"><a href="#2-解决方案的思路" class="headerlink" title="2.解决方案的思路"></a>2.解决方案的思路</h5><p>　　要想很简单地实现线程安全，可以采用静态初始化器的方式，它可以由JVM来保证线程的安全性。比如前面的饿汉式实现方式。但是这样一来，不是会浪费一定的空间吗？因为这种实现方式，会在类装载的时候就初始化对象，不管你需不需要。</p><p>　　如果现在有一种方法能够让类装载的时候不去初始化对象，那不就解决问题了？一种可行的方式就是采用类级内部类，在这个类级内部类里面去创建对象实例。这样一来，只要不使用到这个类级内部类，那就不会创建对象实例，从而同时实现延迟加载和线程安全。</p><p>　　示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *    类级的内部类，也就是静态的成员式内部类，该内部类的实例与外部类的实例</span></span><br><span class="line"><span class="comment">     *    没有绑定关系，而且只有被调用到时才会装载，从而实现了延迟加载。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span></span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 静态初始化器，由JVM来保证线程安全</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　当getInstance方法第一次被调用的时候，它第一次读取SingletonHolder.instance，导致SingletonHolder类得到初始化；而这个类在装载并被初始化的时候，会初始化它的静态域，从而创建Singleton的实例，由于是静态的域，因此只会在虚拟机装载类的时候初始化一次，并由虚拟机来保证它的线程安全性。</p><p>　　这个模式的优势在于，getInstance方法并没有被同步，并且只是执行一个域的访问，因此延迟初始化并没有增加任何访问成本。</p><p>　　</p><p>　　单例和枚举</p><p>　　按照《高效Java 第二版》中的说法：单元素的枚举类型已经成为实现Singleton的最佳方法。用枚举来实现单例非常简单，只需要编写一个包含单个元素的枚举类型即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Singleton &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 定义一个枚举的元素，它就代表了Singleton的一个实例。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    </span><br><span class="line">    uniqueInstance;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 单例可以有自己的操作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">singletonOperation</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//功能处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　使用枚举来实现单实例控制会更加简洁，而且无偿地提供了序列化机制，并由JVM从根本上提供保障，绝对防止多次实例化，是更简洁、高效、安全的实现单例的方式。</p>]]></content>
      
      
        <tags>
            
            <tag> 作者：YuanBo-Chi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《JAVA与模式》之抽象工厂模式</title>
      <link href="/2018/04/28/%E3%80%8AJAVA%E4%B8%8E%E6%A8%A1%E5%BC%8F%E3%80%8B%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/2018/04/28/%E3%80%8AJAVA%E4%B8%8E%E6%A8%A1%E5%BC%8F%E3%80%8B%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>==作者：YuanBo-Chi==</p><p>[toc]</p><p>场景问题<br>　　举个生活中常见的例子——组装电脑，我们在组装电脑的时候，通常需要选择一系列的配件，比如CPU、硬盘、内存、主板、电源、机箱等。为讨论使用简单点，只考虑选择CPU和主板的问题。</p><p>　　事实上，在选择CPU的时候，面临一系列的问题，比如品牌、型号、针脚数目、主频等问题，只有把这些问题都确定下来，才能确定具体的CPU。</p><p>　　同样，在选择主板的时候，也有一系列问题，比如品牌、芯片组、集成芯片、总线频率等问题，也只有这些都确定了，才能确定具体的主板。</p><p>　　选择不同的CPU和主板，是每个客户在组装电脑的时候，向装机公司提出的要求，也就是我们每个人自己拟定的装机方案。</p><p>　　在最终确定这个装机方案之前，还需要整体考虑各个配件之间的兼容性。比如：CPU和主板，如果使用Intel的CPU和AMD的主板是根本无法组装的。因为Intel的CPU针脚数与AMD主板提供的CPU插口不兼容，就是说如果使用Intel的CPU根本就插不到AMD的主板中，所以装机方案是整体性的，里面选择的各个配件之间是有关联的。</p><p>　　对于装机工程师而言，他只知道组装一台电脑，需要相应的配件，但是具体使用什么样的配件，还得由客户说了算。也就是说装机工程师只是负责组装，而客户负责选择装配所需要的具体的配件。因此，当装机工程师为不同的客户组装电脑时，只需要根据客户的装机方案，去获取相应的配件，然后组装即可。</p><p>使用简单工厂模式的解决方案<br>　　考虑客户的功能，需要选择自己需要的CPU和主板，然后告诉装机工程师自己的选择，接下来就等着装机工程师组装电脑了。</p><p>　　对装机工程师而言，只是知道CPU和主板的接口，而不知道具体实现，很明显可以用上简单工厂模式或工厂方法模式。为了简单，这里选用简单工厂。客户告诉装机工程师自己的选择，然后装机工程师会通过相应的工厂去获取相应的实例对象。</p><p>　　<img src="http://i4.buimg.com/567571/13263f85752d09fe.png" alt=""></p><p>源代码<br>CPU接口与具体实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Cpu</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">calculate</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntelCpu</span> <span class="keyword">implements</span> <span class="title">Cpu</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * CPU的针脚数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> pins = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span>  <span class="title">IntelCpu</span><span class="params">(<span class="keyword">int</span> pins)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.pins = pins;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">calculate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"Intel CPU的针脚数："</span> + pins);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AmdCpu</span> <span class="keyword">implements</span> <span class="title">Cpu</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * CPU的针脚数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> pins = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span>  <span class="title">AmdCpu</span><span class="params">(<span class="keyword">int</span> pins)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.pins = pins;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">calculate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"AMD CPU的针脚数："</span> + pins);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主板接口与具体实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Mainboard</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">installCPU</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntelMainboard</span> <span class="keyword">implements</span> <span class="title">Mainboard</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * CPU插槽的孔数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> cpuHoles = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构造方法，传入CPU插槽的孔数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cpuHoles</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">IntelMainboard</span><span class="params">(<span class="keyword">int</span> cpuHoles)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.cpuHoles = cpuHoles;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">installCPU</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">System.out.println(<span class="string">"Intel主板的CPU插槽孔数是："</span> + cpuHoles);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AmdMainboard</span> <span class="keyword">implements</span> <span class="title">Mainboard</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * CPU插槽的孔数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> cpuHoles = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构造方法，传入CPU插槽的孔数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cpuHoles</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AmdMainboard</span><span class="params">(<span class="keyword">int</span> cpuHoles)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.cpuHoles = cpuHoles;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">installCPU</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"AMD主板的CPU插槽孔数是："</span> + cpuHoles);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CPU与主板工厂类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CpuFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Cpu <span class="title">createCpu</span><span class="params">(<span class="keyword">int</span> type)</span></span>&#123;</span><br><span class="line">        Cpu cpu = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(type == <span class="number">1</span>)&#123;</span><br><span class="line">            cpu = <span class="keyword">new</span> IntelCpu(<span class="number">755</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(type == <span class="number">2</span>)&#123;</span><br><span class="line">            cpu = <span class="keyword">new</span> AmdCpu(<span class="number">938</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cpu;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainboardFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Mainboard <span class="title">createMainboard</span><span class="params">(<span class="keyword">int</span> type)</span></span>&#123;</span><br><span class="line">        Mainboard mainboard = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(type == <span class="number">1</span>)&#123;</span><br><span class="line">            mainboard = <span class="keyword">new</span> IntelMainboard(<span class="number">755</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(type == <span class="number">2</span>)&#123;</span><br><span class="line">            mainboard = <span class="keyword">new</span> AmdMainboard(<span class="number">938</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> mainboard;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>装机工程师类与客户类运行结果如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ComputerEngineer</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义组装机需要的CPU</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Cpu cpu = <span class="keyword">null</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义组装机需要的主板</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Mainboard mainboard = <span class="keyword">null</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">makeComputer</span><span class="params">(<span class="keyword">int</span> cpuType , <span class="keyword">int</span> mainboard)</span></span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 组装机器的基本步骤</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//1:首先准备好装机所需要的配件</span></span><br><span class="line">prepareHardwares(cpuType, mainboard);</span><br><span class="line"><span class="comment">//2:组装机器</span></span><br><span class="line"><span class="comment">//3:测试机器</span></span><br><span class="line"><span class="comment">//4：交付客户</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">prepareHardwares</span><span class="params">(<span class="keyword">int</span> cpuType , <span class="keyword">int</span> mainboard)</span></span>&#123;</span><br><span class="line"><span class="comment">//这里要去准备CPU和主板的具体实现，为了示例简单，这里只准备这两个</span></span><br><span class="line"><span class="comment">//可是，装机工程师并不知道如何去创建，怎么办呢？</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//直接找相应的工厂获取</span></span><br><span class="line"><span class="keyword">this</span>.cpu = CpuFactory.createCpu(cpuType);</span><br><span class="line"><span class="keyword">this</span>.mainboard = MainboardFactory.createMainboard(mainboard);</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试配件是否好用</span></span><br><span class="line"><span class="keyword">this</span>.cpu.calculate();</span><br><span class="line"><span class="keyword">this</span>.mainboard.installCPU();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[]args)</span></span>&#123;</span><br><span class="line">ComputerEngineer cf = <span class="keyword">new</span> ComputerEngineer();</span><br><span class="line">cf.makeComputer(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><p><img src="http://i1.piimg.com/567571/f9a2a9561ec8f784.png" alt=""></p><p>　　上面的实现，虽然通过简单工厂方法解决了：对于装机工程师，只知CPU和主板的接口，而不知道具体实现的问题。但还有一个问题没有解决，那就是这些CPU对象和主板对象其实是有关系的，需要相互匹配的。而上面的实现中，并没有维护这种关联关系，CPU和主板是由客户任意选择，这是有问题的。比如在客户端调用makeComputer时，传入参数为(1,2)，运行结果如下：<br>　　<br><img src="http://i1.piimg.com/567571/d97478321e7484a6.png" alt="">　　</p><p>观察上面结果就会看出问题。客户选择的是Intel的CPU针脚数为755，而选择的主板是AMD，主板上的CPU插孔是938，根本无法组装，这就是没有维护配件之间的关系造成的。该怎么解决这个问题呢？　　</p><p>引进抽象工厂模式<br>　　每一个模式都是针对一定问题的解决方案。抽象工厂模式与工厂方法模式的最大区别就在于，工厂方法模式针对的是一个产品等级结构；而抽象工厂模式则需要面对多个产品等级结构。</p><p>　　在学习抽象工厂具体实例之前，应该明白两个重要的概念：产品族和产品等级。</p><p>　　所谓产品族，是指位于不同产品等级结构中，功能相关联的产品组成的家族。比如AMD的主板、芯片组、CPU组成一个家族，Intel的主板、芯片组、CPU组成一个家族。而这两个家族都来自于三个产品等级：主板、芯片组、CPU。一个等级结构是由相同的结构的产品组成，示意图如下：</p><p><img src="http://i2.muimg.com/567571/47cee263d5875255.png" alt=""></p><p>　　显然，每一个产品族中含有产品的数目，与产品等级结构的数目是相等的。产品的等级结构与产品族将产品按照不同方向划分，形成一个二维的坐标系。横轴表示产品的等级结构，纵轴表示产品族，上图共有两个产品族，分布于三个不同的产品等级结构中。只要指明一个产品所处的产品族以及它所属的等级结构，就可以唯一的确定这个产品。</p><p>　　上面所给出的三个不同的等级结构具有平行的结构。因此，如果采用工厂方法模式，就势必要使用三个独立的工厂等级结构来对付这三个产品等级结构。由于这三个产品等级结构的相似性，会导致三个平行的工厂等级结构。随着产品等级结构的数目的增加，工厂方法模式所给出的工厂等级结构的数目也会随之增加。如下图：</p><p><img src="http://i4.buimg.com/567571/6e7162e054a969a0.png" alt=""></p><p>　　　　那么，是否可以使用同一个工厂等级结构来对付这些相同或者极为相似的产品等级结构呢？当然可以的，而且这就是抽象工厂模式的好处。同一个工厂等级结构负责三个不同产品等级结构中的产品对象的创建。</p><p><img src="http://i1.piimg.com/567571/55f2e61a34570201.png" alt=""></p><p>　　可以看出，一个工厂等级结构可以创建出分属于不同产品等级结构的一个产品族中的所有对象。显然，这时候抽象工厂模式比简单工厂模式、工厂方法模式更有效率。对应于每一个产品族都有一个具体工厂。而每一个具体工厂负责创建属于同一个产品族，但是分属于不同等级结构的产品。</p><p>抽象工厂模式结构<br>　　抽象工厂模式是对象的创建模式，它是工厂方法模式的进一步推广。</p><p>　　假设一个子系统需要一些产品对象，而这些产品又属于一个以上的产品等级结构。那么为了将消费这些产品对象的责任和创建这些产品对象的责任分割开来，可以引进抽象工厂模式。这样的话，消费产品的一方不需要直接参与产品的创建工作，而只需要向一个公用的工厂接口请求所需要的产品。</p><p>　　通过使用抽象工厂模式，可以处理具有相同（或者相似）等级结构中的多个产品族中的产品对象的创建问题。如下图所示：</p><p><img src="http://i1.piimg.com/567571/f84184086ae65990.png" alt=""></p><p>　　由于这两个产品族的等级结构相同，因此使用同一个工厂族也可以处理这两个产品族的创建问题，这就是抽象工厂模式。</p><p>　　根据产品角色的结构图，就不难给出工厂角色的结构设计图。</p><p><img src="http://i2.muimg.com/567571/2a32b8ef3b9079cb.png" alt=""></p><p>　　可以看出，每一个工厂角色都有两个工厂方法，分别负责创建分属不同产品等级结构的产品对象。</p><p>　<img src="http://i1.piimg.com/567571/096ff2758e8e0459.png" alt="">　</p><p>源代码<br>　　前面示例实现的CPU接口和CPU实现对象，主板接口和主板实现对象，都不需要变化。</p><p>　　前面示例中创建CPU的简单工厂和创建主板的简单工厂，都不再需要。</p><p>　　新加入的抽象工厂类和实现类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建CPU对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> CPU对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Cpu <span class="title">createCpu</span><span class="params">()</span></span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建主板对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 主板对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Mainboard <span class="title">createMainboard</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntelFactory</span> <span class="keyword">implements</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Cpu <span class="title">createCpu</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> IntelCpu(<span class="number">755</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Mainboard <span class="title">createMainboard</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> IntelMainboard(<span class="number">755</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AmdFactory</span> <span class="keyword">implements</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Cpu <span class="title">createCpu</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> IntelCpu(<span class="number">938</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Mainboard <span class="title">createMainboard</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> IntelMainboard(<span class="number">938</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　装机工程师类跟前面的实现相比，主要的变化是：从客户端不再传入选择CPU和主板的参数，而是直接传入客户已经选择好的产品对象。这样就避免了单独去选择CPU和主板所带来的兼容性问题，客户要选就是一套，就是一个系列。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ComputerEngineer</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义组装机需要的CPU</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Cpu cpu = <span class="keyword">null</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义组装机需要的主板</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Mainboard mainboard = <span class="keyword">null</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">makeComputer</span><span class="params">(AbstractFactory af)</span></span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 组装机器的基本步骤</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//1:首先准备好装机所需要的配件</span></span><br><span class="line">prepareHardwares(af);</span><br><span class="line"><span class="comment">//2:组装机器</span></span><br><span class="line"><span class="comment">//3:测试机器</span></span><br><span class="line"><span class="comment">//4：交付客户</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">prepareHardwares</span><span class="params">(AbstractFactory af)</span></span>&#123;</span><br><span class="line"><span class="comment">//这里要去准备CPU和主板的具体实现，为了示例简单，这里只准备这两个</span></span><br><span class="line"><span class="comment">//可是，装机工程师并不知道如何去创建，怎么办呢？</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//直接找相应的工厂获取</span></span><br><span class="line"><span class="keyword">this</span>.cpu = af.createCpu();</span><br><span class="line"><span class="keyword">this</span>.mainboard = af.createMainboard();</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试配件是否好用</span></span><br><span class="line"><span class="keyword">this</span>.cpu.calculate();</span><br><span class="line"><span class="keyword">this</span>.mainboard.installCPU();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>客户端代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[]args)</span></span>&#123;</span><br><span class="line"><span class="comment">//创建装机工程师对象</span></span><br><span class="line">ComputerEngineer cf = <span class="keyword">new</span> ComputerEngineer();</span><br><span class="line"><span class="comment">//客户选择并创建需要使用的产品对象</span></span><br><span class="line">AbstractFactory af = <span class="keyword">new</span> IntelFactory();</span><br><span class="line"><span class="comment">//告诉装机工程师自己选择的产品，让装机工程师组装电脑</span></span><br><span class="line">cf.makeComputer(af);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　抽象工厂的功能是为一系列相关对象或相互依赖的对象创建一个接口。一定要注意，这个接口内的方法不是任意堆砌的，而是一系列相关或相互依赖的方法。比如上面例子中的主板和CPU，都是为了组装一台电脑的相关对象。不同的装机方案，代表一种具体的电脑系列。<br>　　<br><img src="http://i4.buimg.com/567571/a0c4dd730e72959c.png" alt=""></p><p>　　由于抽象工厂定义的一系列对象通常是相关或相互依赖的，这些产品对象就构成了一个产品族，也就是抽象工厂定义了一个产品族。</p><p>　　这就带来非常大的灵活性，切换产品族的时候，只要提供不同的抽象工厂实现就可以了，也就是说现在是以一个产品族作为一个整体被切换。</p><p><img src="http://i4.buimg.com/567571/e2b124ee31a1f5af.png" alt="">　　</p><p>在什么情况下应当使用抽象工厂模式<br>　　1.一个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有形态的工厂模式都是重要的。</p><p>　　2.这个系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。</p><p>　　3.同属于同一个产品族的产品是在一起使用的，这一约束必须在系统的设计中体现出来。（比如：Intel主板必须使用Intel CPU、Intel芯片组）</p><p>　　4.系统提供一个产品类的库，所有的产品以同样的接口出现，从而使客户端不依赖于实现。</p><p>抽象工厂模式的起源<br>　　抽象工厂模式的起源或者最早的应用，是用于创建分属于不同操作系统的视窗构建。比如：命令按键（Button）与文字框（Text)都是视窗构建，在UNIX操作系统的视窗环境和Windows操作系统的视窗环境中，这两个构建有不同的本地实现，它们的细节有所不同。</p><p>　　在每一个操作系统中，都有一个视窗构建组成的构建家族。在这里就是Button和Text组成的产品族。而每一个视窗构件都构成自己的等级结构，由一个抽象角色给出抽象的功能描述，而由具体子类给出不同操作系统下的具体实现。</p><p><img src="http://i1.piimg.com/567571/84865c898668e400.png" alt=""><br>　　<br>　　可以发现在上面的产品类图中，有两个产品的等级结构，分别是Button等级结构和Text等级结构。同时有两个产品族，也就是UNIX产品族和Windows产品族。UNIX产品族由UNIX Button和UNIX Text产品构成；而Windows产品族由Windows Button和Windows Text产品构成。</p><p><img src="http://i1.piimg.com/567571/ddbb2cfb987cdb88.png" alt=""></p><p>　　系统对产品对象的创建需求由一个工程的等级结构满足，其中有两个具体工程角色，即UnixFactory和WindowsFactory。UnixFactory对象负责创建Unix产品族中的产品，而WindowsFactory对象负责创建Windows产品族中的产品。这就是抽象工厂模式的应用，抽象工厂模式的解决方案如下图：</p><p><img src="http://i4.buimg.com/567571/9f918c862785449c.png" alt="">　　</p><p>　　显然，一个系统只能够在某一个操作系统的视窗环境下运行，而不能同时在不同的操作系统上运行。所以，系统实际上只能消费属于同一个产品族的产品。</p><p>　　在现代的应用中，抽象工厂模式的使用范围已经大大扩大了，不再要求系统只能消费某一个产品族了。因此，可以不必理会前面所提到的原始用意。</p><p>抽象工厂模式的优点<br>分离接口和实现<br>　　客户端使用抽象工厂来创建需要的对象，而客户端根本就不知道具体的实现是谁，客户端只是面向产品的接口编程而已。也就是说，客户端从具体的产品实现中解耦。</p><p>使切换产品族变得容易<br>　　因为一个具体的工厂实现代表的是一个产品族，比如上面例子的从Intel系列到AMD系列只需要切换一下具体工厂。</p><p>抽象工厂模式的缺点<br>不太容易扩展新的产品<br>　　如果需要给整个产品族添加一个新的产品，那么就需要修改抽象工厂，这样就会导致修改所有的工厂实现类。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/04/28/hello-world/"/>
      <url>/2018/04/28/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
    </entry>
    
  
  
</search>
